[{"content":"　​sudo​ 能通过精细化的授权配置（/etc/sudoers 文件）和密码验证，帮助管理员更安全、灵活地控制用户权限。一般都会设立一个超级管理员权限组，将有管理员用户加入到超级管理员用户组，就可以通过 sudo​ 临时获取超级管理员权限执行命令。\n查看超级管理员组 不同的 Linux 发行版的管理权限的组名不同：\nDebian/Ubuntu 系列：\n通常有一个名为 sudo​ 的组，用于授权用户获得管理员权限。 Red Hat/CentOS/Fedora 系列：\n这些系统中一般使用 wheel​ 组来授予 sudo 权限，而不是 sudo​ 组。 其他发行版或自定义系统：\n有的可能使用 admin​ 等其他组名，或者管理员权限配置方式不同。 可以通过下列命令查看当前系统中是否有 sudo​、wheel​ 或 admin​ 等相关组：\n1 cat /etc/group | grep -E \u0026#34;sudo|wheel|admin\u0026#34; Manjaro 就是使用 wheel​ 组来授予 sudo 权限。\n配置文件 /etc/sudoers 通过命令 visudo​ 可以对配置 sudo​ 的文件 /etc/sudoers​ 进行编辑，来配置 sudo 的相关行为。\n​/etc/sudoers​ 文件只有只读权限，虽然可以通过 root 权限强行写入，但是不会检查语法，不保证每次修改的内容符合语法，有可能会引发系统异常。因此，通常使用 visudo​ 来修改。\n但 visudo​ 默认的编辑器是 vi​，不习惯使用的话，可以通过 export EDITOR=vim​ 将 visudo​ 编辑器临时换成 vim​。\nmanjaro 中 /etc/sudoers​ 文件一般如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... ## ## User privilege specification ## root ALL=(ALL:ALL) ALL ## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL:ALL) ALL ## Same thing without a password # %wheel ALL=(ALL:ALL) NOPASSWD: ALL ## Uncomment to allow members of group sudo to execute any command # %sudo ALL=(ALL:ALL) ALL ## Uncomment to allow any user to run sudo if they know the password ## of the user they are running the command as (root by default). # Defaults targetpw # Ask for the password of the target user # ALL ALL=(ALL:ALL) ALL # WARNING: only use this together with \u0026#39;Defaults targetpw\u0026#39; ## Read drop-in files from /etc/sudoers.d @includedir /etc/sudoers.d 越往后的配置，优先级越高，也就是越往后的配置，会覆盖掉前面与之冲突的配置。下面介绍两个配置的含义。\n​​root ALL=(ALL:ALL) ALL​​\n作用对象： 只作用于用户 root​。\n解释：\n第一个 ALL​：root​ 用户可以从任意主机执行 sudo​。\n​ALL=(ALL:ALL)​：\n第一个 ​ALL​​ ： 指定可以切换到的目标用户（这里表示任意用户）。 第二个 ​ALL​​ （冒号后的部分）： 指定可以切换到的目标组（这里表示任意组）。 最后的 ALL​：指示允许执行的命令（这里表示任意命令）。\n总结： root​ 用户不需要提权，因为它本身就是超级用户，所以这个配置通常是冗余的，仅用作兼容性说明，明确 root​ 用户没有任何限制。\n​ ​%wheel ALL=(ALL:ALL) ALL​​\n作用对象： 作用于用户组 wheel​。\n​%​ 表示后面跟的是一个用户组，而不是单个用户。 用户组 wheel​ 通常是系统管理员用来标记具备提权能力的用户。 解释：\n第一个 ALL​：wheel​ 组内的用户可以从任意主机执行 sudo​。\n​ALL=(ALL:ALL)​：\n第一个 ​ALL​​ ： 组内用户可以切换到任意用户。 第二个 ​ALL​​ （冒号后的部分）： 组内用户可以切换到任意组。 最后的 ALL​：组内用户可以执行任意命令。\n总结： 加入 wheel​ 组的用户可以使用 sudo​ 提权来执行任何命令。\n不使用密码提权 取消掉 # %wheel ALL=(ALL:ALL) NOPASSWD: ALL​ 前面的注释即可。\n1 %wheel ALL=(ALL:ALL) NOPASSWD: ALL 表示 wheel​ 用户组中的任意用户都可以使用 sudo 提权到 root，且不需要密码。\n覆盖配置文件 ‍\n一般在 ubuntu、debian 系统中，取消注释就可以免密提权，因为这类系统中 /etc/sudoers.d​ 文件夹下，没有额外的配置文件，那么 /etc/sudoers​ 文件的最后一行 @includedir /etc/sudoers.d​ 即便将 /etc/sudoers.d​ 包含进去，也不会生效。但 manjaro 下默认有一个配置文件 /etc/sudoers.d/10-installer​，其中的内容为：\n1 2 $ sudo cat /etc/sudoers.d/10-installer %wheel ALL=(ALL) ALL 根据前面提到的 /etc/sudoers​ 中的规则，越往后的配置优先级越高，manjaro 发行版中，即便在 /etc/sudoers​ 中取消了注释 %wheel ALL=(ALL:ALL) NOPASSWD: ALL​，也会被 /etc/sudoers.d/10-installer​ 中的配置覆盖。\n所以，可以将 /etc/sudoers​ 最后一行 @includedir /etc/sudoers.d​ 注释掉；也可以在/etc/sudoers.d/10-installer​ 中添加一条，将我们需要免密提权的用户添加进文件中，如下：\n1 2 %wheel ALL=(ALL) ALL ling ALL=(ALL) NOPASSWD: ALL ‍\n","date":"2024-12-06T22:17:28+08:00","permalink":"https://codetang-2417.github.io/p/sudo%E5%85%8D%E5%AF%86%E7%A0%81/","title":"sudo免密码"},{"content":"搭建 VNC 服务 参考：linux ubuntu搭建不同用户的VNC\n该文章详细介绍了，在服务器上搭建多用户的 vnc 服务需要的注意事项和相关命令。\n并在 创建用户​ 中应用了这部分内容。\n目前采用人工分配端口的方式，为用户分配 vnc 端口。可根据文章中提到的，不指定端口号启动 vnc 来自动分配（但这样每一次用户登陆，都新开启一个端口用于 vnc 登陆。可以修改 vnc 脚本来判断是否启动了当前用户的 vnc 服务，再决定要不要分配新的端口，目前未实现）。\n创建用户 创建新用户需要：\n创建 home 目录 创建用户及密码 添加到 docker 组 为用户配置 vnc 服务，分配 vnc 端口号 上述步骤，除手动分配 vnc 端口外，都通过脚本完成。\n准备事项：1. 参考上一节 搭建 VNC 服务，安装对应的软件。2. 根据本节下述参考文章，创建对应的文件。\n参考：ubuntu创建新用户并分配VNC远程桌面\n该文章中介绍了添加用户所需要的文件、命令。需要根据其给出的脚本内容，在服务器上创建对应的文件。可以自行修改脚本路径。\n然后按照使用方法，运行该脚本即可。\n注意事项：\n脚本中 vnc 启动脚本指定了端口号，添加完新用户后，需要修改该用户的 vnc 启动脚本中的vnc 端口号。 用户第一次登陆时，会运行 vnc 服务，提示输出 vnc 密码。可以在创建用户的时候，帮助其创建该密码。最好保持和ssh密码一致，防止遗忘。 ","date":"2024-12-04T10:22:03+08:00","permalink":"https://codetang-2417.github.io/p/%E6%A0%A1%E5%86%85%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AE%A1%E7%90%86%E5%91%98%E6%89%8B%E5%86%8C/","title":"校内服务器管理员手册"},{"content":"获取账号及连接服务器 咨询管理员获取。例如：\n1 2 3 4 5 用户名 san.zhang@10.1.2.3 密码 zhangsan123\u0026amp; GUI 图形界面 VNC 端口 5901 Linux 命令行连接 在终端中，使用 ssh 命令\n1 ssh san.zhang@10.1.2.3 VNC 桌面 GUI 连接 windows 下载 realvnc，创建 vnc 连接，输入 vnc 登陆密码即可。vnc 登陆密码一般由管理员设置，与 SSH 账号密码一致。\n格式形如：san.zhang@10.1.2.3:5901​。其中 5901 是 vnc 端口号。\n具体的 vnc 端口号，可以先命令行登陆服务器，查看登陆提示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ssh san.zhang@10.1.2.3 Welcome to Ubuntu 22.04.4 LTS (GNU/Linux 6.8.0-45-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/pro Expanded Security Maintenance for Applications is not enabled. 83 updates can be applied immediately. To see these additional updates run: apt list --upgradable 11 additional security updates can be applied with ESM Apps. Learn more about enabling ESM Apps service at https://ubuntu.com/esm New release \u0026#39;24.04.1 LTS\u0026#39; available. Run \u0026#39;do-release-upgrade\u0026#39; to upgrade to it. Last login: Tue Dec 3 16:48:15 2024 from 10.1.2.3 A Xtigervnc server is already running for display :4 on machine ubuntu-AS-4124GS-TNR. 最后一行提示 Xtigervnc server​ 已经在 :4​ 端口上运行。由于 VNC server 端口从 5900 开始，这意味着当前用户的 VNC 服务运行在 5904​ 端口。每一个用户的端口号不同，错误的端口号将无法连接桌面环境。\n注：首次 ssh 登陆成功后，会提示输入 vnc 的访问密码，可以使用相同的 ssh 密码作为 vnc 登陆密码。如果没有提示，则是管理员创建帐号时帮助用户输入了 ssh 密码。\n也可以根据管理员给出账号时的 VNC 端口来获取。如遇到不可解决的问题，请联系管理员。\n校外使用方法 需要去学校 VPN 网站下载 ATrust VPN 软件，通过 VPN 连接到校园网环境才可以连接服务器。\n​信息门户​ -\u0026gt; 左侧 综合服务 栏​ -\u0026gt; VPN​\n使用 Docker 建立开发环境 Dockerfile 创建启动镜像 参考：QEMU开发环境搭建。\n依据上述参考文章，编写 Dockerfile 文件，并创建一个符合自己工作环境的 Docker 镜像，基于该镜像启动一个容器。后续使用时，可通过 vscode、命令行等方式连接到容器进行开发。\n深度学习等场景，需要在容器启动时添加 --gpus all​ 使用所有 GPU 资源。其他特殊参数请自行搜索。\n参考文章中已经给出了下述注意事项的解决方案，此处再次提示相关注意点：\n创建的镜像最好将 apt 源换为国内镜像源，提高安装软件的速度。\n创建的镜像需要指定用户 ID 和组 ID 为当前登陆用户的相关 ID。否则共享文件夹时会遇到权限问题。\n当然也可以通过创建容器卷的形式储存工作数据，但不利于主机访问数据。本文的 开发环境搭建 中采用共享文件夹的形式启动容器。\n下面给出 docker 中两种保存工作数据的方式使用场景对比。\n适用场景对比\n特性 容器卷（Volume） 共享文件夹（Bind Mount） 开发环境 不太方便，需进入容器或容器卷目录才能操作 非常适合，代码、日志等文件实时同步到宿主机 生产环境 更适合，数据隔离性好，便于管理和备份 较少使用，权限和安全性管理较复杂 数据持久化 内置支持，便于 Docker 管理 可以持久化，但需自己管理目录 跨平台部署 支持良好（Docker 管理底层实现） 需要注意文件系统和路径兼容性 性能 更高（尤其是对于存储优化的场景） 较低（直接依赖宿主机文件系统性能） 安全性 高，宿主机数据与容器隔离 低，宿主机数据直接暴露给容器 调试和实时交互 不便，需通过 Docker 命令访问数据 方便，宿主机程序可直接访问和修改 在创建镜像时，可以适当安装一些常用软件包，避免每次基于该镜像创建的容器都需要重新安装基础软件。基于自己的工作环境，修改上述参考文章中提到的 Dockfile 中的依赖软件安装文本。\n上传\\下载文件到服务器 scp 命令可以通过 ssh 协议传输文件到服务器和从服务器下载文件。 vscode连接后，可以手动选择文件，并下载到本地，或者将文件拖动到对应的工作空间，上传至服务器。 代理网络 若服务器上需要使用代理网络，加速访问 github、google 等，可参考：个人Linux主机通过SSH隧道使服务器访问外网。\n","date":"2024-12-04T09:33:29+08:00","permalink":"https://codetang-2417.github.io/p/%E6%A0%A1%E5%86%85%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","title":"校内服务器使用指南"},{"content":"问题 在 qbittorrent​ 校验大文件时（大概100GB以上？），会出现无法启动新应用的情况。\nKDE 还会在一段时间后，弹出下列通知\n1 Did not receive a reply. Possible causes include: the remote application did not send a reply, the message bus security policy blocked the reply, the reply timeout expired, or the network connection was broken. 而且在终端中无法运行系统内核相关的程序，例如：journalctl​、systemdctl​ 等。无法通过 reboot​ 重启电脑，只能通过长按电源键硬重启电脑。\n解决方案 手动 1 sudo renice +10 -p $(pgrep qbittorrent) 再次校验大文件时，就不会出现上述问题。\n自动 更改开机自启动 desktop​ 文件，在启动时就将 qbittorrent​ 优先级降低。\n1 2 3 4 $ ls ~/.config/autostart $ vim org.qbittorrent.qBittorrent.desktop 将 Exec=qbittorrent %U 改为 Exec=sh -c \u0026#34;nice -n 10 qbittorrent %U\u0026#34; 更改通用启动 desktop​ 文件，在启动时就将 qbittorrent​ 优先级降低。\n1 2 3 $ vim ~/.local/share/applications/org.qbittorrent.qBittorrent.desktop 将 Exec=qbittorrent %U 改为 Exec=sh -c \u0026#34;nice -n 10 qbittorrent %U\u0026#34; 或者通过图形化界面找到 desktop​ 文件\n​​\n​​\n","date":"2024-11-17T01:25:27+08:00","permalink":"https://codetang-2417.github.io/p/qbittorrent-%E6%A0%A1%E9%AA%8C%E5%A4%A7%E6%96%87%E4%BB%B6%E5%AF%BC%E8%87%B4linux%E5%86%85%E6%A0%B8%E5%87%BA%E9%97%AE%E9%A2%98/","title":"qbittorrent 校验大文件导致Linux内核出问题"},{"content":"　使用 Manjaro，最近发现时间不同步。Manjaro 目前使用 systemd-timesyncd 服务同步时间。可通过下列命令查看服务状态：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $ systemctl status systemd-timesyncd.service  ✔  9s  ○ systemd-timesyncd.service - Network Time Synchronization Loaded: loaded (/usr/lib/systemd/system/systemd-timesyncd.service; enabled; preset: enabled) Active: inactive (dead) since Tue 2024-11-05 09:49:12 CST; 21min ago Duration: 19min 50.593s Invocation: ad67794ba19a43cfbb91ef6b058f40a8 Docs: man:systemd-timesyncd.service(8) Main PID: 892 (code=exited, status=0/SUCCESS) Status: \u0026#34;Idle.\u0026#34; Mem peak: 5.3M CPU: 53ms Nov 05 09:29:21 ling-20ym systemd[1]: Starting Network Time Synchronization... Nov 05 09:29:21 ling-20ym systemd[1]: Started Network Time Synchronization. Nov 05 09:32:09 ling-20ym systemd-timesyncd[892]: Timed out waiting for reply from 111.203.6.13:123 (ntp1.nim.ac.cn). Nov 05 09:32:51 ling-20ym systemd-timesyncd[892]: Timed out waiting for reply from 111.203.6.13:123 (ntp1.nim.ac.cn). Nov 05 09:34:06 ling-20ym systemd-timesyncd[892]: Timed out waiting for reply from 111.203.6.13:123 (ntp1.nim.ac.cn). Nov 05 09:36:24 ling-20ym systemd-timesyncd[892]: Timed out waiting for reply from 111.203.6.13:123 (ntp1.nim.ac.cn). Nov 05 09:40:51 ling-20ym systemd-timesyncd[892]: Timed out waiting for reply from 111.203.6.13:123 (ntp1.nim.ac.cn). Nov 05 09:49:12 ling-20ym systemd[1]: Stopping Network Time Synchronization... Nov 05 09:49:12 ling-20ym systemd[1]: systemd-timesyncd.service: Deactivated successfully. Nov 05 09:49:12 ling-20ym systemd[1]: Stopped Network Time Synchronization. 可知时间同步服务器访问出现问题。修改服务器为中国区的服务器:\n​sudo vim /etc/systemd/timesyncd.conf​\n1 2 [Time] NTP=ntp.aliyun.com ntp.ntsc.ac.cn 重新运行服务，或者手动更新\n1 2 # 手动更新 sudo ntpd -q -g -p ntp.aliyun.com 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 重新运行服务 $ systemctl status systemd-timesyncd.service  ✔ ● systemd-timesyncd.service - Network Time Synchronization Loaded: loaded (/usr/lib/systemd/system/systemd-timesyncd.service; enabled; preset: enabled) Active: active (running) since Tue 2024-11-05 10:13:50 CST; 3min 8s ago Invocation: 50dde2f5504342deaf3543272c50b332 Docs: man:systemd-timesyncd.service(8) Main PID: 14567 (systemd-timesyn) Status: \u0026#34;Contacted time server 203.107.6.88:123 (ntp.aliyun.com).\u0026#34; Tasks: 2 (limit: 28019) Memory: 3.3M (peak: 4.1M) CPU: 42ms CGroup: /system.slice/systemd-timesyncd.service └─14567 /usr/lib/systemd/systemd-timesyncd Nov 05 10:13:50 ling-20ym systemd[1]: Starting Network Time Synchronization... Nov 05 10:13:50 ling-20ym systemd[1]: Started Network Time Synchronization. Nov 05 10:13:52 ling-20ym systemd-timesyncd[14567]: Contacted time server 203.107.6.88:123 (ntp.aliyun.com). Nov 05 10:13:52 ling-20ym systemd-timesyncd[14567]: Initial clock synchronization to Tue 2024-11-05 10:13:52.194984 CST. 参考：systemd-timesyncd、国内常用NTP服务器地址\n‍\n","date":"2024-11-05T10:10:41+08:00","permalink":"https://codetang-2417.github.io/p/time-%E5%90%8C%E6%AD%A5/","title":"Time 同步"},{"content":"　使用 mihomo-party 为 Clash.Meta 的前端 GUI软件。对 Clash 进行配置。\n推荐使用虚拟网卡模式，可以解决 DNS 泄漏问题，否则可能出现无法访问 GPT 的现象。系统代理可以同时开启，不开启没有影响，如果有时遇到其他网站可以访问，某些网站不行，可以尝试关闭 系统代理、虚拟网卡，再重新打开。\nDNS 解析 ​\n虚拟网卡（TUN）模式下自动开启 DNS 模块。这里采用 redir-host​ 模式的 DNS 解析，也就是真实 IP 模式。同时开启流量嗅探。\n校园网的内部资源可能会因为没有 DNS 服务器而解析 IP 失败。需要手动指定 DNS 服务器。\n可以通过查看系统 dns 配置文件找到当前网络的 DNS 服务器。详见：Linux配置/etc/resolv.conf详解\nwindow 直接在 wifi 连接详细信息里查看。\n1 2 3 $ cat /etc/resolv.conf nameserver 202.102.192.68 nameserver 202.102.192.69 ​redir-host​ 模式必须开启流量嗅探，否则在配置 DNS 为明文的情况下，会造成 DNS 污染和泄漏。\n其中 代理节点域名解析​ 对应 clash.meta 的 proxy-server-nameserver​ 字段，该字段需要启用 连接遵守规则​ （对应 clash.meta respect-rules​ 字段）才生效。表示根据节点的路由规则来决定 DNS 请求发往的服务器。走代理节点网站的 DNS 查询使用 proxy-server-nameserver​ 中定义的 DNS 服务器，直连走 nameserver​ 中定义的 DNS 服务器。\n图中所有的 DNS 服务器都是 DOH or DOT 服务器，即发送的 DNS 请求被加密，这是为了防止 DNS 泄漏。\nDNS 配置 ​​\n1 2 3 4 https://doh.dns.sb/dns-query https://dns.alidns.com/dns-query tls://dns.google:853 https://cloudflare-dns.com/dns-query 校园网环境 一些纯 IPV6，或者 PT站需要 IPV6 访问。可以将这类网站的出站改为纯 IPV6 的出站。例如 byr.pt 有国内香港的服务器，如果使用代理访问速度会慢一些，可以将其设置为 直连的 IPV6 出站。\n校园内部资源由于网站比较小众，在当前配置下，会被代理到节点。需要手动添加规则使之直连。\n下面是在北邮校园网情况下，设置 byr.pt 直连 IPV6、校内资源直连 的覆写规则。一定要在覆写栏中填写，如果采用订阅网址的方式，每次更新后，规则会被覆盖，而覆写规则可以一直保持生效。\n​​\n1 2 3 4 5 6 7 8 9 # https://mihomo.party/docs/guide/override/yaml +proxies: - name: IPV6 type: direct ip-version: ipv6 +rules: - DOMAIN-SUFFIX,bupt.edu.cn,DIRECT - DOMAIN-SUFFIX,byr.cn,DIRECT - DOMAIN-SUFFIX,byr.pt,IPV6 mihomo-party 的覆写规则参见 官网。\n其他软件直连 使用 bittorrent 类软件，消耗流量比较大，且 byr.pt 支持校园上传，只是不支持校外访问。因此可以让下载流量的软件全部走直连，只让访问网站走代理。\n​​\n下列是 Linux 系统下设置 qbittorrent 软件走直连的覆写规则，windows 下，可以参考 clash.meta 的配置语法\n1 2 3 4 # https://mihomo.party/docs/guide/override/yaml # https://mihomo.party/docs/guide/override/yaml +rules: - PROCESS-PATH,/usr/bin/qbittorrent,DIRECT 官网配置语法实例，需要在任务管理器找到自己用的 bt 软件路径，但需要将 PROXY​ 字段替换为 DIRECT​。\n1 2 3 4 - PROCESS-PATH,/usr/bin/wget,PROXY - PROCESS-PATH,C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe,PROXY - PROCESS-PATH-REGEX,.*bin/wget,PROXY - PROCESS-PATH-REGEX,(?i).*Application\\\\chrome.*,PROXY ​​\n覆写规则 覆写规则可以在节点管理中设置当前节点需要覆写的规则。\n​​\n​​\n","date":"2024-11-05T09:07:40+08:00","permalink":"https://codetang-2417.github.io/p/clash-%E9%85%8D%E7%BD%AE/","title":"Clash 配置"},{"content":"网络代理的三种方案 系统代理：将数据交给本地 http/socks 服务 TUN/TAP：使用虚拟网卡接管系统全局流量 真 VPN：封装网络层数据包的真正意义上的VPN 其中 TUN 模拟用的最广泛，因为 GPT、奈飞等网站会检测代理模式上网而禁止访问对应服务，TUN 模式在配置良好的情况下，可以正常访问，且 TUN 模式还可以实现软路由等透明代理的代理网络。\n网络通信流程和代理通信流程 参考：Youtube【进阶•代理模式篇】\n无代理正常通信流程 正常情况下，网络通信根据 TCP/IP 四层模型，会通过 应用层-\u0026gt;传输层-\u0026gt;网络层-\u0026gt;接口层，逐层往下封装并发送到互联网中。\n应用层：HTTP 等网络协议对信息的封装\n传输层：TCP 协议的封装，包含通信双方的端口：源端口和目标端口\n网络层：IP 协议的封装，包含通信双方的源 IP 地址和目的 IP 地址\n接口层：物理接口，封装MAC地址，并将数据包发送出去。\n​​\n在正常家庭宽带网络中，都使用 IPV4 作为主要的 IP 通信地址，而 IPV4 地址有限，需要使用 NAT 技术为家庭网络中的设备分配 192.168.0.0/16​ 的c类私有网络地址，因此在路由器发出我们的数据流量时，会主动将其中的 192.168.0.0/16​ 私有地址替换为其获取的 WAN 共有地址，并发送出去。在接受公网的数据包时，也会再替换成对应的私有网络地址。这部分和代理网络没有相关性，只作了解。代理网络主要关注点在应用层到网络层。\n代理网络通信流程 系统代理 最简单，最常见的代理模式，所有的代理软件都会支持的一种模式。\n其主要在应用层工作：\n设置软件为系统代理模式，并且应用本身访问网络也遵循系统代理，则该应用的网络流量会被交给代理软件。 代理软件根据相应的分流规则，决定每一个连接是否需要走代理服务器。 根据代理服务器的加密协议，将流量加密。代理加密（例如 Shadowsocks、V2Ray）能隐藏域名和具体内容，监控者只能看到加密流量，难以获取任何访问信息。而普通的 https 协议还是可以发现访问的网址。 而代理服务器收到数据流量后，会进行解封装，和解密，然后帮助我们访问对应的网站和内容，最后再通过相同的加密方式再返回给本机。 本机再解封装、解密，使得本机可以正常访问被屏蔽的网站。 ​​\n这个模式简单，但有一个问题，并不是所有软件都可以走系统代理访问。大部分软件的行为完全取决于开发者，绝大部分的软件都不会走系统代理，不会给设置系统代理的入口。而且像游戏这类走 udp 协议的流量，就无法通过 http 协议代理，且游戏一般不会添加代理功能。\n系统代理的常见用途就是看网页和聊天。还有一些设置了走代理，但实际并没有，这种情况下，就需要 TUN/TAP 模式。\nTUN/TAP 模式 创建一张虚拟网卡，从网络层接管所有的流量。因为所有发往互联网的流量都必须经过网络层的封装，在这层进行拦截就能够获取所有应用产生的网络数据，这是目前主流的模式。\n手机上的代理软件默认就是这种模式，所有可以实现所有软件的代理。软路由接管全家的科学上网也是同样的原理。所以 TUN/TAP 模式是应用最广泛的代理模式。\n​​\n其主要在网络层和接口层工作：\n数据的封装流程和系统代理模式都一致，区别在与，网络层对 IP 协议封装时，源 IP 地址将不再是物理网卡地址，而是被封装为虚拟网卡地址。因为系统现在有两张网卡，具体发送供给哪一张，由路由表决定。\n所以代理软件通过添加路由表项实现所有 IP 地址的数据都转发给虚拟网卡的功能。如下图所示：\n​​\n所以，网络层现在封装的源 IP 地址就是198.18.0.1​，如果是 TAP 协议，还会向下封装 MAC 地址。\n​​\n当数据来到虚拟网卡后，代理软件会直接读取数据流量，并根据分流规则，将需要加密的数据加密，继续和正常通信一样封装到接口层，且为了避免流量环回，还会自动的在网络层将源 IP 改为物理网卡地址，最后发送出去。\n​​\n所以 TUN 模式的主要特点，就是通过修改路由表接管所有系统流量，不支持走系统代理的软件流量，也会被 TUN 模式接管。\n但软件或者游戏，可以检测到电脑是否开启虚拟网卡。为了让代理过程对电脑完全透明，可以将clash的虚拟网卡转移到路由器里。这样局域网内的设备无需运行任何代理工具，所有设备上网流量必将经过网关路由器。这就是透明代理，也是软路由的由来。\n这种虚拟网卡模式和真正的 VPN 非常接近，但并不是真正的 VPN。因为目前主流的代理网络协议（SS、Vmess、Trojan）都无法封装网络层的数据包，比如 ping 命令的 ICMP 协议流量。当我们 Ping 网站时，会直接从虚拟网卡返回，而不是真实的 ping 命令返回的数据包。\n但真正的 VPN 可以代理网络层协议，可以正常 Ping。\n真正的 VPN VPN 全称 Virtual Private Network，即 虚拟专用网络或者虚拟私有网络。私有网络就是家里的局域网，没有公网 IP，无法从外网直接和你的局域网设备通信。但 VPN 可以不物理的连接私有局域网，和局域网设备通信。只有封装网络层的数据包，才能实现这个功能，实现异地组网。\n但 VPN 并不适合翻墙，因为 VPN 不会隐藏自己的流量，清晰的表明自己就是 VPN 流量，而科学上网的协议将自己隐藏起来，不能判断出究竟是什么类型的流量。\nDNS Domin Name System，域名系统，用于解析域名，获取域名对应的服务器的 IP 地址。\nDNS 工作流程 访问网站时，都是通过域名访问，但需要 IP 地址才能定位一个服务器。在家庭网络中，一般会由运营商分配 DNS 服务器，为网络提供 DNS 服务。当本机需要访问一个域名网站时，会构建一条 UDP 明文数据包发往 DNS 服务器，这个数据包的端口一般都是 53。如果该 DNS 服务器中没有缓存对应域名的 IP 地址，则还会继续向上游 DNS 询问。最终会通过 DNS 迭代查询 找到一个权威 DNS 服务器，权威 DNS 服务器会返回域名绑定的 IP 地址和 TTL（Time To Live，标志着缓存有效时间）。每一个链路上查询过的 DNS 服务器都会缓存这个信息。最后，本机会收到该数据包，知道了 IP 地址，就可以正常访问网站了。\nDNS 泄漏 而 DNS 泄漏，指的是在开启代理网络的情况下，被运营商，或者 CFW 获取到你要访问的目标网站信息。注意，一定是在开启代理的情况下。因为通常情况下，你发送 DNS 请求，运营商一定知道，并且会帮助你查询，或者是污染你的 DNS 请求，被污染的情况下，你是无法正常访问的。而开启代理后再发送目标网站的明文 DNS 请求，然后又发送了一大堆加密数据，那不用想，肯定是在翻墙。所以，只有开启代理时，才会存在 DNS 泄漏。\n还有一些对地区要求高的网站，也可能会通过 DNS 查询，来判断是否是通过代理软件来访问的。还有 OpenAI 也会检测当前地区是否支持访问。当存在 DNS 泄漏时，我们就不能正常访问这些网站了。\n检查 DNS 泄漏 可以通过网站 ipleak.net​ 来查看自己当前的代理网络是否存在 DNS 泄漏。该网站的检测原理是：随机构建域名，并不断的发起随机域名的 DNS 请求。权威 DNS 服务器在受到 DNS 请求时，会记录下对应的上游 DNS 的 IP 地址，并且可以判断 DNS 上游服务器的所属地区，然后发送回该网站。该网站就能够知道你所发起的 DNS 请求，都经过了哪些区域的上游服务器。\n当你没有开启代理时，这个网站返回中国的 DNS 服务器，证明这些服务器在帮助你进行 DNS 解析。如果还配置了其他地区的 DNS，则还可能出现一些少数其他地区的服务器。并不代表 DNS 泄漏或者没有泄漏。\n​​\n只有当开启代理后，流量被发送到代理软件，此时存在两种情况：1. 不发起 DNS 请求就能判断走代理还是直连。2. 发起 DNS 请求后，才能知道是否走代理。\n第 1 种情况基本不存在 DNS 泄漏。而第 2 种大概率存在 DNS 泄漏。第 2 种，即便手动将 DNS 配置为国外的 DNS 服务器，也存在泄漏，因为 DNS 是明文的。这种情况下，是查不到其他的国内 DNS 服务器的，因为指定了国外 DNS 服务器，所以还会迷惑你，以为没有发生 DNS 泄漏。\n只有使用 DoH 或者 DoT 进行加密，或者代理客户端加密进行远程 DNS，发送的 DNS 才不是明文，不会被其他服务器看到。但这会增加延迟。所以大部分情况是不加密 DNS 的，这回造成运营商或者中间任意一台路由器都知道你的意图是访问被墙网站。\n既然 DNS 泄漏是在开启代理后，发送了目标网站的 DNS 请求造成的。那么只要代理时，不发送这类 DNS 请求，就不会造成泄漏了。这就需要对 DNS 分流规则设置的非常合理才行。\n解决 DNS 泄漏 目前 TUN 模式是比较适合科学上网的，但会出现一些网站无法上网的情况，这一般是由于 DNS 设置不当造成的。DNS 负责将域名解析成 IP，但在科学上网中，要实现分流，让 DNS 这个原本简单的协议在代理应用过程中变得非常复杂。\n下面先简要介绍 Clash 的代理分流过程，以及发起 DNS 请求的原因。\nClash 系统代理流程 Clash 的分流是基于规则匹配的，详情请阅读 clash 官方文档 。一般来说规则文件都按照下面的形式组织：\nport：监听端口\nproxies：出站节点，也就是代理服务器\nproxy-groups：节点组，每个节点组可以有多个节点或者策略组，根据 type 选择默认节点。\nrules：分流规则，基于域名或者 IP 匹配。规则将按照从上到下的顺序匹配，列表顶部的规则优先级高于其底下的规则。部分规则如下：\nDOMAIN：匹配完整域名；\nDOMAIN-SUFFIX：匹配域名后缀；例：google.com​匹配www.google.com​/mail.google.com​和google.com​,但不匹配content-google.com​\nDOMAIN-KEYWORD：使用域名关键字匹配\nIP-CIDR \u0026amp; IP-CIDR6：匹配 IP 地址范围，IP-CIDR​和IP-CIDR6​效果是一样的，IP-CIDR6​为是 IPV6 地址\nGEOIP：匹配 IP 所属国家代码\nSRC-IP-CIDR：匹配来源 IP 地址范围\nPROCESS-NAME：使用进程匹配，在Android​平台可以匹配包名\nMATCH：匹配所有请求，无需条件\n根据上述规则，当我们使用浏览器通过系统代理访问 www.google.com​ 时，源 IP 地址为 127.0.0.1​，域名为 www.google.com​。则从上倒下依次根据规则进行判断：\n​DOMIN,google.com,节点组1​：不匹配，www.google.com​不是google.com​\n​DOMIN-SUFFIX,youtube.com,节点组1​：不匹配，不是youtube.com​结尾\n​DOMIN-KEYWORD,youtube,节点组1​：不匹配\n​DOMIN,ad.com,REJECT​：不匹配，ad是广告，直接拒绝回应。\n​SRC-IP-CIDR,192.168.1.201/32,DIRECT​ ：源 IP 地址为 127.0.0.1​，不匹配\n​IP-CIDR,127.0.0.0/8,DIRECT,no-resolve​：这里特殊，这里匹配的是 IP 网段，当访问的是 127.0.0.0/8​ 网段，就走直连。但我们匹配的是 www.google.com​ 域名，无法直接和 IP 进行匹配，因为需要先获取 IP 地址，才能进行匹配。但这里又加了 no-resolve​，表示不进行 DNS 解析。因此这里直接跳过。\n​IP-CIDR6,2620::7/32,节点组1,no-resolve​：和上一条一样。也跳过\n​GEOIP,CN,DIRECT​：GEOIP​ 是一个常见 IP 归属地分类数据库，如果是国内的 IP，就直连。由于后面没有加 no-resolve​，所以要将域名解析为 IP 地址。而这里没有配置内置 DNS 模块，因此，采用本地 DNS 解析。这时，构建的就是明文的 DNS 解析请求，就会造成 DNS 泄漏。请求一个被墙的域名，返回的大概率是一条非国内的被污染的 IP。这时也不匹配这条规则。\n​DST-PORT,80,DIRECT​ 和 SRC-PORT,7777,DIRECT​ 对目的和源端口进行匹配。这里也不匹配。\n​PROCESS-NAME,curl,节点组2​：匹配进程，如果是 curl 发起的，则交给节点组2。也不匹配。\n因为所有规则都不匹配，所以 Clash 还有一个兜底的规则，所有不匹配的规则都交给 MATCH​ 处理。所以这一条访问 www.google.com​ 的请求，会被交给节点组1，也就是香港节点。这里需要注意，刚刚发起的 DNS 请求获取的 IP 只是用于进行规则匹配，不会用于发给香港节点。香港节点收到的还是域名，因此，香港节点收到后还是会发起 DNS 请求获取到正确的 IP。\n​​\n解决方案 下面两种方案仅适用于系统代理模式下。\n白名单模式 刚刚的流程中，发生 DNS 泄漏是因为基于 IP 的规则匹配，没有加 no-resolve​ 而发起了 DNS 请求。那么我们就给所有基于 IP 的规则匹配都加上 no-resolve​。\n但这样会导致国内网站域名跳过 GEOIP,CN,DIRECT,no-resolve​ 规则，而走代理节点。这肯定是不对的。所以不仅需要给所有基于 IP 的规则匹配都加上 no-resolve​，还需要在 GEOIP​ 之前加上国内域名走直连的规则。\n这样大部分国内的网站都能正常走直连，但还是有一些小众的国内网站不会走直连，需要手动添加。这样的效率最高，实际上就是 v2rayN 的绕过大陆模式。\n在 v2ray 中需要配置：AsIs 匹配模式 + 绕过大陆规则。这种完全可以防止 DNS 泄漏，因为 AsIs 只使用域名匹配，当碰到 GEOIP 这种 IP 规则，直接跳过，不发起 DNS 请求。绕过大陆规则就是所有大陆域名放在前面，直接走直连。而国外域名或者没有在大陆规则中的，就全部走代理。\n​​\n黑名单模式 我们还可以把国外的域名放在最开始解析，以匹配代理节点，这样就不会到后续的 GEOIP​ 也就不会造成 DNS 泄漏了。\n不论黑名单还是白名单，在使用 ipleak.net​ 时，由于是随机域名，最终肯定会进行 GEOIP​ 匹配，因此会发起 DNS 请求，这种情况下，就会检测到国内的 DNS 提供商。不过我们需要访问的国外域名不会出现 DNS 泄漏，所以这样的情况也不能完全算是 DNS 泄漏。\n​​\n在 v2ray 中需要配置：IPIfNoMatch 匹配模式 + 黑名单。这样当黑名单中的国外域名出现时，会走代理。而国内以及小众国外域名还是会 DNS 请求。\n总结 在系统代理模式下，上述两种方式已经足够使用，目标网站的 DNS 是不会泄漏的。对于通常意义上的使用场景来说已经够用。但之前也说过，TUN，软路由这种代理模式应用的最广泛，针对这些场景下的 DNS 泄漏，解决就麻烦一些。\nTUN、软路由模式下的代理流程 和系统代理模式的主要区别，是配置了 DNS 模块，接管了系统 DNS 解析模块。下面是 Clash.Meta 的 DNS 工作流程，忽略了 Clash 内部的 DNS 映射处理。\n参考：Clash 官方 DNS 解析流程\nflowchart TD Start[客户端发起请求] --\u003e rule[匹配规则] rule --\u003e Domain[匹配到基于域名的规则] rule --\u003e IP[匹配到基于 IP 的规则] Domain --\u003e |域名匹配到直连规则|DNS IP --\u003e DNS[通过 Clash DNS 解析域名] Domain --\u003e |域名匹配到代理规则|Remote[通过代理服务器解析域名并建立连接] Cache --\u003e |Redir-host/FakeIP-Direct 未命中|NS[匹配 nameserver-policy 并查询 ] Cache --\u003e |Cache 命中|Get Cache --\u003e |FakeIP 未命中,代理域名|Remote NS --\u003e |匹配成功| Get[将查询到的 IP 用于匹配 IP 规则] NS --\u003e |没匹配到| NF[nameserver/fallback 并发查询] NF --\u003e Get[查询得到 IP] Get --\u003e |缓存 DNS 结果|Cache[(Cache)] Get --\u003e S[通过 IP 直接/通过代理建立连接] DNS --\u003e Redir-host/FakeIP Redir-host/FakeIP --\u003e |查询 DNS 缓存|Cache Clash.Meta 支持两种 DNS 配置模式：redir-host 和 fake-ip。redir-host 模式是最初大家使用的一种模式，和 fake-ip 的区别在于 redir-host 模式必须返回一个真实的 IP 地址，因此必须要进行 DNS 查询。而 fake-ip 返回的都是私有的 fake 地址，也就是假地址，因此最开始时不需要 DNS 查询。\n下面根据上述流程图，简单介绍 Clash 中的 TUN 模式的代理行为。\n和系统代理模式相比，TUN 多了一个 DNS 模块的配置。需要配置 DNS 模块的模式 enhanced-mode​ 和域名服务器 nameserver​。\n在网络通过过程中，应用程序，例如浏览器，发起网站访问时首先发起 DNS 请求，获取 IP 地址。Clash 将劫持 DNS 请求，并通过配置的 DNS 模块来处理。下面分别简化介绍 redis-host 和 fake-ip 模式下的 DNS 处理过程。和 Clash.Meta 中的过程稍有不一致，但整体一致。\n解决方案1：redis-host 以下图中的配置为例，浏览器访问域名 google.com​：\n​​\n在 redis-host 模式中，要求必须返回一个真实 IP。所以会同时向 nameserver​ 中定义的三个域名服务器发起 DNS 请求，以最快返回的 DNS 响应为准，这里大概率会得到一个被污染的 IP，假设是 5.5.5.5​。Clash 将保存域名 google.com​ 和 IP 5.5.5.5​ 的映射的关系。\n浏览器会使用这个 IP 发起 http 请求。http 请求会再次被 Clash 捕获，并根据映射表判断是想访问 google.com​。此时 Clash 就根据 rules​ 路由规则进行域名匹配。\n​google.com​直接匹配第一条规则，则会被交给节点组1 的香港节点处理。这里要注意，交给节点的仍然是google.com​域名，香港节点收到后，还会再次发起 DNS 请求来获取真正的 IP 进行访问。\n所以，redis-host 模式由于必须返回真实 IP，就必然发起 DNS 请求，必然产生 DNS 泄漏。\n这里还有另外一个问题：由于本地发起 DNS 请求会得到被污染的 IP 地址，很有可能会造成两个不同的域名被污染到同一个地址的情况，或者两个不同的域名就是被搭建在同一个服务器上。此时 Clash 就无法确认访问的是哪一个域名了。Clash 遇到这种情况将直接发送污染 IP，而不进行远程 DNS。远程节点服务器拿到数据包后，直接访问被污染 IP，肯定不能正常访问，还有可能出现访问 A 网站，而返回的是 B 网站的现象，并由于证书不一致，浏览器发出警告。之前就遇到过访问 google，返回的却是 facebook 的现象。\n​​\n解决这个问题，有两种方案：\n使用域名嗅探功能，直接 http 协议中找出需要访问的域名。这样即便映射表中有相同的 IP，也能找出需要访问的具体网站域名，从而使用远程 DNS 解析。\n在 DNS 配置中添加一个 fallback​ 配置，存放不会被污染的 DNS 服务器，一般是经过加密的 DoT 或者 DoH 服务器。在最初发起 DNS 请求时，同时向 nameserver​ 和 fallback​ 中的 DNS 服务器发起 DNS 请求。如果 nameserver​ 上游 DNS 返回的不是国内 IP，则直接使用 fallback​ 中返回的 IP 地址，确保国外 IP 不被污染。这里有一个注意点：向 fallback​ 发起 DNS 查询的主机的地理位置，将影响 DNS 返回的 IP。DNS 会选择一个离发起 DNS 主机最近位置的服务器 IP。在 clash 中即使是 fallback​ 也通过本机发起 DNS 请求，这就导致返回的 IP 并不是离代理节点服务器最近的位置，造成速度负优化。但 clash.meta 中已经修改。\n但国内访问国外 DoH/DoT 体验很差，间歇性被墙，且需要握手、加密速度也比较慢。\n由于 redis-host 在使用过程中，接连出现的问题，clash 在一次更新中彻底除去 redis-host 模式，转而只支持 fake-ip。而 clash.meta 通过加入流量嗅探解决了 redis-host 的 DNS 污染问题。\n解决方案2：fake-ip IOS 端的代理软件都是用的 fake-ip 模式，v2ray 也有类似功能叫作 fake DNS。\n​​\n以下图中的配置为例，浏览器访问域名 google.com​：\n​​\n在 fake-ip 模式中，所有应用的 DNS 请求全部返回一个虚拟的 IP，也就是 fake-ip-range​ 中的私有地址中分配的一个。假设返回的是 198.18.0.3​。Clash 将保存域名 google.com​ 和 IP 198.18.0.3​ 的映射的关系。\n浏览器会使用这个 IP 发起 http 请求。http 请求会再次被 Clash 捕获，并根据映射表判断是想访问 google.com​。此时 Clash 就根据 rules​ 路由规则进行域名匹配。\n​google.com​直接匹配第一条规则，则会被交给节点组1 的香港节点处理。这里要注意，交给节点的仍然是google.com​域名，香港节点收到后，还会再次发起 DNS 请求来获取真正的 IP 进行访问。\n所以 fake-ip 模式，本地并不需要进行 DNS 解析，也就不存在 DNS 泄漏。还解决了 DNS 污染中，多域名指向统一 IP 的问题，因为每一个 fake ip 都由 clash 控制。\n但这不意味着 fake-ip 永远不会发起 DNS 查询。因为在 rules 的路由匹配规则中，一定会有 GEOIP 规则，当我们访问 ipleak.net​ 时，一定会走到这里，此时仍然会向 nameserver​ 和 fallback​ 中的 DNS 服务器发起 DNS 请求。所以在这里，ipleak.net​ 仍然会返回多家 DNS 提供商。\n这就和系统代理模式下的 DNS 泄漏一样，关键目标网站并没有泄漏。\nfake-ip 虽然可以一定程度上解决 DNS 泄露和 DNS 污染，但是也有自己的问题。比如：当已经访问了网站 www.baidu.com​ 并缓存了假 IP，此时 clash 异常退出，电脑仍然缓存的是假 IP，此时就无法访问 www.baidu.com​。即便 clash 将 DNS 响应的缓存 TTL 设置为 1 秒，但应用程序并不一定会遵循 DNS 响应的 TTL 设置，可能会延长缓存时间来防止频繁 DNS 查询。还有一些程序会开启 DNS 重绑保护，当发现 DNS 获取的是一个私有 IP，或认为出现 DNS 劫持而被丢弃。就比如 windows 系统使用 fake-ip 出现联网图标显示没网的情况。在 Linux 上也同理。解决方法是将 windows 的 test 联网的网址，放在 fake-ip-filter​ 中，放在其中的域名不会获取 fake-ip 而是会发起 DNS 请求，获取真实的 IP。相当于回退到 redir-host 模式。也可以通过 \u0026quot;+.*\u0026quot;​ 通配符将所有的网站添加到 fake-ip-filter​ 回退，此时就处于 redir-host 模式了。\n还有 Ping 命令失效的问题，因为都是 fake-ip 所以 ping 命令全部都由 clash 的虚拟网卡返回。\nWindows 测试是否联网的网址为：www.msftconnecttest.com 和 www.msftncsi.com。参考：github.com/Loyalsoldier/v2ray-rules-dat/issues/136\n在 Manjaro 中，测试是否联网的网址如下：\n1 2 3 sudo cat /lib/NetworkManager/conf.d/20-connectivity.conf  ✔ [connectivity] uri=http://ping.manjaro.org/check_network_status.txt 另外，udp 在一定场景下，必须使用真实的 IP，所以 fake-ip 下 udp 流量都会发起 DNS 请求。比如基于 UDP 的 QUIC 协议，也就是 HTTP3。可以在浏览器中，禁用该功能。\nchrome://flags/#enable-quic\n​​\n总结 通过解析代理网络的 DNS 请求行为以及代理网络的通信流程，结合已有的 clash 模式，可以正确的配置 DNS 模块来防止 DNS 泄漏或者污染。\nDNS 污染导致无法正常访问网站，DNS 泄漏导致一些严格地区的网站无法访问。\n通常系统代理模式下的 DNS 泄漏容易解决，使用白名单或者黑名单加上对应的路由匹配模式，就可以解决。\n而对于 TUN 模式下，或者软路由，这种接管了系统 DNS 的模式，就需要手动配置 DNS 模块，并根据 代理模式（redir-host 或者 fake-ip）来决定是否开启流量嗅探，以及是否配置 DNS代理。\nredir-host + 流量嗅探 + DNS 代理可以完美解决 DNS 泄漏，但是速度会慢。\nfake-ip + 合理路由规则 一定程度上解决 DNS 泄漏，但是速度较快。\nfake-ip 也可以使用 DNS 代理解决 DNS 泄漏。相比于 redir-host 减少了一次 DNS 请求，因此也还是更快。\n但 fake-ip 由于使用的是虚拟 IP，在使用 ping 命令，或者一些检测 DNS 劫持的软件就不能使用了。\n‍\n参考：【进阶•DNS系列视频】\n‍\n‍\n","date":"2024-11-03T15:46:40+08:00","permalink":"https://codetang-2417.github.io/p/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E5%8F%8A-dns-%E6%B3%84%E6%BC%8F%E7%AE%80%E6%9E%90/","title":"网络原理及 DNS 泄漏简析"},{"content":"　QEMU开源软件在Linux上进行开发。在windows上可以采用WSL Linux，也可以自行在电脑上安装Linux原生系统。一般采用vscode作为IDE 开发QEMU。\n本文采用 vscode 连接校内 ubuntu 服务器的方式进行开发环境搭建。ubuntu服务器多人使用，采用docker 容器建立各自独立的开发环境。\ndocker环境 使用docker启动作为编译的系统环境。可以将 docker 视作轻量级虚拟机，先创建 docker镜像，再以镜像为基础启动容器。每一个容器视作虚拟机，系统环境数据存在容器中，工作文件夹等需要保存在硬盘上的重要文件，以共享文件夹的方式映射到容器。镜像不保存任何运行数据。\ndockfile 创建名为 Dockerfile​ 的文件，并填入下列内容。并可以根据自行需要（用户\\组 id，软件依赖等），增删其中的内容。\n注意：存放 Dockerfile​ 的文件夹中最好不要存放任何其他无关的文件，在创建镜像时，docker 会将该文件夹中的所有内容都复制到容器中，这会大大增加镜像创建的时间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 FROM ubuntu:24.04 # 定义构建时变量，可以在docker build构建通过--build-arg来修改 ARG GID=1000 ARG UID=1000 ARG username=developer # 设置 DEBIAN_FRONTEND 环境变量以避免交互式对话框，否则可能会卡在一些交互式输入中 ENV DEBIAN_FRONTEND=noninteractive # 修改ubuntu的镜像源为阿里云 # ubuntu24.04版本修改软件源的位置：/etc/apt/sources.list 替换为 /etc/apt/sources.list.d/ubuntu.sources RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list.d/ubuntu.sources \\ \u0026amp;\u0026amp; sed -i s@/security.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list.d/ubuntu.sources \\ \u0026amp;\u0026amp; apt-get update -y \u0026amp;\u0026amp; apt-get install -y sudo locales \\ \u0026amp;\u0026amp; apt-get clean \\ \u0026amp;\u0026amp; echo \u0026#34;%sudo ALL=(ALL) NOPASSWD:ALL\u0026#34; \u0026gt;\u0026gt; /etc/sudoers # 修改容器或系统中的 sudoers 文件，允许属于 sudo 组的用户执行 sudo 命令时无需输入密码。 # 修改语言环境（locale）设置 RUN locale-gen en_US.UTF-8 \u0026amp;\u0026amp; update-locale # 添加用户：赋予sudo权限，指定密码123，建议docker的密码不要太复杂，太多了很容易忘记。 # 注：用户id和组id尽可能的和当前用户id一致，使得读写共享文件时的权限一致，否则可能出现docker无法写入共享文件的问题。 # 命令 id 可以查看用户的各种id RUN getent group ${GID} || groupadd -g ${GID} dev \\ \u0026amp;\u0026amp; getent passwd ${username} || useradd -ms /bin/bash -u ${UID} -g ${GID} -G sudo ${username} \\ \u0026amp;\u0026amp; echo \u0026#34;${username}:123\u0026#34; | chpasswd \\ \u0026amp;\u0026amp; echo \u0026#39;root:123\u0026#39; | chpasswd # 安装各种以依赖软件，可以根据需要定制，也可以后续手动安装。 # QEMU编译需要的依赖 RUN apt-get install -y build-essential meson ninja-build pkg-config \\ diffutils python3 python3-venv \\ libglib2.0-dev libusb-1.0-0-dev libncursesw5-dev \\ libpixman-1-dev libepoxy-dev libv4l-dev libpng-dev \\ libsdl2-dev libsdl2-image-dev libgtk-3-dev libgdk-pixbuf2.0-dev \\ libasound2-dev libpulse-dev \\ libx11-dev libfdt-dev libiscsi-dev # riscv-gnu-toolchain 需要的依赖 RUN apt-get install -y autoconf automake autotools-dev curl \\ python3 python3-pip libmpc-dev libmpfr-dev libgmp-dev gawk build-essential \\ bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev \\ ninja-build git cmake libglib2.0-dev libslirp-dev RUN apt-get install -y git gdb clang cmake vim gdb # 还原 DEBIAN_FRONTEND 环境变量（可选） ENV DEBIAN_FRONTEND=dialog # 指定容器启动后的工作目录 WORKDIR /home/${username} # 指定容器启动后的登录用户 USER ${username} 创建镜像 基础构建\n1 docker build -t tc-qemu . 其中 -t​ 后跟镜像名称，可任意更改。docker build -t tc-qemu .​ 这条命令会从当前目录（.​）中寻找 Dockerfile​，然后根据其中的指令构建一个名为 tc-qemu​ 的 Docker 镜像。\n若在创建镜像时希望动态修改 Dockerfile​ 中的ARG参数，则在构建时，添加参数 --build-arg ARG_name=value​ ，将 ARG_name​ 修改为 value​。\n由于每个用户 id 和组 id 不一样，需要在终端中运行命令id​查询到当前用户的group和user id，并在构建时修改参数：\n1 docker build --build-arg GID=1004 --build-arg UID=1004 -t tc-qemu . 修改用户 id 和组 id 和当前的账户一致，是为了确保在写入共享文件夹的时候有相同的权限，否则可能造成在容器中无法正常写入的情况。\n创建容器 下面的命令创建一个名为 tc_qemu_dev 的容器，并将主机的文件夹 /home/tiancheng.tang/Desktop/work/​ 共享到容器中的 /home/developer/work​ 文件夹。\n1 docker run -it --name tc_qemu_dev --mount type=bind,source=/home/tiancheng.tang/Desktop/work/,target=/home/developer/work tc-qemu 注：如果需要使用代理网络，可以通过ssh隧道将流量代理到本机（例如：个人Linux主机通过SSH隧道使服务器访问外网），在创建容器时添加参数--network host​，让docker位于host网络中。\n1 docker run -it --network host --name tc_qemu_dev --mount type=bind,source=/home/tiancheng.tang/Desktop/work/,target=/home/developer/work tc-qemu 在设置代理时，可以手动设置 export http_proxy=\u0026quot;localhost:7897\u0026quot; export https_proxy=\u0026quot;localhost:7897\u0026quot;​，也可以在启动容器时，添加参数直接设置代理环境 -e HTTP_PROXY=http://localhost:7897​\n1 docker run -it --network host -e HTTP_PROXY=http://localhost:7897 -e HTTPS_PROXY=http://localhost:7897 --name tc_qemu_dev --mount type=bind,source=/home/tiancheng.tang/Desktop/work/,target=/home/developer/work tc-qemu 上述命令的含义自行询问GPT或者查询网络。\nQEMU 源码 QEMU 是一个大型开源软件，会不断的发布稳定版本，并在 master 主分支上不断更新新的功能。为了便于对旧版本进行维护、修复和发布更新，QEMU 为每一个稳定版本都创建了 stable 分支，并会不断的维护。\n本文以 qemu 9.0 分支版本作为基础，进行开发。\n官方源码仓库：github.com/qemu/qemu.git\n官方仓库 fork 到私人仓库 以 gitee 为例\n​​\n将私人仓库 clone 到本地：\n1 git clone https://gitee.com/code-tang/qemu-sayram2.0.git 私人仓库建立工作分支 在稳定分支 9.0 基础上，在本地新建新分支 sayram2​、sayram2-dev​，并将本地新建的两个分支 push 远程仓库。\n1 2 3 4 5 git fetch origin stable-9.0:sayram2 git push --set-upstream origin sayram2 git checkout -b sayram2-dev git push --set-upstream origin sayram2-dev 然后查看本地分支情况：\n1 2 3 4 $ git branch -v master 58d49b5895 Merge tag \u0026#39;net-pull-request\u0026#39; of https://github.com/jasowang/qemu into staging sayram2 6a54d5cf55 Update version for 9.0.3 release * sayram2-dev 6a54d5cf55 Update version for 9.0.3 release 其中，sayram2-dev​ 作为开发分支，开发稳定后，merge 到稳定分支 sayram2​ 中。若后续官方的 stable-9.0​ 分支出现重大更新，可将其 pull 到本地，和 sayram2​、sayram2-dev​两个分支进行 merge​。\n注意：需要更新官方仓库时，不要在仓库点击强制同步，这样会覆盖仓库代码。\n​​\n若要更新官方仓库，需在本地添加官方 github 仓库源，并 pull 代码到对应的分支，完成 merge 工作后，再推送到私有仓库。\n1 2 3 git remote add official https://github.com/qemu/qemu.git git checkout sayram2-dev git pull official stable-9.0 --rebase 执行该命令后，本地分支将基于 official​ 的 stable-9.0​ 分支的最新提交进行变基，相当于先将远程的更改应用在当前分支上，再重新应用本地的更改，从而避免出现合并提交。出现冲突需要手动解决。\n如果后续 stable-9.0 出现更新，并希望将更新应用到 sayram2 分支，则可以直接 pull stable-9.0。\n1 2 git checkout sayram2 git pull official stable-9.0 常规编译流程 参考官方文档：www.qemu.org/docs/master/devel/build-system.html\n一般的开发仅关注于源码，不会对编译脚本做过多改动。\n从源码编译 qemu 总共两步：1. configure 2. build\nconfigure\n1 2 cd qemu ./configure --target-list=riscv32-softmmu --enable-debug 关于 configure​ 的更多选项可以参考 ./configure --help​ 的输出。\n1 2 3 4 5 6 7 8 9 10 11 developer@ubuntu-AS-4124GS-TNR:~/work/qemu/qemu-official$ ./configure --help Using \u0026#39;./build\u0026#39; as the directory for build output Usage: configure [options] Options: [defaults in brackets after descriptions] Standard options: --help print this message --target-list=LIST set target list (default: build all) Available targets: aarch64-linux-user aarch64_be-linux-user alpha-linux-user build\n可以使用 make 和 ninja 进行编译，两者都行。区别是 ninja 自动开启多线程加速编译，而 make 需要手动加上参数 -j​。\n1 2 3 4 5 6 cd build ninja or cd build make -j 个人喜欢用 ninja，输出的编译信息不会占满整个屏幕。\nvscode远程开发项目 vscode 实际上就是一个编辑器，但是可以通过各种插件将其变为一个IDE。例如远程开发功能，vscode 需要安装扩展：Remote - SSH​、 Dev Containers​。vscode 可以运行在任意电脑上，通过远程网络连接到同一个工作服务器上开发。\nSSH连接服务器 ​​\n新建远程后，会在顶部弹出界面，提示输入 ssh 连接命令。如图所示输入账号和ip地址\n​​\n顶部会弹出选项框，要求选择一个配置文件，保存当前连接的服务器信息。选择第一个即可。\n​​\n​​\n这里的配置文件可以后续再进行修改，其中 Host​ 表示 ssh 服务器名称，可以任意更改，Hostname​ 保存服务器 ip地址， User​ 保存用户名。\n然后远程资源管理器会更新输入的服务器信息。\n​​\n点击连接按钮后，顶部弹出输入密码。\n​​\n首次连接，或者更新 vscode 后，服务器会下载 vscode 服务器，需要一定时间。\n​​\nvscode连接容器 当安装完 Dev Containers​ 扩展后，远程资源管理器会多一个开发容器的选项。\n​​\n已经连接的容器会显示在 开发容器​ 这一栏，没有连接过的容器显示在 其他容器​ 这一栏。和 SSH 同理，点击容器连接即可，不需要输入密码。\n​​\n连接后，所有的开发环境都存在于 docker 容器，在本文创建镜像时，共享了主机的 work​ 目录，因此，将代码存放于该目录。\nvscode 中调试 vscode 只是编辑器，还需要配置 task.json​ 调试文件，和 launch.json​ 文件来决定调试需要运行的文件，调试工具的位置等。\nqemu 在 Linux 上的调试文件如下：\n​.vscode/launch.json​：调试文件，F5快捷键进入调试模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ {//\u0026#34;-init_data\u0026#34;,\u0026#34;${workspaceFolder}/Hmatrix0.dat \u0026#34;ultichip-u1,pipeline=true\u0026#34;,\u0026#34;, //配置编译./configure --enable-debug --target-list=riscv32-softmmu //配置编译./configure --enable-debug --disable-werror --target-list=riscv32-softmmu \u0026#34;name\u0026#34;: \u0026#34;(gdb) Launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/build/qemu-system-riscv32\u0026#34;, // QEMU 启动时的参数，需要根据需要，自行调整。 \u0026#34;args\u0026#34;: [\u0026#34;-machine\u0026#34;, \u0026#34;ub\u0026#34;, \u0026#34;-cpu\u0026#34;, \u0026#34;ultichip-u1,pipeline=true\u0026#34;, \u0026#34;-bios\u0026#34;, \u0026#34;\u0026#39;\u0026#39;\u0026#34;, \u0026#34;-m\u0026#34;, \u0026#34;128M\u0026#34;,\u0026#34;-d\u0026#34;,\u0026#34;in_asm\u0026#34;, \u0026#34;-display\u0026#34;, \u0026#34;none\u0026#34;, \u0026#34;-ulog\u0026#34;, \u0026#34;./test_sayram/outlog/runtime.log\u0026#34;, \u0026#34;-rlog\u0026#34;, \u0026#34;./test_sayram/outlog/reg.log\u0026#34;,\u0026#34;-savedmem\u0026#34;,\u0026#34;./test_sayram/outlog/dmemory.dat\u0026#34;,\u0026#34;-nographic\u0026#34;,\u0026#34;-kernel\u0026#34;, \u0026#34;./test_sayram/input/dl/vp0\u0026#34;, \u0026#34;-device\u0026#34;, \u0026#34;loader,file=./test_sayram/input/dl/qemu_indmem.bin,addr=0x17b40\u0026#34;, \u0026#34;-lbr\u0026#34;, \u0026#34;32\u0026#34;], \u0026#34;stopAtEntry\u0026#34;: true, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;:\u0026#34;PATH\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;%PATH%;\\bin\u0026#34; } ], //\u0026#34;console\u0026#34;: \u0026#34;externalTerminal\u0026#34;, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;miDebuggerArgs\u0026#34;: \u0026#34;-q -ex quit; wait() { fg \u0026gt;/dev/null; }; /bin/gdb -q --interpreter=mi\u0026#34;, // \u0026#34;miDebuggerPath\u0026#34;: \u0026#34;F:/msys/mingw64/bin/gdb.exe\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true } ], \u0026#34;preLaunchTask\u0026#34;: \u0026#34;build\u0026#34;, } ] } ​.vscode/task.json​：编译任务，决定如何编译项目\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, // 手动运行一次：./configure --enable-debug --target-list=riscv32-softmmu --disable-werror \u0026#34;command\u0026#34;: \u0026#34;cd build; ninja; cd ..\u0026#34;, \u0026#34;problemMatcher\u0026#34;: [], \u0026#34;group\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;isDefault\u0026#34;: true } } ] } ‍\n","date":"2024-10-30T19:57:03+08:00","permalink":"https://codetang-2417.github.io/p/qemu%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"QEMU开发环境搭建"},{"content":"　QEMU 9.1.50 版本为例。\n数据结构及初始化 QEMU 在 softmmu/vl.c​ 文件中定义了 QEMUOption​ 结构体来描述不同的命令行参数，其代码如下：\n1 2 3 4 5 6 typedef struct QEMUOption { const char *name; int flags; int index; uint32_t arch_mask; } QEMUOption; 其中 name​ 表示参数名称，flags​ 表示参数属性，为 1 表示拥有子参数，为 0 则表示无子参数，index​ 表示命令索引 (QEMU_OPTION_cmd)，arch_mask​ 表示参数支持的架构。在 softmmu/vl.c​ 文件中还定义了一个全局 QEMUOption​ 数组 qemu_options​ 来描述 QEMU 的全部可用参数，具体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 enum { #define DEF(option, opt_arg, opt_enum, opt_help, arch_mask) \\ opt_enum, #define DEFHEADING(text) #define ARCHHEADING(text, arch_mask) #include \u0026#34;qemu-options.def\u0026#34; }; static const QEMUOption qemu_options[] = { { \u0026#34;h\u0026#34;, 0, QEMU_OPTION_h, QEMU_ARCH_ALL }, #define DEF(option, opt_arg, opt_enum, opt_help, arch_mask) \\ { option, opt_arg, opt_enum, arch_mask }, #define DEFHEADING(text) #define ARCHHEADING(text, arch_mask) #include \u0026#34;qemu-options.def\u0026#34; { /* end of list */ } }; 可以看到，qemu_options​ 数组中首先定义了一个参数 h​，其使用方法为 qemu-system-riscv64 -h​，作用是打印帮助信息。其余所有的可用参数都都通过 DEF​ 宏定义在 \u0026lt;qemu_build_dir\u0026gt;/qemu-options.def​ 文件中。需要注意的是，qemu-options.def​ 文件是由 scripts/hxtool​ 脚本在编译时根据 qemu-options.hx​ 文件生成的，因此不在 QEMU 源代码目录中。\n这里需要说明一下，在 QEMU 中常用的一种编程方式：将可重复利用的配置信息通过宏定义的方式放在一个文件中，在正式使用时，通过重新定义宏来实现同一个配置信息文件生成不同结构体或数组的功能。例如需要定义的 qemu_options​ 静态数组和各个选项的 enum​类型，其中对 DEF​ 宏进行了重新定义，并包含了同一个文件 \u0026ldquo;qemu-options.def\u0026rdquo;，但由于 DEF​ 两次定义的内容不同，最终生成的数据结构不同。实现一次配置，多次重复利用。\n​QEMUOption​ 只定义了每一个大选项的名称、是否有子选项、支持的体系结构，但并没有定义子选项。子选项则是由文件 include/qemu/option_int.h​ 中定义的两个结构体 QemuOpt​、QemuOpts​进行描述。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct QemuOpt { char *name; char *str; const QemuOptDesc *desc; union { bool boolean; uint64_t uint; } value; QemuOpts *opts; QTAILQ_ENTRY(QemuOpt) next; }; struct QemuOpts { char *id; QemuOptsList *list; Location loc; QTAILQ_HEAD(, QemuOpt) head; QTAILQ_ENTRY(QemuOpts) next; }; ​QemuOpt​ 保存每一个子选项的具体信息，每一个子选项会通过 TailQueue​ 连接成一个双向尾队列 QemuOpts​。因此，也可以将 QemuOpt​ 视作 QemuOpts​ 中的一个队列节点。其中所定义的 QTAILQ_ENTRY​ 是和 TailQueue​ 相关的数据结构，关于 TailQueue​ 的详细信息可查看 QEMU中的队列queue。\n​QemuOpts​ 是大选项中各个子选项的动态集合。QemuOpts​中保存的QTAILQ_HEAD(, QemuOpt) head;​ 是 QemuOpt​ 队列的头节点，能够访问所有的 QemuOpt​。\n以 -device​ 大选项为例，QEMU 中 -device​ 表示设备，设备有非常多种，每一种都是独立的，且可以重复添加。一个 QemuOpts​ 只能保存一种设备的子选项集合。那么多个相同种类的设备，但是参数不同，如何保存？这就需要再引入一个数据结构 QemuOptsList​，QemuOptsList​ 也是一个 TailQueue​，保存 QemuOpts​ 的集合。\n1 2 3 4 5 6 7 struct QemuOptsList { const char *name; const char *implied_opt_name; bool merge_lists; /* Merge multiple uses of option into a single list? */ QTAILQ_HEAD(, QemuOpts) head; QemuOptDesc desc[]; }; 每一个 QemuOptsList​ 代表了大选项，QemuOptsList​ 中的每一个 QemuOpts​ 代表一类设备，由大选项中的子选项集合组成。\n​​\n下图给出完整体的数据结构的实例，将 QemuOptsList​ 中的数据结构和 QemuOpts​ 分开绘制，并在 QemuOpts​ 给出了 TailQueue​ 的细节，结合 QEMU中的队列queue 理解更佳。\n​​\nQEMU 在 util/qemu-config.c​ 中定义了一个全局的 QemuOptsList​ 数组 vm_config_groups​ 来储存所有可用的参数（即上图中提到的数组 vm_config_groups​）：\n1 2 static QemuOptsList *vm_config_groups[48]; static QemuOptsList *drive_config_groups[5]; 这两行代码说明了 QEMU 最多支持 48 个参数，5 个驱动器参数。这两个全局数组由位于 softmmu/vl.c​ 文件的 qemu_init​ 函数负责初始化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 qemu_add_opts(\u0026amp;qemu_drive_opts); qemu_add_drive_opts(\u0026amp;qemu_legacy_drive_opts); qemu_add_drive_opts(\u0026amp;qemu_common_drive_opts); qemu_add_drive_opts(\u0026amp;qemu_drive_opts); qemu_add_drive_opts(\u0026amp;bdrv_runtime_opts); qemu_add_opts(\u0026amp;qemu_chardev_opts); qemu_add_opts(\u0026amp;qemu_device_opts); qemu_add_opts(\u0026amp;qemu_netdev_opts); qemu_add_opts(\u0026amp;qemu_nic_opts); qemu_add_opts(\u0026amp;qemu_net_opts); qemu_add_opts(\u0026amp;qemu_rtc_opts); qemu_add_opts(\u0026amp;qemu_global_opts); qemu_add_opts(\u0026amp;qemu_mon_opts); qemu_add_opts(\u0026amp;qemu_trace_opts); qemu_plugin_add_opts(); qemu_add_opts(\u0026amp;qemu_option_rom_opts); qemu_add_opts(\u0026amp;qemu_accel_opts); qemu_add_opts(\u0026amp;qemu_mem_opts); qemu_add_opts(\u0026amp;qemu_smp_opts); qemu_add_opts(\u0026amp;qemu_boot_opts); qemu_add_opts(\u0026amp;qemu_add_fd_opts); qemu_add_opts(\u0026amp;qemu_object_opts); qemu_add_opts(\u0026amp;qemu_tpmdev_opts); qemu_add_opts(\u0026amp;qemu_overcommit_opts); qemu_add_opts(\u0026amp;qemu_msg_opts); qemu_add_opts(\u0026amp;qemu_name_opts); qemu_add_opts(\u0026amp;qemu_numa_opts); qemu_add_opts(\u0026amp;qemu_icount_opts); qemu_add_opts(\u0026amp;qemu_semihosting_config_opts); qemu_add_opts(\u0026amp;qemu_fw_cfg_opts); qemu_add_opts(\u0026amp;qemu_action_opts); 其中，qemu_add_opts​ 和 qemu_add_drive_opts​ 函数的实现位于 util/qemu-config.c​ 文件中，主要负责将参数中传入的 OemuOptsList​ 添加到全局数组中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void qemu_add_drive_opts(QemuOptsList *list) { int entries, i; entries = ARRAY_SIZE(drive_config_groups); entries--; /* keep list NULL terminated */ for (i = 0; i \u0026lt; entries; i++) { if (drive_config_groups[i] == NULL) { drive_config_groups[i] = list; return; } } fprintf(stderr, \u0026#34;ran out of space in drive_config_groups\u0026#34;); abort(); } void qemu_add_opts(QemuOptsList *list) { int entries, i; entries = ARRAY_SIZE(vm_config_groups); entries--; /* keep list NULL terminated */ for (i = 0; i \u0026lt; entries; i++) { if (vm_config_groups[i] == NULL) { vm_config_groups[i] = list; return; } } fprintf(stderr, \u0026#34;ran out of space in vm_config_groups\u0026#34;); abort(); } 命令行参数的解析 在 qemu 中，参数解析在 vl.c​ 中的 qemu_init​ 函数中，参数的解析分为两部分：\n第一部分检查选项是否是 QEMU 中预定义的 QEMUOption​，并初始化 machine_opts_dict​ 数组，根据是否传入了 -no-user-config​ 参数来加载用户配置。 真正解析具体参数并执行相应设置 第一阶段 首先按照下标顺序依次读取终端传入的参数数组，跳过子选项，只解析主选项。通过 lookup_opt​ 函数查询主选项是否是预定义的 QEMUOption​，如果没找到，退出程序，如果找到，则返回找到的 QEMUOption​ 指针。虽然 lookup_opt​ 函数也会保存主选项对应的子选项参数数组的指针到 optarg​，但是第一阶段并不会使用。\n如果在解析主选项过程中，检查到有主选项-no-user-config​，后续就跳过加载用户配置，否则还会加载用户配置。然后会初始化 machine_opts_dict​ 数组，这里的 machine_opts_dict​ 是一个字典结构，主要用于存储终端传入的参数数组中的虚拟机选项和参数，包括 CPU 数量、内存大小、设备配置等。machine_opts_dict​ 的存在使得参数解析机制能够以一种结构化的方式管理和访问虚拟机参数，而不是使用分散的单独变量或者凌乱的数据结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /* first pass of option parsing */ optind = 1; while (optind \u0026lt; argc) { if (argv[optind][0] != \u0026#39;-\u0026#39;) { /* disk image */ optind++; } else { const QEMUOption *popt; popt = lookup_opt(argc, argv, \u0026amp;optarg, \u0026amp;optind); switch (popt-\u0026gt;index) { case QEMU_OPTION_nouserconfig: userconfig = false; break; } } } machine_opts_dict = qdict_new(); if (userconfig) { qemu_read_default_config_file(\u0026amp;error_fatal); } ​lookup_opt​ 函数定义如下，由于qemu_options​定义时，最后一个元素为{ }​，在遍历时发现 popt-\u0026gt;name​ 为空还没有匹配到主选项，就可以认为该主选项非法。lookup_opt​ 函数若匹配到当前的主选项，且主选项有子选项，则将子选项数组的指针保存到 poptarg​ 并返回给上层函数。lookup_opt​ 同时还会将已经遍历的 optind​ 的值也返回给上层函数，表示已经遍历过参数数组的这些参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 static const QEMUOption *lookup_opt(int argc, char **argv, const char **poptarg, int *poptind) { const QEMUOption *popt; int optind = *poptind; char *r = argv[optind]; const char *optarg; loc_set_cmdline(argv, optind, 1); optind++; /* Treat --foo the same as -foo. */ if (r[1] == \u0026#39;-\u0026#39;) r++; popt = qemu_options; for(;;) { if (!popt-\u0026gt;name) { error_report(\u0026#34;invalid option\u0026#34;); exit(1); } if (!strcmp(popt-\u0026gt;name, r + 1)) break; popt++; } if (popt-\u0026gt;flags \u0026amp; HAS_ARG) { if (optind \u0026gt;= argc) { error_report(\u0026#34;requires an argument\u0026#34;); exit(1); } optarg = argv[optind++]; loc_set_cmdline(argv, optind - 2, 2); } else { optarg = NULL; } *poptarg = optarg; *poptind = optind; return popt; } 第二阶段 真正开始解析参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /* second pass of option parsing */ optind = 1; for(;;) { if (optind \u0026gt;= argc) break; if (argv[optind][0] != \u0026#39;-\u0026#39;) { loc_set_cmdline(argv, optind, 1); drive_add(IF_DEFAULT, 0, argv[optind++], HD_OPTS); } else { const QEMUOption *popt; popt = lookup_opt(argc, argv, \u0026amp;optarg, \u0026amp;optind); if (!(popt-\u0026gt;arch_mask \u0026amp; arch_type)) { error_report(\u0026#34;Option not supported for this target\u0026#34;); exit(1); } switch(popt-\u0026gt;index) { case QEMU_OPTION_cpu: ... break; ... default: ... } } } 重新按照下标顺序依次遍历终端传入的参数数组，调用 lookup_opt​ 函数找到对应的 QEMUOption​，然后检查对应选项在当前架构下是否支持，最后使用 switch​ 语句根据 QEMUOption​ 的成员变量 index​ 的不同来执行不同的分支完成具体的设置。需要注意，主选项和子选项是成对出现的，在 lookup_opt​ 函数中也是成对解析，如果发现子选项进入了主循环，则默认为 driver​。\n‍\n参考资料 QEMU 参数解析机制简析 《QEMU/KVM 源码解析与应用》李强，机械工业出版社 ‍\n","date":"2024-10-29T16:41:42+08:00","permalink":"https://codetang-2417.github.io/p/qemu-%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E8%A7%A3%E6%9E%90/","title":"QEMU 命令参数解析"},{"content":"　​include/qemu/queue.h​中的注释如下。该文件通过宏定义的方式，定义了4种数据结构，以及相关的操作。\n四种数据结构分别是：singly-linked list​单向链表、list​双向链表、simple queue​简单队列、tail queue​尾队列。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /* * This file defines four types of data structures: singly-linked lists, * lists, simple queues, and tail queues. * * A singly-linked list is headed by a single forward pointer. The * elements are singly linked for minimum space and pointer manipulation * overhead at the expense of O(n) removal for arbitrary elements. New * elements can be added to the list after an existing element or at the * head of the list. Elements being removed from the head of the list * should use the explicit macro for this purpose for optimum * efficiency. A singly-linked list may only be traversed in the forward * direction. Singly-linked lists are ideal for applications with large * datasets and few or no removals or for implementing a LIFO queue. * * A list is headed by a single forward pointer (or an array of forward * pointers for a hash table header). The elements are doubly linked * so that an arbitrary element can be removed without a need to * traverse the list. New elements can be added to the list before * or after an existing element or at the head of the list. A list * may only be traversed in the forward direction. * * A simple queue is headed by a pair of pointers, one the head of the * list and the other to the tail of the list. The elements are singly * linked to save space, so elements can only be removed from the * head of the list. New elements can be added to the list after * an existing element, at the head of the list, or at the end of the * list. A simple queue may only be traversed in the forward direction. * * A tail queue is headed by a pair of pointers, one to the head of the * list and the other to the tail of the list. The elements are doubly * linked so that an arbitrary element can be removed without a need to * traverse the list. New elements can be added to the list before or * after an existing element, at the head of the list, or at the end of * the list. A tail queue may be traversed in either direction. * * For details on the use of these macros, see the queue(3) manual page. */ 本文主要描述tail queue​，并简单介绍其他三种数据结构。\n​singly-linked list​单向链表 特点：\n由元素组成，每个元素通过单个向前的指针连接。 在列表头部或某个元素之后添加元素效率较高。 移除元素通常需要O(n)时间，因为可能涉及遍历列表以找到元素。 在删除操作较少或数据以后进先出（LIFO）方式增长的场景中最为理想。 适用场景：\n在数据集大且删除操作少的应用中非常有用。 适合堆栈实现，其中元素不断地被推入并从头部弹出。 ​list​双向链表 特点：\n元素是双向链接的，允许轻松移除任何元素而无需完全遍历。 只能向前遍历。 新元素可以在列表的头部或现有元素之前或之后添加。 适用场景：\n适合频繁插入和从列表任何部分删除的应用。 在需要快速访问和修改数据且不希望遍历列表带来性能损失的场景中常用。 ​simple queue​简单队列 特点：\n由两个指针头部，一个指向列表的头部，另一个指向尾部。 元素单向链接，这意味着节省空间，但只允许从头部移除。 支持在列表的末尾或现有元素之后添加元素。 适用场景：\n适合队列实现，其中元素在尾部入队，在头部出队（先进先出，FIFO）。 在主要是追加操作或元素按到达顺序处理的情况下非常有用。 ​tail queue​尾队列 特点：\n类似于简单队列，但元素是双向链接的。 允许移除任何元素而无需遍历整个列表。 元素可以在列表的头部或尾部添加或移除，列表可以向任一方向遍历。 适用场景：\n在需要频繁在列表两端插入和删除的情况下非常灵活。 理想用于实现双端队列（deque），在两端高效添加或删除数据。 在QEMU中tail queue​被大量使用。\ntail queue​数据结构形式 QTailQLink 文件include/qemu/queue.h​中定义了tail queue​最重要的数据结构QTailQLink​，这是一个内部结构，被QTAILQ_HEAD​和QTAILQ_ENTRY​使用。主要目的在于尽可能不影响自定义数据结构的同时，将数据结构联系起来。\n1 2 3 4 typedef struct QTailQLink { void *tql_next; struct QTailQLink *tql_prev; } QTailQLink; ​QTailQLink​定义的tql_next​类型为void *​，其作用是指向当前节点后续的自定义数据结构节点，由于自定义数据结构类型不能确定，因此只能用void *​定义。tql_prev​则是指向当前节点的前一个QTailQLink​节点。这两个变量的在后续QTAILQ_HEAD​和QTAILQ_ENTRY​中将体现出独特的作用。\nQTAILQ_HEAD ​QTAILQ_HEAD​定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /* * Tail queue definitions. The union acts as a poor man template, as if * it were QTailQLink\u0026lt;type\u0026gt;. */ #define QTAILQ_HEAD(name, type) \\ union name { \\ struct type *tqh_first; /* first element */ \\ QTailQLink tqh_circ; /* link for circular backwards list */ \\ } /* * union使两个变量共享同一个空间：tqh_first为一个指针，QTailQLink包含两个指针。 * 因此，tqh_first和tqh_circ.tql_next储存在同一个位置。 * 即tqh_circ.tql_next就是tqh_first。 */ 需要注意，QTAILQ_HEAD​被定义为union​结构体，也就是union​结构体中所有的变量共享同一块内存空间。当我们QTailQLink​展开后，tqh_first​和QTailQLink.tql_next​共享同一块内存，也就是两者实际上的值是相同的，只不过名字不同。\n​​\nQTAILQ_ENTRY 同理，QTAILQ_ENTRY​也是如此：\n1 2 3 4 5 #define QTAILQ_ENTRY(type) \\ union { \\ struct type *tqe_next; /* next element */ \\ QTailQLink tqe_circ; /* link for circular backwards list */ \\ } ​​\n​QTAILQ_HEAD​和QTAILQ_ENTRY​区别在与，QTAILQ_HEAD.tqh_first​指向第一个自定义数据结构体，QTAILQ_HEAD​本身是一个单独节点，不会存在于自定义数据结构中。而QTAILQ_ENTRY​是定义在自定义数据结构体中的，作为自定义数据结构体的一部分。\n​ModuleEntry​举例 为了直观的理解，以util/module.c​中定义的ModuleEntry​为例：\n1 2 3 4 5 6 7 8 9 10 11 12 // A general element for tail queue, must contain QTAILQ_ENTRY, and the name for // QTAILQ_ENTRY is arbitrary // Example typedef struct ModuleEntry { void (*init)(void); // data only for this struct QTAILQ_ENTRY(ModuleEntry) node;// use for queue module_init_type type; // data only for this struct } ModuleEntry; typedef QTAILQ_HEAD(, ModuleEntry) ModuleTypeList; ​ModuleEntry​就是自定义数据结构体，其中包含QTAILQ_ENTRY​定义的同时，还包含有其他变量，将其展开后代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 typedef struct ModuleEntry { void (*init)(void); union { struct ModuleEntry *tqe_next; struct QTailQLink { void *tql_next; struct QTailQLink *tql_prev; } tqe_circ; } node; module_init_type type; } ModuleEntry; 根据在QTAILQ_ENTRY​中的对union​结构体的分析，我们可以得到\n1 2 3 4 5 6 7 ModuleEntry entry; /* 下面两者等价，指向ModuleEntry类型 */ (ModuleEntry *) entry.node.tqe_next (ModuleEntry *) entry.node.tqe_circ.tql_next /* 指向struct QTailQLink */ (struct QTailQLink *) entry.node.tqe_circ.tql_prev 而QTAILQ_HEAD​则是单独定义的：\n1 2 typedef QTAILQ_HEAD(, ModuleEntry) ModuleTypeList; static ModuleTypeList dso_init_list; 同样将其展开，可以看到和ModuleEntry​不同点在在于，其中不包含其他类型的数据。\n1 2 3 4 5 6 7 8 typedef union ModuleTypeList { struct ModuleEntry *tqh_first; struct QTailQLink { void *tql_next; struct QTailQLink *tql_prev; } tqh_circ; } ModuleTypeList; 在实际使用时，如下图组织数据：ModuleTypeList​定义头节点，ModuleEntry​定义中间节点，双向队列由头节点和 node 之间的指针来维护。\n​​\n需要注意的是，所有next指针（tql_next​、tqe_next​）指向的都是自定义数据结构，而所有的prev指针（tql_prev​）指向的都是struct QTailQLink​（即tqh_circ​，tqe_circ​）。这意味着，如果我们想要访问cur节点的前一个节点，需要从tql_prev-\u0026gt;tql_prev-\u0026gt;tql_next​来访问。\n其他API head初始化 有两种方式实现：QTAILQ_HEAD_INITIALIZER​和QTAILQ_INIT​。\n​QTAILQ_HEAD_INITIALIZER​ 实际上是宏定义的结构体赋值文本，不算是函数接口（api）。\n​QTAILQ_INIT​是宏定义的函数体，算是函数接口（api）。\n因此，函数调用时使用QTAILQ_INIT​，而定义struct时需要初始化head，则使用QTAILQ_HEAD_INITIALIZER​。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 /* */ #define QTAILQ_HEAD_INITIALIZER(head) \\ { .tqh_circ = { NULL, \u0026amp;(head).tqh_circ } } /* * HEAD初始化时，头尾是同一个节点（本HEAD节点） * 和后续的 QTAILQ_INIT(head)作用相同，但用途不同。 * QTAILQ_HEAD_INITIALIZER 是宏定义，用于自定义struct初始化head时使用。 * QTAILQ_INIT 是函数，在函数中调用实现head初始化。 */ /* QTAILQ_HEAD_INITIALIZER */ static QemuOptsList qemu_source_opts = { .name = \u0026#34;source\u0026#34;, .implied_opt_name = \u0026#34;file\u0026#34;, .head = QTAILQ_HEAD_INITIALIZER(qemu_source_opts.head), .desc = { { } }, }; /* * Tail queue functions. */ #define QTAILQ_INIT(head) do { \\ (head)-\u0026gt;tqh_first = NULL; \\ (head)-\u0026gt;tqh_circ.tql_prev = \u0026amp;(head)-\u0026gt;tqh_circ; \\ } while (/*CONSTCOND*/0) // 初始化队列时，由于只有一个HEAD节点，因此HEAD的prev指向自身，next（即first元素）指向空 // 否则HEAD的prev指向的就是尾元素 /* QTAILQ_INIT */ static ModuleTypeList init_type_list[MODULE_INIT_MAX]; static ModuleTypeList dso_init_list; static void init_lists(void) { static int inited; int i; if (inited) { return; } for (i = 0; i \u0026lt; MODULE_INIT_MAX; i++) { QTAILQ_INIT(\u0026amp;init_type_list[i]); } QTAILQ_INIT(\u0026amp;dso_init_list); inited = 1; } 头部和尾部插入 由于是宏定义实现的接口，我们预先不知道自定义的数据结构的名称，以及其中的strutc QTailQLink​名称，因此需要传入这两个参数，elm​和field​。例如，ModuleEntry​对应于elm​，ModuleEntry​中的node​对应于field​。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 /* * Tail queue functions. */ #define QTAILQ_INSERT_HEAD(head, elm, field) do { \\ if (((elm)-\u0026gt;field.tqe_next = (head)-\u0026gt;tqh_first) != NULL) \\ (head)-\u0026gt;tqh_first-\u0026gt;field.tqe_circ.tql_prev = \\ \u0026amp;(elm)-\u0026gt;field.tqe_circ; \\ else \\ (head)-\u0026gt;tqh_circ.tql_prev = \u0026amp;(elm)-\u0026gt;field.tqe_circ; \\ (head)-\u0026gt;tqh_first = (elm); \\ (elm)-\u0026gt;field.tqe_circ.tql_prev = \u0026amp;(head)-\u0026gt;tqh_circ; \\ } while (/*CONSTCOND*/0) // 向头节点插入时，先判断HEAD后有没有其他元素，并将当前元素elm的next指针指向HEAD后的元素 // 如果有其他元素，则将HEAD的后续元素的prev指针指向当前元素elm // 如果没有其他元素，则将HEAD的prev指针指向当前元素elm。 // 然后将HEAD的first指向elm，因为first其实就是HEAD的next // 最后将elm的prev指向head。 // 需要注意：HEAD中的tqe_circ、elm中的field（即QTAILQ_ENTRY）的tqe_circ // 才是整个链条中的“节点”， // elm中，field就是QTAILQ_ENTRY，用来标识节点，因此elm不仅有“节点”，还有其他的数据 // 而在HEAD中，HEAD就是QTAILQ_HEAD，和QTAILQ_ENTRY同属基本的queue数据结构， // 因此，在整个链条中，QTAILQ_HEAD和QTAILQ_ENTRY作为队列中的节点，其中的指针 // prev和next链接每个节点。 // 在实现中很有意思的一点，next指针的类型是type *，而pre的指针类型是QTailQLink * // 因此，在访问next中的“节点”时，需要访问next.field.tqe_circ，而pre直接就访问 // pre.tqe_circ #define QTAILQ_INSERT_TAIL(head, elm, field) do { \\ (elm)-\u0026gt;field.tqe_next = NULL; \\ (elm)-\u0026gt;field.tqe_circ.tql_prev = (head)-\u0026gt;tqh_circ.tql_prev; \\ (head)-\u0026gt;tqh_circ.tql_prev-\u0026gt;tql_next = (elm); \\ (head)-\u0026gt;tqh_circ.tql_prev = \u0026amp;(elm)-\u0026gt;field.tqe_circ; \\ } while (/*CONSTCOND*/0) #define QTAILQ_INSERT_AFTER(head, listelm, elm, field) do { \\ if (((elm)-\u0026gt;field.tqe_next = (listelm)-\u0026gt;field.tqe_next) != NULL)\\ (elm)-\u0026gt;field.tqe_next-\u0026gt;field.tqe_circ.tql_prev = \\ \u0026amp;(elm)-\u0026gt;field.tqe_circ; \\ else \\ (head)-\u0026gt;tqh_circ.tql_prev = \u0026amp;(elm)-\u0026gt;field.tqe_circ; \\ (listelm)-\u0026gt;field.tqe_next = (elm); \\ (elm)-\u0026gt;field.tqe_circ.tql_prev = \u0026amp;(listelm)-\u0026gt;field.tqe_circ; \\ } while (/*CONSTCOND*/0) #define QTAILQ_INSERT_BEFORE(listelm, elm, field) do { \\ (elm)-\u0026gt;field.tqe_circ.tql_prev = (listelm)-\u0026gt;field.tqe_circ.tql_prev; \\ (elm)-\u0026gt;field.tqe_next = (listelm); \\ (listelm)-\u0026gt;field.tqe_circ.tql_prev-\u0026gt;tql_next = (elm); \\ (listelm)-\u0026gt;field.tqe_circ.tql_prev = \u0026amp;(elm)-\u0026gt;field.tqe_circ; \\ } while (/*CONSTCOND*/0) #define QTAILQ_REMOVE(head, elm, field) do { \\ if (((elm)-\u0026gt;field.tqe_next) != NULL) \\ (elm)-\u0026gt;field.tqe_next-\u0026gt;field.tqe_circ.tql_prev = \\ (elm)-\u0026gt;field.tqe_circ.tql_prev; \\ else \\ (head)-\u0026gt;tqh_circ.tql_prev = (elm)-\u0026gt;field.tqe_circ.tql_prev; \\ (elm)-\u0026gt;field.tqe_circ.tql_prev-\u0026gt;tql_next = (elm)-\u0026gt;field.tqe_next; \\ (elm)-\u0026gt;field.tqe_circ.tql_prev = NULL; \\ (elm)-\u0026gt;field.tqe_circ.tql_next = NULL; \\ (elm)-\u0026gt;field.tqe_next = NULL; \\ } while (/*CONSTCOND*/0) 除了上述Tail queue functions​，文件中还定义了一些访问方法，不在此处展示，当明白数据组织后，再去看源码将很容易。\n‍\n","date":"2024-10-29T09:29:20+08:00","permalink":"https://codetang-2417.github.io/p/qemu%E4%B8%AD%E7%9A%84%E9%98%9F%E5%88%97queue/","title":"QEMU中的队列queue"},{"content":"　参考：SSH 三步解决免密登录\n本地生成SSH密钥 本地客户端生成公私钥：（一路回车默认即可）\n1 ssh-keygen 上述命令会在用户目录.ssh​文件夹下创建公私钥\n1 2 $ ls ~/.ssh  ✔  44s  config id_rsa id_rsa.pub known_hosts id_rsa （私钥）id_rsa.pub (公钥)\n上传公钥到服务器 1 ssh-copy-id -i ~/.ssh/id_rsa.pub uasername@server_ip 将本地公钥上传到服务器的~/.ssh/authorized_keys​中。\n‍\n","date":"2024-10-25T10:44:56+08:00","permalink":"https://codetang-2417.github.io/p/ssh-%E5%85%8D%E7%99%BB%E9%99%86/","title":"SSH 免登陆"},{"content":"　在学校的服务器使用过程中，需要服务器访问外网，但在服务器上可能没有权限创建代理网络，或者不方便使用。而且直接使用服务器访问外网也可能有风险，因此，本文通过ssh隧道，将服务器的网络代理到我们的终端主机，也就是我们自己的电脑上，再在自己的电脑上安装代理软件，实现服务器通过ssh隧道访问外网的功能。\n本机代理配置 本文中 “本机” 一词代表个人电脑，服务器 代表远程连接的服务器电脑。\n本机系统如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ neofetch  ✔ ██████████████████ ████████ ling@ling-20ym ██████████████████ ████████ -------------- ██████████████████ ████████ OS: Manjaro Linux x86_64 ██████████████████ ████████ Host: 20YM Lenovo ThinkBook 16p Gen 2 ████████ ████████ Kernel: 6.1.112-1-MANJARO ████████ ████████ ████████ Uptime: 9 hours, 57 mins ████████ ████████ ████████ Packages: 1772 (pacman) ████████ ████████ ████████ Shell: bash 5.2.37 ████████ ████████ ████████ Resolution: 2560x1600, 2560x1440 ████████ ████████ ████████ DE: Plasma 6.1.5 ████████ ████████ ████████ WM: KWin ████████ ████████ ████████ Theme: [Plasma], Breeze [GTK2/3] ████████ ████████ ████████ Icons: [Plasma], McMojave-circle-dark [GTK2/3] ████████ ████████ ████████ Terminal: konsole CPU: AMD Ryzen 7 5800H with Radeon Graphics (16) @ 3.200GHz GPU: AMD ATI Radeon Vega Series / Radeon Vega Mobile Series GPU: NVIDIA GeForce RTX 3060 Mobile / Max-Q Memory: 18054MiB / 23392MiB 采用clash verge作为代理软件，该软件能够开放本地端口作为代理访问路径，为ssh隧道提供了出口端口。\n本人使用tun模式，尽可能的避免DNS泄漏。如果使用代理模式也可以。但 Linux上只有少数程序会走系统代理模式，除了在需要在clash verge中开启代理模式，还需要在对应的软件中手动设置代理。因此还是tun模式更适合linux上使用。参考：Ubuntu下系统代理只能作用于Firefox？\n注：开启代理模式后，即便本机其他程序不走clash，我们通过ssh建立隧道依然可行。\n​​\n这里开启tun模式后，并保证本机能够正常访问外网后，就可以开始ssh隧道搭建。需要注意，clash verge默认开放的代理端口为7897，可以自行修改。\nSSH隧道 参考：SSH 隧道技术、SSH隧道详解与使用AutoSSH实现稳定的内网穿透、SSH 隧道简明教程\nSSH隧道提供三种模式：正向 SSH 隧道（本地转发）、反向 SSH 隧道（远程转发）、动态转发 SSH 隧道（Socket服务器）。\n由于一台电脑上可能有多个网卡（意味着有多个 IP），因此在使用 SSH 隧道时，需要指定：1. 从哪一个 IP建立SSH连接。也就是SSH的登陆地址。2. SSH隧道应该连接到哪一个 IP上。也就是隧道地址。\n在下面的介绍中，destination 表示服务器的地址，也就是登陆服务器的标识符：Username@Host_IP，host:hostport 表示服务器上的隧道地址。host可以和Host_IP不同，但都是服务器上的IP地址。\n正向 SSH 隧道 将本主机上的某网络端口上的所有流量，通过 SSH 隧道转发到远程服务器上的网络端口。\n1 ssh -L [bind_address:]port:host:hostport destination 其中 bind_address 可选（默认为 localhost），是本机上的一个网络ip。该命令会本地开启一个绑定在 [bind_address:]port 上的套接字，并监听。将该套接字上所有的流量都转发到 destination 服务器上的 host:hostport。\n1 ssh -L 9090:localhost:8080 root@10.0.0.2 例如，这个例子就是将本机 localhost:9090 上的流量转发到 10.0.0.2 服务器上的 localhost:8080。\n反向 SSH 隧道 将远程服务器上的网络端口上的所有流量，通过 SSH 隧道转发到本主机上的某网络端口。\n1 ssh -R [bind_address:]port:host:hostport destination 和正向隧道的命令行格式相同，不同点在于此命令是在服务器上开启一个绑定在 host:hostport 上的套接字，并监听。将该套接字上所有的流量都转发到 本机 上的 [bind_address:]port。\n1 ssh -R 9090:localhost:8080 root@10.0.0.2 例如，这个例子就是将10.0.0.2 服务器上的 localhost:8080 上的流量转发到本机 localhost:9090。\n动态转发 SSH 隧道 动态转发 SSH 隧道实际上是将远程服务器作为一个 Socket 服务器，专门转发本地端口上的所有流量到服务器所处的网络中。动态转发不像正向隧道与反向隧道一样转发端口与目标端口是一对一的，动态转发中的转发端口对应的目标是目标主机所在的整个网络。不过使用动态转发访问目标主机所在网络时需要应用程序本身支持代理配置或者使用socket代理工具。\n1 ssh -D [bind_address:]port destination -D [bind_address:]port 指定监听的端口，会在本地监听该端口，并将请求到该端口流量基于 SOCKS5 协议转发到远程主机上，其中 [bind_address:]可以不填，当不写或者为 * 时表示监听全部地址。示例:-D *:8081,-D 8081,-D 127.0.0.1:8081,-D 192.168.0.1:8081。\n可以参考：SSH 隧道简明教程 中扩展-跨机器转发​章节，介绍的很清楚。\n下面是从中截出的两张图片，主要应用是在A与B之间创建隧道，最终通过隧道访问到ServerC中的 http 服务。\n​​\n最常用的就是绕过防火墙，在外网上通过一台可以访问内网的 Server A，访问内容。基于Socket协议的翻墙软件就是这个原理，用一台没被墙的、在国内可以通过SSH访问到的VPS，作为Socket服务器，也就是图中的 Server B。VPS在国外，可以访问国外网络资源，国内就将所有的外网网络请求发往 Server A的SSH 绑定端口，Server A会将其转发给国外网络，例如入中的 Server C。由于 Server A 到 Server B之间是SSH加密传输的，防火墙看不到其中具体访问的网络内容，就不会判断为翻墙。但由于这种方式应用太广泛，现在检测流量特征的手段很强，可以快速判断出并封掉。\n​​\n常用参数 ​-L​：local，表示使用本地端口转发创建 ssh 隧道 ​-R​：remote，表示使用远程端口转发创建 ssh 隧道 ​-D​：dynamic，表示使用动态端口转发创建 ssh 隧道 ​-N​： 表示创建隧道以后不连接到 sshServer端，通常与”-f”选项连用 ​-f​：表示在后台运行ssh隧道，通常与”-N”选项连用 ​-q​ 参数用于启用 静默模式（quiet mode） ​-g​：表示 ssh 隧道对应的转发端口将监听在主机的所有IP中，不使用”-g选项”时，转发端口默认只监听在主机的本地回环地址中，”-g” 表示开启网关模式，远程端口转发中，无法开启网关功能 ​-C​：启用压缩，可以提高传输速度。 ​-p port​：指定 SSH 服务器监听的端口 (如果不是默认的22端口)。 ​-i 私钥文件​：使用指定的私钥文件进行身份验证。 ​-T​ ：用于禁用伪终端分配，使用 -N​ 时，因为本身就没有需要交互的命令，SSH 默认不会分配伪终端，便不需要 -T​ 应用 为了达到我们的目的：将服务器上的网络代理到本机上，我们有两种方案：\n建立反向隧道，将服务器端口上的流量转发到本机，服务器上所有的流量都走代理端口。优点是：比较简单，只需要ssh建立隧道即可，不需要安装其他软件，只要主机能访问外网，服务器就可以。缺点是：如果有其他服务器，需要在主机上为每一个服务器都单独创建SSH隧道。如果主机下线了，服务器就无法访问外网了。 建立 Socket服务器，让服务器的所有流量都走 Socket服务器。但这样的话和建立一个翻墙代理的区别就会很小了，不如直接就在服务器上安装代理软件。优点是：更安全，代理管理起来更方便。一般来说Socket服务器不会轻易下线，保证服务器一直有外网网络。缺点是：每一台服务器上都需要单独配置软件，且Socket服务器需要在外网。 对于普通的应用场景来说，在自己的电脑上，我们都会安装代理软件，在服务器管理员没有配置跳板机或者跳板机故障时，我们就可以采用第一种，快速 实现 or 恢复 服务器访问外部网络。\n我们假设服务器的ip为10.0.0.2，服务器上有用户名为 server的用户。\n本机配置 本机上我们安装clash verge，正常启动后，就会clash verge就会监听 localhost:7897，并转发流量到代理服务器。本示例为方便起见，将主机和远程服务器的端口都设置为 7897，实际上远程服务器可以设置为其他没有被使用的端口，主机也可以在clash verge中将代理端口改为其他端口后，将SSH隧道的本地端口同步修改。\n运行：\n1 ssh -R 7897:localhost:7897 -fqCN server@10.0.0.2 为远程服务器的 localhost:7897 和本机的 localhost:7897建立ssh隧道。转发方向为：远程服务器 SSH隧道 -\u0026gt; 本机 localhost:7897 -\u0026gt; clash verge。\n​-fqCN​：后台运行、静默模式、启动压缩模式，加快速度、只转发端口，不连接终端。\n远程服务器配置 远程服务器上需要在终端中添加代理变量，也可以写到终端变量文件（~/.bashrc 或者 ~/.profile ）中，每次登陆自动生效。使得所有的流量走代理端口，也就是本地回环地址的7897端口。转发方向：服务器其他网络 -\u0026gt; 服务器 localhost的7897端口 -\u0026gt; 服务器SSH隧道\n1 2 export http_proxy=\u0026#34;localhost:7897\u0026#34; export https_proxy=\u0026#34;localhost:7897\u0026#34; 设置好后不能正常联网 在实践过程中，我遇到了按照上述配置后，主机网络正常访问外网，服务器和主机之间SSH隧道通信正常，但服务器无法访问外网。如下：\n服务器：\n1 2 $ curl -x socks5://localhost:7897 https://www.google.com curl: (35) error:0A000126:SSL routines::unexpected eof while reading 添加参数 -v​ 打印详细日志输出，可以看到使用了本地的DNS解析地址。但国内的DNS在没被代理的时候，会被CFW污染，因此这个地址实际上不是谷歌的服务器IP，但由于已经缓存下来了，所以在访问的时候会通过该IP来访问。于是，传递给代理的ip也是这个错误ip，就会导致访问出错。\n1 2 3 $ curl -v -x socks5://localhost:7897 https://www.google.com * Trying 127.0.0.1:7897... * SOCKS5 connect to IPv4 199.59.148.229:443 (locally resolved) 解决办法：\n等几分钟中\u0026hellip;等DNS缓存过期。\n安装 proxychain，并在其中配置proxy_dns​，使得DNS也通过代理查询。\n配置 proxychain\n1 2 3 4 5 6 7 8 9 10 11 12 $ vim /etc/proxychains.conf ... # Proxy DNS requests - no leak for DNS data proxy_dns ... [ProxyList] # add proxy here ... # meanwile # defaults set to \u0026#34;tor\u0026#34; https 127.0.0.1 7897 socks5 127.0.0.1 7897 通过 proxychain 访问\n1 $ proxychains curl -I https://www.youtube.com 在使用 systemd 管理服务的 Linux 上。可以通过重启系统解析服务来情况 DNS 缓存 sudo systemctl restart systemd-resolved​。\n正常情况下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ curl -v -x socks5://localhost:7897 https://www.google.com * Trying 127.0.0.1:7897... * SOCKS5 connect to IPv4 31.13.94.41:443 (locally resolved) * SOCKS5 request granted. * Connected to (nil) (127.0.0.1) port 7897 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * CAfile: /etc/ssl/certs/ca-certificates.crt * CApath: /etc/ssl/certs * TLSv1.0 (OUT), TLS header, Certificate Status (22): * TLSv1.3 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS header, Certificate Status (22): * TLSv1.3 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS header, Finished (20): 重新建立SSH 隧道后服务器无法访问外网 可能会出现 SSH 隧道已经被清空，但服务器端还没有退出对应的线程的情况，这时需要我们手动找出对应的线程，并kill掉。再重新建立 SSH 隧道。\n1 2 3 4 5 6 $ sudo lsof -i :7897 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME sshd 2129065 tiancheng.tang 7u IPv6 48338339 0t0 TCP ip6-localhost:7897 (LISTEN) sshd 2129065 tiancheng.tang 9u IPv4 48338340 0t0 TCP localhost:7897 (LISTEN) $ kill 2129065 如果需要长时间稳定使用SSH 隧道，可以使用autossh。\n","date":"2024-10-20T18:50:54+08:00","permalink":"https://codetang-2417.github.io/p/%E4%B8%AA%E4%BA%BAlinux%E4%B8%BB%E6%9C%BA%E9%80%9A%E8%BF%87ssh%E9%9A%A7%E9%81%93%E4%BD%BF%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE%E5%A4%96%E7%BD%91/","title":"个人Linux主机通过SSH隧道使服务器访问外网"},{"content":"　参考：深入探索 perf CPU Profiling 实现原理，perfwiki，系统级性能分析工具perf的介绍与使用\nperf 是由 Linux 官方提供的系统性能分析工具 。我们通常说的 perf 实际上包含两部分：\nperf 命令，用户空间的应用程序，是内核子系统 perf_events 的前端工具。 perf_events ，Linux 内核中的一个子系统。 perf_events是Linux 2.6.31版本引入的内核子系统，可以提供多种来源的事件的性能计数器，供用户空间软件 perf 使用，完成性能分析（Performance profiling）。perf 和 perf_events 最初支持硬件计数器（performance monitoring counters，PMC），后来扩展到下列的多种事件源的支持。\nperf_events 4类事件源：\nHardware Events:：由CPU 性能计数器（performance counters）以及其内部的 Performance Monitoring Unit (PMU)获取，用来统计 Hardware event，例如 cpu-cycles、instructions executed 、cache-misses、branch mispredicted、周期数（the number of cycles）、退役指令（instructions retired）， 缓存未命中（L1 cache misses L1 ）等。这些 event 因每种处理器类型和型号而异。\n注：Last Branch Record（LBR）是Intel CPU中最先引入的一个功能，记录最近执行过的分支指令，可以用来分析分支指令的执行情况，在perf list中，branch相关的功能也被划分到PMU分类，认为LBR的相关数据是通过PMU来获取的。\nSoftware Events: 基于内核计数器的低优先级events， 例如, context-switches，CPU migrations(处理器迁移次数)， minor faults(soft page faults)，major faults(hard page faults)。\nTracepoints:：由内核的 ftrace 实现的跟踪点事件，是散落在内核源代码中的一些 hook，用来调用probe函数。开启后，它们便可以在特定的代码被运行到时被触发，这一特性可以被各种 trace/debug 工具所使用。Perf 就是该特性的用户之一。假如您想知道在应用程序运行期间，内核内存管理模块的行为，便可以利用潜伏在 slab 分配器中的 tracepoint。当内核运行到这些 tracepoint 时，便会通知 perf。仅仅适用于2.6.3以及之后的 linux 内核。除了内核中的tracepoint，还有用户态中的，USDT（User-level statically-defined tracing）。\nDynamic Tracing： probe函数（探针or探测函数），kprobe（kernel probe）内核态探针，用来创建和管理内核代码中的探测点。Uprobes，user-probe，用户态探针，用来对用户态应用程序进行探测点的创建和管理，关于kprobe和uprobe可参考对应的内核文档。\n下图显示了 perf 命令和 perf_events 的关系，以及 perf_events 支持的事件源。下面的分类和linux perf wiki上的perf_envent分类有些许不同，主要在与tracepoint的定义，下图包含了Static Tracing以及Dynamic Tracing。\n​​\n图片来源：深入探索 perf CPU Profiling 实现原理\n我们可以通过命令perf list​来查看perf支持的事件类型，但perf list​不能完全显示所有支持的事件类型，需要sudo perf list​。\n同时还可以显示特定模块支持的perf事件：hw/cache/pmu都是硬件相关的；tracepoint基于内核的ftrace；sw（software）实际上是内核计数器。\n下边列出一些sudo perf list​的输出例子：\n1 2 3 4 5 6 7 branch-instructions OR branches [Hardware event] context-switches OR cs [Software event] cpu-clock [Software event] L1-dcache-load-misses [Hardware cache event] L1-dcache-loads [Hardware cache event] branch-instructions OR cpu/branch-instructions/ [Kernel PMU event] block:block_bio_backmerge [Tracepoint event] 下图是很有名的brendan gregg的博客中的分类，他写了很多关于性能分析的书籍和博客。​\n图片来源：www.brendangregg.com/blog/2015-02-27/linux-profiling-at-netflix\u0026hellip;.、www.brendangregg.com/perf.html\n原理 CPU 和其他硬件设备通常提供用于观测性能数据的 PMC。简单来说，PMC 就是 CPU 上的可编程寄存器，可通过编程对特定硬件事件进行计数。通过 PMC 可以监控和计算 CPU 内部各种事件，比如 CPU 指令的执行效率、CPU caches 的命中率、分支预测的成功率等微结构级别的性能信息。利用这些数据分析性能，可以实现各种性能优化。\nperf 命令通过 perf_event_open(2) 系统调用访问 PMC，配置想要捕获的硬件事件。PMC 可以在两种模式下使用：\nCounting（计数模式），只报告Hardware Event、Software Events、PMU计数等。相关命令perf stat。开销几乎为零。 Sampling（采样模式），当发生一定数量的事件后，会触发一个中断，以便捕获系统的状态信息。perf将事件数据缓存到一块buffer中，然后异步写入到perf.data文件中。使用perf report等工具进行离线分析。可用于采集代码路径。 bpf：Kernel 4.4+新增功能，可以提供更多有效filter和输出总结。 下面详细介绍一下 Sampling 模式：\nPerf 通过系统调用 sys_perf_event_open 陷入到内核中，内核根据 perf 提供的信息在PMU（Performance Monitoring Unit）上初始化一个硬件性能计数器（PMC: Performance Monitoring Counter）。PMC随着指定硬件事件的发生而自动累加。如果不触发溢出中断，则就是counting模式，例如 perf stat模式。\n在PMC 溢出时，PMU触发一个PMI（Performance Monitoring Interrupt）中断。内核在PMI 中断的处理函数中保存PMC的计数值，触发中断时的指令地址，当前时间戳以及当前进程的PID、TID、comm 等信息。我们把这些信息统称为一个采样（sample）。内核会将收集到的sample放入用于跟用户空间通信的Ring Buffer。用户空间里的perf分析程序采用mmap机制从ring buffer中读入采样，并对其解析。\n下图从系统调用和数据结构的层面展示了用户空间如何获取PMU信息的流程。还有一张类似的图，是来自阿里的pdf中的，被其他博客转载，或者重绘后使用，其大体内容和下图是一致的。pdf地址：类似图\n​​\n图片来源：plantegg.github.io/2021/05/16/Perf_IPC%E4%BB%A5%E5%8F%8ACPU%E5%8\u0026hellip;\n使用 关于 perf 的详细使用，参考：系统级性能分析工具perf的介绍与使用\n‍\n","date":"2024-10-19T10:27:24+08:00","permalink":"https://codetang-2417.github.io/p/linux-perf%E5%B7%A5%E5%85%B7/","title":"Linux Perf工具"},{"content":"　目前国内的镜像加速网站被墙，个人电脑可以通过代理的方式下载镜像，但服务器可能无法使用代理，或者无法访问网络，因此可以通过离线的方式，或者使用自建私有镜像仓库的形式来管理镜像。\n本文说明如何通过离线的方式向服务器上传镜像：将 Docker 镜像导出并传输到服务器，然后再导入镜像。\n步骤 导出镜像到本地文件 在本地，将 Docker 镜像导出为 `.tar`​ 文件： ```bash docker save -o ubuntu24.tar ubuntu:24.04 ``` 这会将名为 `ubuntu:24.04`​ 的镜像保存为 `ubuntu24.tar`​ 文件。 将文件传输到服务 通过 USB 或局域网的文件传输工具（如 `scp`​、`rsync`​、FTP 等）将 `ubuntu24.tar`​ 文件传输到服务器。 例如使用 `scp`​： ```bash scp ubuntu24.tar user@server:/path/to/destination ``` 在服务器上导入镜像 将文件传输到服务器后，在服务器上使用以下命令导入该镜像： ```bash docker load -i /path/to/destination/ubuntu24.tar ``` 这会将 `ubuntu24.tar`​ 文件中的 Docker 镜像加载到服务器的 Docker 环境中。 如果镜像过大，或者使用人数较多的情况，需要考虑自建镜像仓库，有一些免费的管理软件可供使用，不再本文介绍范围内，后续如果有需要再进行总结。\n","date":"2024-10-16T22:47:00+08:00","permalink":"https://codetang-2417.github.io/p/%E7%A6%BB%E7%BA%BF%E6%96%B9%E5%BC%8F%E4%BC%A0%E8%BE%93-docker-%E9%95%9C%E5%83%8F/","title":"离线方式传输 Docker 镜像"},{"content":"循环队列 队列：先进先出的数据结构，有多种实现方式，比较简单的是通过数组模拟。还可以用链表。\n循环队列则是为了解决顺序队列的”假溢出“问题而提出。\n假溢出：顺序队列的数组空间没有真正被填满，但因为队列的头指针已经向后移动了一定距离，导致在继续入队时，队列判定为溢出。如果不使用循环队列，动态的修改队列的头尾指针的指向，则需要不断的将队列中的元素移动到数组的头部，保证不溢出。\n循环队列需要考虑队空和队满的判别条件。\n有两种方法区分队空和队满：\n创建变量 size，记录循环队列大小。size = 0​为队空。size = array.length​为队满。 数组只使用array.length-1​的空间，留出1个元素作为缓冲。front指向队列中首元素，而rear指向队列尾元素的下一个元素。因此front == rear​为队空，front == (rear + 1) % capacity​为队满。 例题：\n1 2 假设以数组A[70]存放循环队列的元素, 其头指针是front=47, 当前队列有50个元素, 则队列的尾指针值为（ ）。 A.70 B.27 C.37 D.20 front到数组末尾共有 70 - 47 = 23个元素，则数组头部开始应再存 50 - 23 = 27个元素，默认情况下，采用第2种循环队列判空和判满的方式，则rear指向的应该是27，也就是第28个元素。\n图 参考：Hello 算法：图\n图的分类 图是非线性数据结构，由顶点和边组成。根据边的特性，分为有向图和无向图。\n​​\n而根据顶点是否连通，又可以分为连通图和非连通图。\n​​\n还可以为每一条边添加权重，从而转变为有权图\n​​\n图的术语 参考：图（Graph）详解 - 数据结构 - CSDN App\n邻接（adjacency）：当两顶点之间存在边相连时，称这两顶点“邻接”。在图 9-4 中，顶点 1 的邻接顶点为顶点 2、3、5。\n路径（path）：从顶点 A 到顶点 B 经过的边构成的序列被称为从 A 到 B 的“路径”。在图 9-4 中，边序列 1-5-2-4 是顶点 1 到顶点 4 的一条路径。\n度（degree）：一个顶点拥有的边数。对于有向图，入度（in-degree）表示有多少条边指向该顶点，出度（out-degree）表示有多少条边从该顶点指出。\n完全图： 在有 n 个顶点的无向图中，若有 n*(n-1)/2 条边，即任意两个顶点之间有且仅有一条边，则称此图为无向完全图；在 n 个顶点的有向图中，若有 n*(n-1) 条边，即任意两个顶点之间有且仅有方向相反的边，此图称为有向完全图。\n路径： 在图 G = (V， E) 中，若从顶点 vi 出发有一组边使其可到达顶点 vj，则称顶点 vi 到顶点 vj 的顶点序列为从顶点 vi 到顶点 vj 的路径。\n路径长度： 对于不带权的图，一条路径的路径长度是指该路径上的边的条数；对于带权的图，一\n条路径的路径长度是指该路径上各个边权值的总和。\n连通图： 在无向图中，若从顶点 v1 到顶点 v2 有路径，则称顶点 v1 与顶点 v2 是连通的。若图中任意一对顶点都是连通的，则称此图为连通图。\n强连通图： 在有向图中，若在每一对顶点 vi 和 vj 之间都存在一条从 vi 到 vj 的路径，也存在一条从 vj 到 vi 的路径，则称此图是强连通图。\n弱连通图：在有向图中，如果将图中的所有有向边转换为无向边后，图是连通的，则称为弱连通图。\n生成树： 在无向图中，一个连通图的最小连通无环子图称作该图的生成树。生成树有且只有 n 个顶点和 n-1 条边。\n注：最小连通无环子图中的”最小“应当从连通图上来理解，“最小连通子图”，指一个连通图中，边数最小的子图，但要求顶点数不变。\n无向图的连通分量：是在图中具有连通性的一部分，是图中能够相互连通的极大顶点集合。因为一个图并不总是连通图、强连通图、弱连通图。往往是其中存在一些连通子图，为了描述这类图，提出的连通分量的概念，需要注意，连通分量一定是极大连通子图，如果一个顶点存在于某一个连通子图，那么这个顶点在的连通分量一定就是包含了所有和其连通的顶点的子图。\n例题：\n1 2 对于一个具有n个顶点的无向连通图，其连通分量的个数为： A.n B.n+1 C.1 D.0 连通分量是极大连通子图，对于连通图来说，其本身就是连通图，则极大连通子图就是其自身。因此，连通分量个数为1。\n强连通分量：有向图中的一个子图，其中任意两个顶点之间都有双向可达的路径。即对于任意顶点 $u$ 和 $v$，存在从 $u$ 到 $v$ 的路径，且也存在从 $v$ 到 $u$ 的路径。或者简单的说，图的某个子图是一个强连通图，则称这个子图为强连通分量。\n弱连通分量：有向图中，如果我们忽略边的方向，把所有边都当作无向边，那么能够连通的极大子图就是弱连通分量。或者简单的说，图的某个子图是一个弱连通图，则称这个子图为弱连通分量。\n图的表示 邻接矩阵 设图的顶点数量为 n ，邻接矩阵（adjacency matrix）使用一个 n×n 大小的矩阵来表示图，每一行（列）代表一个顶点，矩阵元素代表边，用 1 或 0 表示两个顶点之间是否存在边。\n​​\n邻接矩阵具有以下特性。\n顶点不能与自身相连，因此邻接矩阵主对角线元素没有意义。 对于无向图，两个方向的边等价，此时邻接矩阵关于主对角线对称。 将邻接矩阵的元素从 1 和 0 替换为权重，则可表示有权图。 使用邻接矩阵表示图时，我们可以直接访问矩阵元素以获取边，因此增删查改操作的效率很高，时间复杂度均为 $O(1)$ 。然而，矩阵的空间复杂度为 $O(n^2)$ ，内存占用较多。\n邻接表 邻接表（adjacency list）使用 n 个链表来表示图，链表节点表示顶点。第 i 个链表对应顶点 i ，其中存储了该顶点的所有邻接顶点（与该顶点相连的顶点）。图 9-6 展示了一个使用邻接表存储的图的示例。\n​​\n邻接表仅存储实际存在的边，而边的总数通常远小于 $n^2$ ，因此它更加节省空间。然而，在邻接表中需要通过遍历链表来查找边，因此其时间效率不如邻接矩阵。\n观察图 9-6 ，邻接表结构与哈希表中的“链式地址”非常相似，因此我们也可以采用类似的方法来优化效率。比如当链表较长时，可以将链表转化为 AVL 树或红黑树，从而将时间效率从 $O(n)$ 优化至 $O(log⁡\\ n)$ ；还可以把链表转换为哈希表，从而将时间复杂度降至 $O(1)$ 。\n‍\n","date":"2024-09-29T09:45:17+08:00","permalink":"https://codetang-2417.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9F%A5%E8%AF%86%E7%82%B9%E9%9B%86%E5%90%88/","title":"数据结构知识点集合"},{"content":"　参考：时间复杂度\n时间复杂度分析统计的不是算法运行时间，而是算法运行时间随着数据量变大时的增长趋势。\n在数学上，时间复杂度被定义为 函数渐进上界，可以简单理解为能够反应函数的增长趋势的函数。\n通常用大O符号表示：$O(f(n))$。其中 $f(n)$ 就是我们计算时间复杂度时的结果。\n计算 $ f(n) $ 的实质是计算操作的数量。\n计算操作数量 计算技巧：\n忽略常数项 省略系数 循环嵌套时，使用乘法 只取高阶项 常见类型 ​​\n常数阶$O(1)$ 常数阶的操作数量与输入数据大小 n 无关，即不随着 n 的变化而变化。\n在以下函数中，尽管操作数量 size​ 可能很大，但由于其与输入数据大小 n 无关，因此时间复杂度仍为 $O(1)$：\n1 2 3 4 5 6 7 8 /* 常数阶 */ int constant(int n) { int count = 0; int size = 100000; for (int i = 0; i \u0026lt; size; i++) count++; return count; } 线性阶$O(n)$ 线性阶的操作数量相对于输入数据大小 n 以线性级别增长。线性阶通常出现在单层循环中：\n1 2 3 4 5 6 7 /* 线性阶 */ int linear(int n) { int count = 0; for (int i = 0; i \u0026lt; n; i++) count++; return count; } 实际上就是操作的数量以数据规模 n 的线性级别增长。\n遍历数组和遍历链表等操作的时间复杂度均为 $O(n)$ ，其中 n 为数组或链表的长度：\n1 2 3 4 5 6 7 8 9 /* 线性阶（遍历数组） */ int arrayTraversal(vector\u0026lt;int\u0026gt; \u0026amp;nums) { int count = 0; // 循环次数与数组长度成正比 for (int num : nums) { count++; } return count; } 平方阶 $O(n^2)$ 平方阶的操作数量相对于输入数据大小 n 以平方级别增长。平方阶通常出现在嵌套循环中，外层循环和内层循环的时间复杂度都为 $O(n)$，因此总体的时间复杂度为 $O(n^2)$ ：\n1 2 3 4 5 6 7 8 9 10 11 /* 平方阶 */ int quadratic(int n) { int count = 0; // 循环次数与数据大小 n 成平方关系 for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; n; j++) { count++; } } return count; } 以冒泡排序为例，外层循环执行 n−1 次，内层循环执行 n−1、n−2、…、2、1 次，因此时间复杂度为 $O((n−1)*n/2)=O(n^2)$（求和公式）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /* 平方阶（冒泡排序） */ int bubbleSort(vector\u0026lt;int\u0026gt; \u0026amp;nums) { int count = 0; // 计数器 // 外循环：未排序区间为 [0, i] for (int i = nums.size() - 1; i \u0026gt; 0; i--) { // 内循环：将未排序区间 [0, i] 中的最大元素交换至该区间的最右端 for (int j = 0; j \u0026lt; i; j++) { if (nums[j] \u0026gt; nums[j + 1]) { // 交换 nums[j] 与 nums[j + 1] int tmp = nums[j]; nums[j] = nums[j + 1]; nums[j + 1] = tmp; count += 3; // 元素交换包含 3 个单元操作 } } } return count; } 指数阶 $O(2^n)$ 生物学的“细胞分裂”是指数阶增长的典型例子：初始状态为 1 个细胞，分裂一轮后变为 2 个，分裂两轮后变为 4 个，以此类推，分裂 n 轮后有 $2^n$ 个细胞。\n图 2-11 和以下代码模拟了细胞分裂的过程，时间复杂度为 $O(2^n)$ ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 /* 指数阶（循环实现） */ int exponential(int n) { int count = 0, base = 1; // 细胞每轮一分为二，形成数列 1, 2, 4, 8, ..., 2^(n-1) for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; base; j++) { count++; } base *= 2; } // count = 1 + 2 + 4 + 8 + .. + 2^(n-1) = 2^n - 1 return count; } 在实际算法中，指数阶常出现于递归函数中。例如在以下代码中，其递归地一分为二，经过 n 次分裂后停止：\n1 2 3 4 5 6 /* 指数阶（递归实现） */ int expRecur(int n) { if (n == 1) return 1; return expRecur(n - 1) + expRecur(n - 1) + 1; } ​​\n指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心算法等来解决。\n对数阶 $O(log⁡\\ n)$ 与指数阶相反，对数阶反映了“每次操作缩减到一半”的情况。设输入数据大小为 n ，由于每次操作都缩减数据规模到一半，数据规模将迅速较少，循环次数是 $log_2\\ ⁡n$，即 $2^n$ 的反函数。\n图 2-12 和以下代码模拟了“每轮缩减到一半”的过程，时间复杂度为 $O(log2 ⁡n﻿)$，简记为 $O(log\\ ⁡n)$ ：\n1 2 3 4 5 6 7 8 9 /* 对数阶（循环实现） */ int logarithmic(int n) { int count = 0; while (n \u0026gt; 1) { n = n / 2; count++; } return count; } 每一次操作都使 $n=n/2$​，这就会快速减少操作的次数。\n​​\n和指数阶一样，对数阶也经常出现在递归函数中，两者的区别在递归返回时调用递归函数时的参数以及调用次数。\n1 2 3 4 5 6 /* 对数阶（递归实现） */ int logRecur(int n) { if (n \u0026lt;= 1) return 0; return logRecur(n / 2) + 1; } 线性对数阶$O(n log n﻿)$ 线性对数阶常出现于嵌套循环中，两层循环的时间复杂度分别为 O(log⁡n) 和 O(n) 。相关代码如下：\n1 2 3 4 5 6 7 8 9 10 /* 线性对数阶 */ int linearLogRecur(int n) { if (n \u0026lt;= 1) return 1; int count = linearLogRecur(n / 2) + linearLogRecur(n / 2); for (int i = 0; i \u0026lt; n; i++) { count++; } return count; } ​​\n阶乘阶$O(n!)$ 阶乘阶对应数学上的“全排列”问题。给定 n 个互不重复的元素，求其所有可能的排列方案，方案数量为：\n$n!=n\\times(n-1)\\times(n-2)\\times\u0026hellip;\\times2\\times1$\n阶乘通常使用递归实现。如图 2-14 和以下代码所示，第一层分裂出 n 个，第二层分裂出 n−1 个，以此类推，直至第 n 层时停止分裂：\n1 2 3 4 5 6 7 8 9 10 11 /* 阶乘阶（递归实现） */ int factorialRecur(int n) { if (n == 0) return 1; int count = 0; // 从 1 个分裂出 n 个 for (int i = 0; i \u0026lt; n; i++) { count += factorialRecur(n - 1); } return count; } 像回溯算法就属于这一类，由于必须要遍历所有的情况，只能通过递归来实现。\n​​\n请注意，因为当 n≥4 时恒有 n!\u0026gt;2n ，所以阶乘阶比指数阶增长得更快，在 n 较大时也是不可接受的。\n‍\n","date":"2024-09-21T15:14:34+08:00","permalink":"https://codetang-2417.github.io/p/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/","title":"时间复杂度"},{"content":"博客seo优化 SEO（搜索引擎优化）指的是一系列的策略和技术，旨在提高博客在搜索引擎结果页面（SERP）上的可见性和排名。SEO的目标是使博客在搜索引擎中更容易被用户找到，从而吸引更多的有针对性的流量。\n参考：Hugo博客seo优化\n页面关键词 为每篇博客文章设置标题、关键词、描述\n1 2 3 4 5 title: seo优化 keywords: - seo - hugo description: \u0026#34;hugo博客seo优化\u0026#34; 页面描述 在站点目录下的config中添加博客描述有利于搜索\n1 2 params: description: \u0026#34;Ling的个人博客，hugo，papermod，golang，mysql，微服务\u0026#34; Google搜索优化 第一步，进入Google Search Console点击添加资源，输入自己的网站。比如我的是 https://codetang-2417.github.io，选择第二种验证方式，然后下载一个html文件放到hugo站点的static文件夹下，然后重新部署站点，回到Google Search Console页面点击验证，如果能访问到表示验证成功。\n​​\n第二步，在Google Search Console页面点击站点地图，输入当前站点的sitemap.xml，也有可能是其他后缀，hugo部署后一般会自动生成sitemap，在根目录下，如：https://codetang-2417.github.io/sitemap.xml。\n​​\n百度搜索优化 进入百度搜索资源平台，选择 用户中心-\u0026gt;站点管理-\u0026gt;添加网站，添加上你自己的网站，这里的验证方式也可以选择下载html的方式，步骤和google的一样，验证成功后选择 搜索服务-\u0026gt;普通收录-\u0026gt;sitemap，输入sitemap的网址，和google的站点地图一样，如我的是： https://codetang-2417.github.io/sitemap.xml。注意百度不允许以子目录的方式提交子站点，和google不一样，只能在提交sitemap文件时，提交多个sitemap文件。\n必应搜索优化 进入Bing Webmaster Tools，登录后直接导入google的数据就可以，很方便。\n收录时间 我的网站在2023年9月底建立，直到2024年8月底才被大量的收录进谷歌。\n这期间只有一个网页被编入索引。收录的速度和网站的质量以及上述的SEO有关系。所以网站短时间内是不会被立刻收录，需要慢慢等待，不断的更新网站提升质量。\n​​\n还可以点进入查看未编入索引的原因，并验证当前的修正情况。\n​​\n","date":"2024-09-17T10:01:32+08:00","permalink":"https://codetang-2417.github.io/p/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%94%B6%E5%BD%95%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2-seo%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E4%BC%98%E5%8C%96/","title":"搜索引擎收录个人博客-SEO（搜索引擎优化）"},{"content":"　目前搭建个人博客网站分为动态网站和静态网站两种。其中动态网站需要购买服务器，并且需要维护网站安全，虽然功能比静态网站更多更丰富，也有后台管理系统，可以在线写博客，但成本还是太高。这类网站框架有：wordpress（主流，功能丰富但需要时间和优化知识），typecho（轻量级，最近团队开始重新维护），Halo等。\n静态网站则功能有限，只能显示静态编译好的html，不能在线写博客，没有管理系统。但好在可以0成本搭建，结合github page功能，无需服务器就可以搭建。这类网站框架有Hugo（go语言编写，大量博客加载速度快，新框架，但目前已经发展的挺不错的了），Hexo（老牌，网络资源丰富，但大量博文加载很慢）等。\n结合我自己的需求，静态网站就足够我的使用场景了。并考虑到日后的博客数量会很多，选择Hugo。\n且之前也用hugo搭过一个博客网站，但是由于发布太过于繁琐（即使使用了github action），后面没有怎么更新了。但现在思源的发布插件已经支持了一键自动发布，和思源配合，能够解放双手，为这个博客发布的工作流补上最后一块拼图。由于其效果不好，最终还是不能使用这个一键发布工具，不过考虑参考采用这个发布工具，开发一个针对我的应用场景的发布工具。Todo++\n补充：如果想建立类似于书籍或者使用说明的这种形式的博客网站，可以选择 mkdocs，mdbook可能存在一些小问题。\ngithub page类型选择 我们使用github pages作为静态网站的部署方式，个人用户只有两种 GitHub Pages 网站的类型：一种是 user​(用户)，一种是project​(项目)。\n​user​类型的网址只能对应唯一的用户，而且仓库的名字必须为 \u0026lt;username\u0026gt;.github.io​，对应的网址为 http(s)://\u0026lt;username\u0026gt;.github.io​。\n​project​类型的仓库则可以新建很多，只要仓库的名字不为 \u0026lt;username\u0026gt;.github.io​ 即可，对应的网址为 http(s)://\u0026lt;username\u0026gt;.github.io/\u0026lt;repository\u0026gt;​。\n本文采用多种仓库的形式进行管理，因为为了可能会引入不同的网站框架。\n需要注意，我们可以同时拥有user​和project​ pages。因此，我们可以将个人博客放到user​上，而其他的网页，例如专为某一个项目写的说明文档，放在单独的仓库中。这样访问博客站点只需要访问https://\u0026lt;username\u0026gt;.github.io​即可，而访问其他项目就加上后缀，例如：https://\u0026lt;username\u0026gt;.github.io/HugoStack​。\n并且按照这篇博客中的方式，只公开编译好的站点，隐藏源码仓库。\nHugo搭建 最开始按照 【Hugo+PaperMod搭建博客】 中的教程进行搭建。但后续发现这个主题文档不完善，使用过程中的小问题很多，因此不建议使用。转而使用 stack 主题。\n涉及到的工具：\nhugo stack 主题 github giscus 是评论接口，也很快。使用的也是 github 的服务，利用的是 github discussion，所以，比 discus 之类的小厂要快。稳定性倒是差不多。以及，github 的用户是比较多的，所以会更方便大家评论交流，这一点很重要。 neovim/vscode git flaticon 用来挑选网站的 favicon 的。 安装 本文在Manjaro系统下操作。\n首先需要安装一些依赖软件：go​ hugo​ dart-sass​\n参考链接：manjaro go环境搭建、PaperMod Installation\n1 2 3 sudo pacman -S go sudo pacman -S hugo sudo pacman -S dart-sass 安装主题 两种方式：使用主题给出的模板仓库直接创建仓库；本地建立仓库，通过 git submoudle 安装。\n第一种直接使用模板的方式不会下载主题仓库，修改起来较为麻烦。且使用的配置文件格式是 toml，写起来也繁琐。但好处是不需要自己对网页做各种修改，可以直接使用。\n第二种方式可以修改主题，但是连同一些网页基础的设置也需要自己手动配，可以参考主题仓库中的示例。\n值得注意的是，第二种方式下载的主题其各种配置和hugo所创建的新的站点文件夹结构很类似，我们优先在hugo的根目录下进行修改，hogu会优先使用根目录下的文件，这样就可以覆盖主题中的一些配置。例如\n存在文件 themes/Stack/assets/icons/user.svg，我们可以直接在根目录下创建同名文件，hugo就会优先使用根目录下的 user.svg，而不是themes下的。\n使用 git 模板 参考 github.com/CaiJimmy/hugo-theme-stack-starter。\n采用 github template 的形式直接使用主题提供的模板创建仓库，并将仓库设置为github page。且该模板已经配置了github action。\n先按照 readme 中的指示，使用 stack starter 作为模板创建仓库。点击Use this template​。\n​​\n这里注意，用这个模板创建的不是\u0026lt;username\u0026gt;.github.io​为名称的仓库，而是创建一个其他命名的私有仓库，因为这里存放的是源码，我们期望源码为私有仓库，在部署的时候再将其部署到\u0026lt;username\u0026gt;.github.io​为名称的仓库。\n然后将源码下载到本地，我们对其部署的方式进行修改。\n要从源码仓库部署到站点仓库，则需要我们使用 PAT（Personal access tokens）访问权限。\n生成PAT 只有从源码仓库部署到其他仓库需要生成PAT，并在源码仓库中将PAT保存为Actions secrets​变量。\n使用时，在action​文件中引用secrets​设置的变量即可。\n例如，在源码仓库设置的 PAT 名称为HUGO_BUILD，就可以按照下列方式使用。具体语法要查看使用的action​方法的说明文档。例如JamesIves/github-pages-deploy-action@v4​。\n1 2 3 4 5 6 7 8 9 name: Deploy 🚀 uses: JamesIves/github-pages-deploy-action@v4 # 一个自动发布github pages的action with: repository-name: codetang-2417/codetang-2417.github.io token: ${{ secrets.HUGO_BUILD }} branch: main folder: public clean: true single-commit: true 生成Personal access tokens\n点击个人头像，选择 Setting​，拉到最低下，选择Developer Settings​-\u0026gt;Personal Access Tokens​-\u0026gt;Tokens​。\n​​\n选择Generate new token​\n​​\n创建后需要马上复制生成的Personal Access Tokens​，因为后续将看不到该Personal Access Tokens​。\n生成Actions secrets\n接下来在源码repo中添加上面的personal access token，进入repo的 Settings​-\u0026gt;Secrets and variable​-\u0026gt;Actions secrets​一栏，选择New repository secret​并添加。\n​​\n配置 在hugo的配置文件 config/_default/config.toml 更改 base url：\n1 2 # Change baseurl before deploy baseurl = \u0026#34;https://codetang-2417.github.io/\u0026#34; 然后 git push 到 github，等待 deploy 任务完成，就可以正常通过网址 https://codetang-2417.github.io​ 访问了。如果直接使用源码仓库作为 git page的域名仓库，则需要在网址最后加上仓库名，否则会导致访问网站时 css 加载不出来等问题（且涉及到绝对域名地址引用位置的也需要修改）。\n下面的部分就是修改模板中的git action​文件，使之部署到其他仓库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 name: Deploy to Github Pages on: push: branches: [master] # 这里的意思是当 master 分支发生push的时候，运行下面的jobs pull_request: branches: [master] jobs: build: runs-on: ubuntu-latest permissions: # Give the default GITHUB_TOKEN write permission to commit and push the # added or changed files to the repository. contents: write steps: - uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Cache Hugo resources uses: actions/cache@v4 env: cache-name: cache-hugo-resources with: path: resources key: ${{ env.cache-name }} - uses: actions/setup-go@v5 with: go-version: \u0026#34;^1.17.0\u0026#34; - run: go version - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build run: hugo --minify --gc --cleanDestinationDir - name: Deploy 🚀 uses: JamesIves/github-pages-deploy-action@v4 # 一个自动发布github pages的action with: repository-name: codetang-2417/codetang-2417.github.io token: ${{ secrets.HUGO_BUILD }} branch: main folder: public clean: true single-commit: true 手动安装 创建一个新站点，这里可以参考 hugo 官网的指导。\n以及这篇文章，介绍的很详细：krislinzhao.github.io/docs/create-a-wesite-using-github-pages-an\u0026hellip;\n有一些主题默认的配置文件格式是yaml，需要使用 \u0026ndash;format 指定为yaml。\n1 hugo new site \u0026lt;name of site\u0026gt; --format yaml ​​\n然后进入站点文件夹，配置git\n1 2 3 4 5 cd LingLong git init git add . git branch -m main git commit -m \u0026#34;Framwork: Init Hugo new site.\u0026#34; 导入子模块\n1 git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack 同样需要注意，在hugo的配置文件中，将仓库名加在 base url后。\n1 2 # Change baseurl before deploy baseurl = \u0026#34;https://codetang-2417.github.io/HugoStack/\u0026#34; 这种方式由于hugo根目录中没有任何配置，因此需要自己手动配置。参考主题目录中的 exampleSite文件夹。\n简单介绍hugo的目录中各个文件夹的含义。\narchetypes：存放用 hugo 命令新建的 Markdown 文件应用的 front matter 模版 content：存放内容页面，比如「博客」、「读书笔记」等 layouts：存放定义网站的样式，写在layouts​文件下的样式会覆盖安装的主题中的 layouts​文件同名的样式 static：存放所有静态文件，如图片 data：存放创建站点时 Hugo 使用的其他数据 public：存放 Hugo 生成的静态网页 themes：存放主题文件 config.toml：网站配置文件 本文不采用这种方式，节省时间。\n配置 stack 主题 这里不选用 PaperMod，因为这个主题总有一些小问题，还需要自行修改大量的代码。\n以下基于 git 模板的仓库。\n参考：stack.jimmycai.com/config/，说明中写的很详细，每一个字段的作用。\n简单说明一下该主题中的各个文件夹的作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ tree -d . ├── assets │ ├── img │ └── scss ├── config │ └── _default ├── content │ ├── categories │ │ └── example-category │ ├── page │ │ ├── archives │ │ ├── links │ │ └── search │ └── post │ ├── hello-world │ ├── image-gallery │ ├── markdown-syntax │ ├── math-typesetting │ └── shortcodes assets：存放图片，scss样式\nconfig：存放hugo和主题配置，toml 格式，分文件配置各个参数，比较清晰明了。\ncontent：博文内容存放位置。\n其中 page 存放是导航栏的内容，post 存放文章的内容，categories 为分类。page和post的文件结构一样，每一篇文章单独一个文件夹，里面的 index.md为正文内容，还可以存放一些图片，可以直接在文章中引用。区别在与page和post的 frontmatter 中的layout字段不同，也就是布局。\npages的 frontmatter如下（即在正文之前的最开头的文字）\n1 2 3 4 5 6 7 8 9 10 11 --- title: \u0026#34;Archives\u0026#34; date: 2022-03-06 layout: \u0026#34;archives\u0026#34; slug: \u0026#34;archives\u0026#34; menu: main: weight: 2 params: icon: archives --- menu后续的内容是菜单层级。\npost frontmatter如下：\n1 2 3 4 5 6 7 8 9 10 11 12 --- title: Hello World description: Welcome to Hugo Theme Stack slug: hello-world date: 2022-03-06 00:00:00+0000 image: cover.jpg categories: # 分类，可以在归档界面看到 - Example Category tags: - Example Tag weight: 1 # You can add weight to some posts to override the default sorting (date descending) --- 以上是我们在平时写文章时最主要用到的部分。\ncategories 为分类，在这下面创建的文件和显示在分类栏，即便没有文件被分在这个类别也会显示。如果categories中没有，但是文章中的 frontmatter引用了，则会自动显示，而不需要在这个目录下创建。\n其格式如下：content/categories/example-category/_index.md\n1 2 3 4 5 6 7 8 9 10 --- title: Example Category description: A description of this category image: # Badge style style: background: \u0026#34;#2a9d8f\u0026#34; color: \u0026#34;#fff\u0026#34; --- 一些基本信息的配置 修改文件：config/_default/config.toml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # Change baseurl before deploy baseurl = \u0026#34;https://codetang-2417.github.io/\u0026#34; copyright = \u0026#34;LingLong\u0026#39;s Blog\u0026#34; # 网站的版权声明，通常显示在页脚 languageCode = \u0026#34;zh-cn\u0026#34; title = \u0026#34;LingLong\u0026#34; # 站点标题 # Theme i18n support # Available values: en, fr, id, ja, ko, pt-br, zh-cn, zh-tw, es, de, nl, it, th, el, uk, ar defaultContentLanguage = \u0026#34;zh-cn\u0026#34; # Set hasCJKLanguage to true if DefaultContentLanguage is in [zh-cn ja ko] # This will make .Summary and .WordCount behave correctly for CJK languages. hasCJKLanguage = true # Change it to your Disqus shortname before using disqusShortname = \u0026#34;Ling\u0026#34; # 标签页简称 enableRobotsTXT = true # 允许生成 robots.txt buildDrafts = false # 构建时是否包括草稿 buildFuture = false # 构建未来发布的内容 buildExpired = false # 构建过期的内容 enableEmoji = true [pagination] pagerSize = 8 # 首页最多容纳的文章数量 配置导航栏 修改文件：config/_default/menu.toml，这里的导航栏只能新增，不能修改已有的。\n推荐直接在 page文件夹中添加page时，在 frontmatter 里添加。\n详见：stack.jimmycai.com/config/menu\n配置评论 这里的评论使用了 giscus 插件。\n根据 giscus 官网的 指导，最后生成一份代码，主要是安装 github app和开启discussion\ngiscus app安装\n​​\n然后点击 app 旁边的链接进入app页面。\n​​\n然后可以先去站点仓库，Setting -\u0026gt; General -\u0026gt; Features，打开disscusion​。\n打开后，回到giscus​，填一些配置，主要是仓库名称，mapping方式。\n​​\n然后在该网页中的找到这段配置代码：\n​​\n将其填入到配置文件 config/_default/params.toml 中，主要是 repoId，categoryId\n1 2 3 4 5 6 7 8 9 10 [comments.giscus] repo = \u0026#34;codetang-2417/codetang-2417.github.io\u0026#34; repoID = \u0026#34;xxxxxxxxx\u0026#34; category = \u0026#34;Announcements\u0026#34; categoryID = \u0026#34;xxxxxxxxx\u0026#34; mapping = \u0026#34;pathname\u0026#34; lightTheme = \u0026#34;light\u0026#34; darkTheme = \u0026#34;dark\u0026#34; reactionsEnabled = 1 emitMetadata = 0 下面给出常见的几种 frontmatter page 1 2 3 4 5 6 7 8 9 10 11 --- title: \u0026#34;Archives\u0026#34; date: 2022-03-06 layout: \u0026#34;archives\u0026#34; slug: \u0026#34;archives\u0026#34; menu: main: # 菜单层级 weight: 2 # 用于排序 params: icon: archives # 图标 --- 其中 icon存放于 themes/xxx/assets/icons 或者 根目录assets/icons。\n主题自带的icon有：\n1 2 archives.svg back.svg brand-twitter.svg clock.svg date.svg home.svg language.svg messages.svg search.svg toggle-left.svg user.svg arrow-back.svg brand-github.svg categories.svg copyright.svg hash.svg infinity.svg link.svg rss.svg tag.svg toggle-right.svg post 1 2 3 4 5 6 7 8 9 10 11 12 13 --- title: Markdown Syntax Guide date: 2023-09-07 description: Sample article showcasing basic Markdown syntax and formatting for HTML elements. tags: # 自定义tag - markdown - css - html - themes categories: # 自定义分类，可以在 content/categories/ 创建更详细描述 - themes - syntax --- 例如，分类 example-category，其文件夹下存放文件 _index.md\n1 2 $ ls content/categories/example-category  ✔ _index.md _index.md内容为\n1 2 3 4 5 6 7 8 9 10 --- title: Example Category description: A description of this category image: # Badge style style: background: \u0026#34;#2a9d8f\u0026#34; color: \u0026#34;#fff\u0026#34; --- 编写和发布 在博客搭建起来以后，我尝试过 siyuan 的一键发布工具，但是效果不好，不能处理本地图片，需要图床，但 hugo 本身是静态网页，图片也是存在 git 仓库中，是可以直接访问的。因此，还是选择在 siyuan 中编写完导出 md 文件夹，手动复制到本地仓库并上传。\n参考来源 使用 Github 记录笔记和搭建 blog\n思源笔记一键发布至Hexo、Hugo、Jekyll、Vitepress、Vuepress博客（github）并通过github action构建page并同步gitee page、GitHub Pages\nHugo + Github免费搭建博客，并实现自动化部署\n‍\n","date":"2024-09-15T09:09:00+08:00","permalink":"https://codetang-2417.github.io/p/%E5%9F%BA%E4%BA%8E-hugo-%E5%92%8C-github-pages%E6%90%AD%E5%BB%BAbolg/","title":"基于 Hugo 和 github pages搭建bolg"},{"content":"　使用命令useradd​。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 $ useradd -h Usage: useradd [options] LOGIN useradd -D useradd -D [options] Options: --badnames do not check for bad names -b, --base-dir BASE_DIR base directory for the home directory of the new account --btrfs-subvolume-home use BTRFS subvolume for home directory -c, --comment COMMENT GECOS field of the new account -d, --home-dir HOME_DIR home directory of the new account -D, --defaults print or change default useradd configuration -e, --expiredate EXPIRE_DATE expiration date of the new account -f, --inactive INACTIVE password inactivity period of the new account -g, --gid GROUP name or ID of the primary group of the new account -G, --groups GROUPS list of supplementary groups of the new account 新用户需要添加到的其他组的组名的列表 -h, --help display this help message and exit -k, --skel SKEL_DIR use this alternative skeleton directory -K, --key KEY=VALUE override /etc/login.defs defaults -l, --no-log-init do not add the user to the lastlog and faillog databases -m, --create-home create the user\u0026#39;s home directory -M, --no-create-home do not create the user\u0026#39;s home directory -N, --no-user-group do not create a group with the same name as the user -o, --non-unique allow to create users with duplicate (non-unique) UID -p, --password PASSWORD encrypted password of the new account -r, --system create a system account -R, --root CHROOT_DIR directory to chroot into -P, --prefix PREFIX_DIR prefix directory where are located the /etc/* files -s, --shell SHELL login shell of the new account -u, --uid UID user ID of the new account -U, --user-group create a group with the same name as the user -Z, --selinux-user SEUSER use a specific SEUSER for the SELinux user mapping --extrausers Use the extra users database 使用useradd创建新用户，创建家目录，指定用户id和组id，以及默认的shell，并将其添加到sudo组。需要保证组id在useradd之前已经创建。\n1 groupadd -g 1000 dev \u0026amp;\u0026amp; useradd -ms /bin/bash -u 1000 -g 1000 -G sudo ${username} ‍\n添加到sudo组：\n用 usermod 命令可以将现有用户添加到附加组，例如：\n1 2 3 4 5 sudo usermod -aG sudo ${user} -a 选项表示追加（append），即将用户添加到指定组而不从现有组中移除。 sudo usermod -aG docker $USER 将当前用户添加到docker组 删除用户以及其用户目录\n1 sudo userdel -r username 脚本 使用方法：先按照下面的脚本建立 xstartup、vnc_run.sh、addUser.sh 并放在通用路径。然后运行 ./addUser.sh username​\n脚本：/home/vnc_example/xstartup，避免使用ubuntu自带的gnome，目前的版本中出现锁屏无法输入密码的问题。\n1 2 3 4 5 6 7 8 9 10 #!/bin/sh export XKL_XMODMAP_DISABLE=1 export XDG_CURRENT_DESKTOP=\u0026#34;GNOME-Flashback:GNOME\u0026#34; export XDG_MENU_PREFIX=\u0026#34;gnome-flashback-\u0026#34; # 服务器物理显示器会默认使用显示端口 5901，需要确保 VNC端口以及配置 不与现有的 GNOME 会话发生冲突。 unset SESSION_MANAGER unset DBUS_SESSION_BUS_ADDRESS gnome-session --session=gnome-flashback-metacity --disable-acceleration-check 脚本：/home/vnc_run.sh\n1 2 #! /bin/bash vncserver -geometry 1920x1080 :2 -localhost no # :1 reserved for local connection offline. 脚本：addUser.sh​，创建新用户，并为其分配home空间、vnc设置（需要手动更改端口号）。创建过程中会使用上面提到的两个脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #!/bin/bash set -e # 若有命令出错，立即退出 # set -x # 调试模式 # 检查是否输入了用户名 if [ -z \u0026#34;$1\u0026#34; ]; then echo -e \u0026#34;\\033[31mError: Please provide a username.\\033[0m\u0026#34; exit 1 fi # 获取用户名 username=$1 # 创建用户并将其添加到 docker 组 if sudo useradd -ms /bin/bash -G docker \u0026#34;$username\u0026#34;; then echo -e \u0026#34;\\033[32mUser $username added successfully and added to docker group.\\033[0m\u0026#34; else echo -e \u0026#34;\\033[31mFailed to add user $username.\\033[0m\u0026#34; exit 1 fi # 设置用户密码 echo -e \u0026#34;\\033[33mPlease set the password for the new user: $username\\033[0m\u0026#34; sudo passwd \u0026#34;$username\u0026#34; # 确保 .vnc 目录存在 sudo mkdir -p /home/\u0026#34;$username\u0026#34;/.vnc sudo chown \u0026#34;$username\u0026#34;:\u0026#34;$username\u0026#34; /home/\u0026#34;$username\u0026#34;/.vnc # 复制 VNC 脚本 if sudo cp /home/vnc_run.sh /home/\u0026#34;$username\u0026#34;/; then sudo chown \u0026#34;$username\u0026#34;:\u0026#34;$username\u0026#34; /home/\u0026#34;$username\u0026#34;/vnc_run.sh echo -e \u0026#34;\\033[32mvnc.sh copied successfully to /home/$username.\\033[0m\u0026#34; else echo -e \u0026#34;\\033[31mFailed to copy vnc.sh to /home/$username.\\033[0m\u0026#34; exit 1 fi # 复制 xstartup 配置文件 if sudo cp /home/vnc_example/xstartup /home/\u0026#34;$username\u0026#34;/.vnc/; then sudo chown \u0026#34;$username\u0026#34;:\u0026#34;$username\u0026#34; /home/\u0026#34;$username\u0026#34;/.vnc/xstartup sudo chmod +x /home/\u0026#34;$username\u0026#34;/.vnc/xstartup echo -e \u0026#34;\\033[32mxstartup copied successfully to /home/$username/.vnc.\\033[0m\u0026#34; else echo -e \u0026#34;\\033[31mFailed to copy xstartup to /home/$username/.vnc.\\033[0m\u0026#34; exit 1 fi # 在 ~/.profile 文件中添加自动启动 VNC 的命令 vnc_run_script=\u0026#34;/home/$username/vnc_run.sh\u0026#34; profile_file=\u0026#34;/home/$username/.profile\u0026#34; if ! sudo grep -q \u0026#34;$vnc_run_script\u0026#34; \u0026#34;$profile_file\u0026#34;; then echo \u0026#34;$vnc_run_script\u0026#34; | sudo tee -a \u0026#34;$profile_file\u0026#34; \u0026gt; /dev/null sudo chown \u0026#34;$username\u0026#34;:\u0026#34;$username\u0026#34; \u0026#34;$profile_file\u0026#34; echo -e \u0026#34;\\033[32mAdded VNC auto-start to $username\u0026#39;s .profile.\\033[0m\u0026#34; else echo -e \u0026#34;\\033[33mVNC auto-start script already exists in $username\u0026#39;s .profile.\\033[0m\u0026#34; fi # 输出提示修改 VNC 端口 echo -e \u0026#34;\\033[31mPlease modify the VNC port manually for user $username in $vnc_run_script if needed.\\033[0m\u0026#34; # 添加成功创建用户的提示 echo -e \u0026#34;\\033[32mAdd user $username in this server successfully.\\033[0m\u0026#34; ‍\n","date":"2024-06-08T09:56:31+08:00","permalink":"https://codetang-2417.github.io/p/ubuntu%E5%88%9B%E5%BB%BA%E6%96%B0%E7%94%A8%E6%88%B7%E5%B9%B6%E5%88%86%E9%85%8Dvnc%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/","title":"ubuntu创建新用户并分配VNC远程桌面"},{"content":"　本文介绍在 iPhone 上下载 ChatGPT并订阅 GPT PLUS。\n参考：最新ChatGPT Plus订阅开通方法（支付宝礼品卡）\n先需要一个免税区美区ID：注册美区账号\n支付宝购买 支付宝右上角切换地区到美国\n搜索：礼品卡（不要搜 apple礼品卡）\n选择 pockyt shop\n第二页选择app store进行购买，需要进行注册\n购买后将礼品卡号码复制到app store进行充值\n订阅 使用美区 Apple ID在 App Store 上登陆（注意：一定 不要 在设置中登陆，会导致锁机！）\n搜索 ChatGPT，下载 OpenAI 版本的官方App。\n进入后直接使用AppleID登陆，然后就可以点击开通Plus，自动从 App Store的已经充值的余额中扣除。\n‍\n","date":"2024-03-29T09:48:59+08:00","permalink":"https://codetang-2417.github.io/p/ios-%E8%AE%A2%E9%98%85gpt4-%E8%B4%AD%E4%B9%B0%E7%A4%BC%E5%93%81%E5%8D%A1/","title":"IOS 订阅GPT4-购买礼品卡"},{"content":"　参考：第 11 章 排序\n排序算法的评价维度 运行效率 ：我们期望排序算法的时间复杂度尽量低，且总体操作数量较少（时间复杂度中的常数项变小）。对于大数据量的情况，运行效率显得尤为重要。\n就地性：顾名思义，原地排序通过在原数组上直接操作实现排序，无须借助额外的辅助数组，从而节省内存。通常情况下，原地排序的数据搬运操作较少，运行速度也更快。\n稳定性：稳定排序在完成排序后，相等元素在数组中的相对顺序不发生改变。\n稳定排序是多级排序场景的必要条件。假设我们有一个存储学生信息的表格，第 1 列和第 2 列分别是姓名和年龄。在这种情况下，非稳定排序可能导致输入数据的有序性丧失：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 输入数据是按照姓名排序好的 # (name, age) (\u0026#39;A\u0026#39;, 19) (\u0026#39;B\u0026#39;, 18) (\u0026#39;C\u0026#39;, 21) (\u0026#39;D\u0026#39;, 19) (\u0026#39;E\u0026#39;, 23) # 假设使用非稳定排序算法按年龄排序列表， # 结果中 (\u0026#39;D\u0026#39;, 19) 和 (\u0026#39;A\u0026#39;, 19) 的相对位置改变， # 输入数据按姓名排序的性质丢失 (\u0026#39;B\u0026#39;, 18) (\u0026#39;D\u0026#39;, 19) (\u0026#39;A\u0026#39;, 19) (\u0026#39;C\u0026#39;, 21) (\u0026#39;E\u0026#39;, 23) 自适应性：自适应排序能够利用输入数据已有的顺序信息来减少计算量，达到更优的时间效率。自适应排序算法的最佳时间复杂度通常优于平均时间复杂度。\n是否基于比较：基于比较的排序依赖比较运算符（\u0026lt;、=、\u0026gt;）来判断元素的相对顺序，从而排序整个数组，理论最优时间复杂度为 O(nlog⁡n) 。而非比较排序不使用比较运算符，时间复杂度可达 O(n) ，但其通用性相对较差。\n‍\n复杂度为$O(n^2)$的简单排序方式，为：冒泡、选择、插入\n线性对数阶 $O(nlog_2n)$ 排序：快速排序、堆排序和归并排序\n‍\n选择排序 选择排序（selection sort）：开启一个循环，每轮从未排序区间选择最小的元素，将其放到已排序区间的末尾。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /* 选择排序 */ void selectionSort(vector\u0026lt;int\u0026gt; \u0026amp;nums) { int n = nums.size(); // 外循环：[i, n-1)，n-1不需要遍历，一定是最大 // 最后一个元素不需要遍历，因为最后一个元素一定是最大的。 for (int i = 0; i \u0026lt; n - 1; i++) { // 内循环：找到未排序区间内的最小元素，k只是作为记录。实际遍历的还是[i,n]未排序区间 int k = i; for (int j = i + 1; j \u0026lt; n; j++) { if (nums[j] \u0026lt; nums[k]) k = j; // 记录最小元素的索引 } // 将该最小元素与未排序区间的首个元素交换 swap(nums[i], nums[k]); } } 算法特性 时间复杂度为 **$O(n^2)$**​ 、非自适应排序：外循环共 n−1 轮，第一轮的未排序区间长度为 n ，最后一轮的未排序区间长度为 2 ，即各轮外循环分别包含 n、n−1、…、3、2 轮内循环，求和为 $(n−1)(n+2)/2$。\n空间复杂度为 **$O(1)$**​ 、原地排序：指针 i 和 j 使用常数大小的额外空间。\n非稳定排序：在交换元素时，因此可能出现元素相同时被交换到不同的位置，如图\n​​\n‍\n冒泡排序 「冒泡排序 bubble sort」通过连续地比较与交换相邻元素实现排序。这个过程就像气泡从底部升到顶部一样,\n因此得名冒泡排序。实际上，冒泡排序和选择排序原理类似，但冒泡排序的效率更低，因为每一次都需要交换，而选择排序只有在确定是 最小/最大 的时候才会交换。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /* 冒泡排序 */ void bubbleSort(vector\u0026lt;int\u0026gt; \u0026amp;nums) { // 外循环：未排序区间为 [0, i] for (int i = nums.size() - 1; i \u0026gt; 0; i--) { // 内循环：将未排序区间 [0, i] 中的最大元素交换至该区间的最右端 for (int j = 0; j \u0026lt; i; j++) { if (nums[j] \u0026gt; nums[j + 1]) { // 交换 nums[j] 与 nums[j + 1] // 这里使用了 std::swap() 函数 swap(nums[j], nums[j + 1]); } } } } 算法特性 时间复杂度为 **$O(n^2)$**​ 、非自适应排序：外循环共 n−1 轮，第一轮的未排序区间长度为 n-1 ，最后一轮的未排序区间长度为 1 ，即各轮外循环分别包含 n−1、…、3、2 、1轮内循环，求和为 $(n−1)n/2$。而如果引入优化一，则最佳情况下，时间复杂度可达到 O(n) ，即数据全部有序的情况下，只遍历一次就可以得出结果。\n空间复杂度为 **$O(1)$**​ 、原地排序：指针 i 和 j 使用常数大小的额外空间。\n稳定排序：在交换元素时，遇到相同的元素不会交换。\n‍\n效率优化 优化一：设置标志位 我们发现，如果某轮“冒泡”中没有执行任何交换操作，说明数组已经完成排序，可直接返回结果。因此，可以增加一个标志位 flag​ 来监测这种情况，一旦出现就立即返回。\n经过优化，冒泡排序的最差时间复杂度和平均时间复杂度仍为 $O(n^2)$ ；但当输入数组完全有序时，可达到最佳时间复杂度 $O(n)$。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /* 冒泡排序（标志优化）*/ void bubbleSortWithFlag(vector\u0026lt;int\u0026gt; \u0026amp;nums) { // 外循环：未排序区间为 [0, i] for (int i = nums.size() - 1; i \u0026gt; 0; i--) { bool flag = false; // 初始化标志位 // 内循环：将未排序区间 [0, i] 中的最大元素交换至该区间的最右端 for (int j = 0; j \u0026lt; i; j++) { if (nums[j] \u0026gt; nums[j + 1]) { // 交换 nums[j] 与 nums[j + 1] // 这里使用了 std::swap() 函数 swap(nums[j], nums[j + 1]); flag = true; // 记录交换元素 } } if (!flag) break; // 此轮“冒泡”未交换任何元素，直接跳出 } } 优化二：设置结束边界 参考：冒泡排序及其优化（三种优化）\n除了检测是否有交换外，还可以记录上一次交换的位置。最后一次交换的位置之后的数据都是有序的，可以记录上一次最后交换的位置，作为下一次循环的结束边界。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* 冒泡排序（边界）*/ void bubbleSortWithFlag(vector\u0026lt;int\u0026gt; \u0026amp;nums) { int lastSwap = nums.size() - 1; // 外循环：未排序区间为 [0, i] for (int i = nums.size() - 1; i \u0026gt; 0; i--) { int thisTurnLastSwap = lastSwap; // 内循环：将未排序区间 [0, i] 中的最大元素交换至该区间的最右端 for (int j = 0; j \u0026lt; thisTurnLastSwap; j++) { if (nums[j] \u0026gt; nums[j + 1]) { // 交换 nums[j] 与 nums[j + 1] // 这里使用了 std::swap() 函数 swap(nums[j], nums[j + 1]); lastSwap = j; } } if (thisTurnLastSwap == lastSwap) break; // 此轮“冒泡”未交换任何元素，直接跳出 } } 这里将 优化一 的思想融入了。\n优化三：双向冒泡排序 参考：最简单的冒泡排序还能怎么优化?\n双向冒泡排序，又叫鸡尾酒排序（Cocktail Sort）。\n它的过程是：先从左往右比较一次，再从右往左比较一次，然后又从左往右比较一次，以此类推。\n适用于大部分数据已经排序好的情况，可以减少已排序好数据的比较轮数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* 冒泡排序（双向冒泡）*/ function bubbleSortOpt3(vector\u0026lt;int\u0026gt; \u0026amp;nums){ // \u0026lt;== 设置每一轮循环的开始与结束位置 int start = 0, end = nums.size() - 1; while(start \u0026lt; end){ for(int i = start; i \u0026lt; end; i++){ // 从start位置end位置过一遍安排最大值的位置 if(nums[i] \u0026gt; nums[i+1]){ swap(nums[i], nums[i+1]); } } end--; // \u0026lt;== 由于当前最大的数已经放到了 end 位置, 故 end 位置向前移动 for(int i = end; i \u0026gt; start; i--){ // 从end向start位置过一遍, 安排最小值的位置 if(nums[i] \u0026lt; nums[i-1]){ swap(nums[i], nums[i-1]); } } start++; // \u0026lt;== 由于当前最小的数已经放到了 start 位置, 故 start 位置向后移动 } } 插入排序 插入排序（insertion sort）是一种简单的排序算法，它的工作原理与手动整理一副牌的过程非常相似。\n具体来说，我们在未排序区间选择一个基准元素，将该元素与其左侧已排序区间的元素逐一比较大小，并将该元素插入到正确的位置。\n设基准元素为 base​ ，我们需要将从目标索引到 base​ 之间的所有元素向右移动一位，然后将 base​ 赋值给目标索引。\n​​\n插入排序的整体流程如图 11-7 所示。\n初始状态下，数组的第 1 个元素已完成排序。\n选取数组的第 2 个元素作为 base​ ，将其插入到正确位置后，数组的前 2 个元素已排序。\n选取第 3 个元素作为 base​ ，将其插入到正确位置后，数组的前 3 个元素已排序。\n以此类推，在最后一轮中，选取最后一个元素作为 base​ ，将其插入到正确位置后，所有元素均已排序。\n​​\n1 2 3 4 5 6 7 8 9 10 11 12 13 /* 插入排序 */ void insertionSort(vector\u0026lt;int\u0026gt; \u0026amp;nums) { // 外循环：已排序区间为 [0, i-1] for (int i = 1; i \u0026lt; nums.size(); i++) { int base = nums[i], j = i - 1; // 内循环：将 base 插入到已排序区间 [0, i-1] 中的正确位置 while (j \u0026gt;= 0 \u0026amp;\u0026amp; nums[j] \u0026gt; base) { nums[j + 1] = nums[j]; // 将 nums[j] 向右移动一位 j--; } nums[j + 1] = base; // 将 base 赋值到正确位置 } } 算法特性 时间复杂度为 **$O(n^2)$**​ 、自适应排序：在最差情况下，每次插入操作分别需要循环 n−1、n−2、…、2、1 次，求和得到 (n−1)n/2 ，因此时间复杂度为 $O(n^2)$ 。在遇到有序数据时，插入操作会提前终止。当输入数组完全有序时，插入排序达到最佳时间复杂度 $O(n)$ 。 空间复杂度为 **$O(1)$**​ 、原地排序：指针 i 和 j 使用常数大小的额外空间。 稳定排序：在插入操作过程中，我们会将元素插入到相等元素的右侧，不会改变它们的顺序。 插入排序的优势 插入排序的时间复杂度为 $O(n^2)$ ，而我们即将学习的快速排序的时间复杂度为 $O(n\\ log\\ ⁡n)$ 。尽管插入排序的时间复杂度更高，但在数据量较小的情况下，插入排序通常更快。\n这个结论与线性查找和二分查找的适用情况的结论类似。快速排序这类 $O(n\\ log⁡\\ n)$ 的算法属于基于分治策略的排序算法，往往包含更多单元计算操作。而在数据量较小时，$n^2$ 和 $n\\ log\\ ⁡n$ 的数值比较接近，复杂度不占主导地位，每轮中的单元操作数量起到决定性作用。\n实际上，许多编程语言（例如 Java）的内置排序函数采用了插入排序，大致思路为：对于长数组，采用基于分治策略的排序算法，例如快速排序；对于短数组，直接使用插入排序。\n虽然冒泡排序、选择排序和插入排序的时间复杂度都为 $O(n^2)$ ，但在实际情况中，插入排序的使用频率显著高于冒泡排序和选择排序，主要有以下原因。\n冒泡排序基于元素交换实现，需要借助一个临时变量，共涉及 3 个单元操作；插入排序基于元素赋值实现，仅需 1 个单元操作。因此，冒泡排序的计算开销通常比插入排序更高。 选择排序在任何情况下的时间复杂度都为 $O(n^2)$ 。如果给定一组部分有序的数据，插入排序通常比选择排序效率更高。 选择排序不稳定，无法应用于多级排序。 快速排序 快速排序（quick sort）是一种基于分治策略的排序算法，运行高效，应用广泛。和归并排序相同点都是使用分治策略，不同点在与快速排序是根据基准数划分，先划分，再排序，归并排序是先分组，再排序，再合并。\n快速排序的核心操作是“哨兵划分”，其目标是：选择数组中的某个元素作为“基准数”，将所有小于基准数的元素移到其左侧，而大于基准数的元素移到其右侧。具体来说，哨兵划分的流程如图 11-8 所示。\n选取数组最左端元素作为基准数，初始化两个指针 i​ 和 j​ 分别指向数组的两端。 设置一个循环，在每轮中使用 i​（j​）分别寻找第一个比基准数大（小）的元素，然后交换这两个元素。 循环执行步骤 2.​ ，直到 i​ 和 j​ 相遇时停止，最后将基准数交换至两个子数组的分界线。 对左右两个子数组继续快速排序。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /* 哨兵划分 */ int partition(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int right) { // 以 nums[left] 为基准数 int i = left, j = right; while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; nums[j] \u0026gt;= nums[left]) j--; // 从右向左找首个小于基准数的元素 while (i \u0026lt; j \u0026amp;\u0026amp; nums[i] \u0026lt;= nums[left]) i++; // 从左向右找首个大于基准数的元素 swap(nums[i], nums[j]); // 交换这两个元素 } swap(nums[i], nums[left]); // 将基准数交换至两子数组的分界线 return i; // 返回基准数的索引 } /* 快速排序 */ void quickSort(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int right) { // 子数组长度为 1 时终止递归 if (left \u0026gt;= right) return; // 哨兵划分 int pivot = partition(nums, left, right); // 递归左子数组、右子数组 quickSort(nums, left, pivot - 1); quickSort(nums, pivot + 1, right); } 算法特性 时间复杂度为 **$O(n\\ log\\ n)$**​ 、非自适应排序：在平均情况下，哨兵划分的递归层数为 log⁡n ，每层中的总循环数为 n ，总体使用 $O(n\\ log⁡\\ n)$时间。在最差情况下，每轮哨兵划分操作都将长度为 n 的数组划分为长度为 0 和 n−1 的两个子数组，此时递归层数达到 n ，每层中的循环数为 n ，总体使用 $O(n^2)$时间。 空间复杂度为 **$O(1)$**​ 、原地排序：指针 i 和 j 使用常数大小的额外空间。 非稳定排序：在交换基准元素时，有可能会使基准元素被交换到相等元素的后边。 效率优化 优化一：基准数优化 快速排序在某些输入下的时间效率可能降低。举一个极端例子，假设输入数组是完全倒序的，由于我们选择最左端元素作为基准数，那么在哨兵划分完成后，基准数被交换至数组最右端，导致左子数组长度为 n−1、右子数组长度为 0 。如此递归下去，每轮哨兵划分后都有一个子数组的长度为 0 ，分治策略失效，快速排序退化为“冒泡排序”的近似形式。\n为了尽量避免这种情况发生，我们可以优化哨兵划分中的基准数的选取策略。例如，我们可以随机选取一个元素作为基准数。然而，如果运气不佳，每次都选到不理想的基准数，效率仍然不尽如人意。\n需要注意的是，编程语言通常生成的是“伪随机数”。如果我们针对伪随机数序列构建一个特定的测试样例，那么快速排序的效率仍然可能劣化。\n为了进一步改进，我们可以在数组中选取三个候选元素（通常为数组的首、尾、中点元素），并将这三个候选元素的中位数作为基准数。这样一来，基准数“既不太小也不太大”的概率将大幅提升。当然，我们还可以选取更多候选元素，以进一步提高算法的稳健性。采用这种方法后，时间复杂度劣化至$O(n^2)$的概率大大降低。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 int medianThree(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int mid, int right) { int l = nums[left], r = nums[right], m = nums[mid]; if((l \u0026lt;= m \u0026amp;\u0026amp; m \u0026lt;= r) || (r \u0026lt;= m \u0026amp;\u0026amp; m \u0026lt;= l)) { return mid; } if((m \u0026lt;= l \u0026amp;\u0026amp; l \u0026lt;= r) || (r \u0026lt;= l \u0026amp;\u0026amp; l \u0026lt;= m)) { return left; } return right; } int partition(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int right) { int i = left, j = right; int mid = left + (right - left) / 2; mid = medianThree(nums, left, mid, right); swap(nums[left], nums[mid]); while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; nums[j] \u0026gt;= nums[left]) { j--; } while (i \u0026lt; j \u0026amp;\u0026amp; nums[i] \u0026lt;= nums[left]) { i++; } swap(nums[i], nums[j]); } swap(nums[left], nums[i]); return i; } c++的库函数std::sort​函数（基于快速排序、堆排序和插入排序的混合算法）中快排部分，也采用了基准数优化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 template\u0026lt;typename _Iterator, typename _Compare\u0026gt; _GLIBCXX20_CONSTEXPR void __move_median_to_first(_Iterator __result,_Iterator __a, _Iterator __b, _Iterator __c, _Compare __comp) { if (__comp(__a, __b)) { if (__comp(__b, __c)) std::iter_swap(__result, __b); else if (__comp(__a, __c)) std::iter_swap(__result, __c); else std::iter_swap(__result, __a); } else if (__comp(__a, __c)) std::iter_swap(__result, __a); else if (__comp(__b, __c)) std::iter_swap(__result, __c); else std::iter_swap(__result, __b); } template\u0026lt;typename _RandomAccessIterator, typename _Compare\u0026gt; _GLIBCXX20_CONSTEXPR inline _RandomAccessIterator __unguarded_partition_pivot(_RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp) { _RandomAccessIterator __mid = __first + (__last - __first) / 2; std::__move_median_to_first(__first, __first + 1, __mid, __last - 1, __comp); return std::__unguarded_partition(__first + 1, __last, __first, __comp); } 优化二：尾递归优化-空间优化 在某些输入下，快速排序可能占用空间较多。以完全有序的输入数组为例，设递归中的子数组长度为 m ，每轮哨兵划分操作都将产生长度为 0 的左子数组和长度为 m−1 的右子数组，这意味着每一层递归调用减少的问题规模非常小（只减少一个元素），递归树的高度会达到 n−1 ，此时需要占用 O(n) 大小的栈帧空间。\n为了防止栈帧空间的累积，我们可以在每轮哨兵排序完成后，比较两个子数组的长度，仅对较短的子数组进行递归。由于较短子数组的长度不会超过 n/2 ，因此这种方法能确保递归深度不超过 $log⁡\\ n$，从而将最差空间复杂度优化至 $O(log\\ ⁡n)$ 。代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /* 快速排序（尾递归优化） */ void quickSort(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int right) { // 子数组长度为 1 时终止 while (left \u0026lt; right) { // 哨兵划分操作 int pivot = partition(nums, left, right); // 对两个子数组中较短的那个执行快速排序 if (pivot - left \u0026lt; right - pivot) { quickSort(nums, left, pivot - 1); // 递归排序左子数组 left = pivot + 1; // 剩余未排序区间为 [pivot + 1, right] } else { quickSort(nums, pivot + 1, right); // 递归排序右子数组 right = pivot - 1; // 剩余未排序区间为 [left, pivot - 1] } } } 注意 在快速排序的分区算法中，​while​​ 循环的顺序 与 基准元素的位置 密切相关，不能随意颠倒。原因主要有以下两个关键点，并且根据基准位置的不同，处理方式也不同：\n1. 确保每个元素都能正确与基准比较： 因为程序是顺序执行的，在 i 和 j 相差1时，先执行的 while循环，会多一次比较机会，这决定了最后一次比较中的两个数据能够被正确的划分。\n右侧基准时：i​ 指针从左向右寻找第一个 大于基准的元素，j​ 指针从右向左寻找 小于基准的元素。如果 ​i​ 指针先行，它能确保左侧所有元素与基准进行比较，确保小于基准的元素正确地放置在左区间。\n如果颠倒顺序让 j​ 指针先行，可能导致某些靠近基准的元素（特别是小于基准的）无法与基准比较，破坏分区的完整性。 左侧基准时：则相反，应该让 ​j​​ 指针先行，这样可以确保右侧的元素都能正确地与基准比较，找到第一个小于基准的元素。\n2. 确保最后交换时基准与大于等于基准的元素交换： 右侧基准时：如果 ​i​​ 指针先行，最后一次交换时，i​ 会停在 大于等于基准的元素 上，这样交换后能确保分区结构正确，即 左区间 \u0026lt; 基准 \u0026lt; 右区间。\n如果 j​ 指针先行，则可能导致 i​ 停在一个 小于等于基准的元素 上，导致错误分区，破坏了左小右大的结构。 左侧基准时：同理，应让 ​j​​ 指针先行，这样确保最后交换时基准能够与 小于等于基准的元素 交换，保证 左区间 \u0026lt; 基准 \u0026lt; 右区间。\n实例说明 例如当 i = 0, j = 1，且 nums[0] \u0026lt;= nums[right] 时，上面的代码，会先执行 i++的循环，则 nums[i]就能够和基准 nums[right] 比较，i = j = 1。而若 j\u0026ndash; 的循环在最前面，则先执行 j\u0026ndash;的循环，这之后 i \u0026lt; j就不成立了，nums[i]就无法和基准比较，那么 i = j =0，此时大循环结束，需要交换nums[right] 和 nums[i]（i=0），而 nums[0] \u0026lt;= nums[right]，如果交换，则出现了 ​基准 \u0026lt; 右区间 \u0026gt; 左区间​​ 的错误分区。正确的交换应该是 nums[right] 和 nums[1]，保证 ​左区间 \u0026lt; 基准 \u0026lt; 右区间​​。\n下面给出上述阐述的数组：\n1 2 3 4 5 6 7 8 9 10 11 原数组： id 0 1 2 3 nums 1 5 3 2 right = 3, i = 1, j = 1, swap(nums[right], nums[i])后： id 0 1 2 3 nums 1 2 3 5 right = 3, i = 0, j = 0, swap(nums[right], nums[i])后： id 0 1 2 3 nums 2 5 3 1 所以如果我们把基准指针从 left 替换为 right，相应地，while循环的顺序就需要改变为：\n1 2 3 4 5 6 7 8 9 10 11 while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; nums[i] \u0026lt;= nums[right]) {// 从左侧开始找第一个大于基准的位置 i++; } while (i \u0026lt; j \u0026amp;\u0026amp; nums[j] \u0026gt;= nums[right]) {// 从右侧开始找第一个小于基准的位置 j--; } swap(nums[i], nums[j]); } swap(nums[right], nums[i]); 插曲 在 C++ 标准库中，std::sort​ 函数是一种用于对容器或数组中的元素进行排序的函数。它是基于快速排序（Quicksort）、堆排序（Heapsort）和插入排序（Insertion Sort）的混合算法，称为 Introsort。\n关键算法步骤 Introsort 是基于快速排序的，但会在递归深度达到一定程度时切换到堆排序，以防止最坏情况下快速排序退化为 $O(n^2)$ 的时间复杂度。 在排序过程中，对小规模区间使用插入排序，以利用其在小数据集上的高效性。 leetcode上的排序题目：912. 排序数组 中的测试数据增加了有序大数组，对快速排序不友好，会退化为类似冒泡排序的 $O(n^2)$算法，因此，使用快排需要经过基准数优化才能通过，另外，堆排序在这个题目中表现很好，因此C++中的sort函数也会快很多。\n归并排序 待续。\n堆排序 待续。\n","date":"2024-03-20T09:44:18+08:00","permalink":"https://codetang-2417.github.io/p/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","title":"常见排序算法"},{"content":"　参考：git中的.gitignore 的忽略规则、.gitignore文件语法和常见写法、git-scm.com/docs/gitignore\n忽略规则的优先级 ​gitignore​文件中的每一行都指定一个模式。当决定是否忽略该路径的文件时，Git 通常会检查来自多个源的gitignore​模式，按照以下优先级顺序，从最高到最低（在一个优先级内，最后匹配的模式决定结果）：\n从命令行中读取可用的忽略规则，从上往下依次读取 当前目录定义的规则（即：如果在父目录中定义了一些模式，但在子目录的 .gitignore​ 中有冲突的模式，则子目录的规则会优先。） 父级目录定义的规则，依次递推。 $GIT_DIR/info/exclude 文件中定义的规则 core.excludesfile中定义的全局规则 注：这些模式是相对于 .gitignore​ 文件所在位置进行匹配的。这意味着如果 .gitignore​ 文件在某个子目录中，那么它定义的规则只适用于该子目录及其子目录中的文件。称.gitignore​文件所处的目录为根目录。\nPATTERN的格式 Pattern可以理解为我们在gitignore​文件中写下的每一行字符，可以理解为匹配的规则。\n所有空行或者以 #（hash） 开头的行都会被 Git 忽略。其中以 # 开头的行用作注释。\n# 的英文为 hash，对于以哈希开头的Pattern，需要在第一个哈希前面放置一个反斜杠（backslash）（“ \\​ ”）。\\​表示转义。\n末尾的空格也需要加\\​转义，否则空格被忽略。\n前缀“ !​ ”，用于取消之前的排除规则。已经被前面的Pattern所排除的任何匹配文件（且符合当前Pattern的），将再次被包含在内。\n如果文件的开头就是!​那么需要在最开头添加\\​，例如：\\~important!.txt​\n注意： 如果某个文件的上级目录已经被排除（例如上级目录在 .gitignore​ 中被忽略了），则无法通过 \u0026ldquo;!\u0026rdquo; 将该文件重新包括进来。因为 Git 出于性能原因，不会保留已被排除的目录内容，因此即便你试图通过规则重新包括某个文件，这个操作也不会生效。\n举例：\n1 2 qrkernel/ !qrkernel/filelist.mk ​!qrkernel/filelist.mk​操作是无效的，因为qrkernel/​表示排除当前根目录以及子目录中所有的qrkernel​目录。因此，文件filelist.mk​的上级目录已经被排除，所以再次包含filelist.mk​无效。\n正确的写法：\n1 2 qrkernel/** !qrkernel/filelist.mk ​qrkernel/**​只排除qrkernel​目录下的文件和子目录及其内容，不会排除qrkernel​目录本身。\n“/​“（slash）符号用作文件夹分隔符，可以出现在pattern的开头，中间，结尾。\n“/​“出现在pattern的开头或者中间，或者两者同时出现，则表示pattern是.gitignore​所在的目录层级，否则，pattern表示的范围是.gitignore​当前目录及其子目录层级。\n如果模式末尾有“/​“，则该模式将仅匹配目录，否则该模式可以匹配文件和目录。\n例如，模式doc/frotz/​匹配doc/frotz​目录，但不匹配a/doc/frotz​目录；然而frotz/​匹配frotz​和a/frotz​目录（所有路径都以.gitignore​文件所处的文件夹为根目录，相对于该根目录进行匹配）。\n星号（asterisk）“ *​ ”匹配除“/​”之外的任何内容。字符“ ?​ ”匹配除“ /​ ”之外的任意1个字符。范围表示法，例如[a-zA-Z]​ ，可用于匹配范围中的字符之一。有关更详细的说明，请参阅 fnmatch(3) 和 FNM_PATHNAME 标志。\n两个连续的“*​”，在全路径匹配pattern中有特殊的含义\n以**/​开头的pattern，表示在所有的文件夹中进行匹配。例如：\u0026quot;**/foo​\u0026quot;匹配当前根目录及所有子目录下的所有的以foo命名的文件以及文件夹，和patternfoo​等价。\u0026quot;**/foo/bar​\u0026quot;则匹配根目录及子目录下的foo目录下的所有bar​命名的文件及目录。 以“ /**​ ”结尾的pattern，表示匹配目录中的所有内容。例如，“ abc/**​ ”匹配目录根目录下“ abc​ ”目录内的所有文件。 ​/**/​匹配任意目录，例如，“ a/**/b​ ”匹配“ a/b​ ”、“ a/x/b​ ”、“ a/x/y/b​ ”等。 ​.gitignore​只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore​是无效的。例如已经进行了提交，或者add的文件和目录，则需要git rm -r --cached .​ 命令，将当前目录下所有文件从 Git 的暂存区（Index）中移除，但是保留这些文件在工作目录中的状态。这意味着这些文件不再被 Git 跟踪，但仍然会保留在本地文件系统中，不会被删除。\n然后再修改.gitignore​文件，此时git就会按照新修正的.gitignore​进行索引。\n注意：建议只在需要移除的目录下使用该命令，如果在根目录下使用，会直接移除所有的文件索引。\n1 2 3 git rm -r --cached . git add . git commit -m \u0026#39;update .gitignore\u0026#39; 匹配规则举例 文件 .gitignore​ 的格式规范如下：\n可以使用标准的 glob 模式匹配，它会递归地应用在整个工作区中。\n匹配是区分大小写的，如：/abc 和 /Abc 含义不同\n*~ 忽略所有以~结尾的文件（这种文件通常被许多编辑器标记为临时文件）\n空目录（包括隐藏目录）会被忽略，无法提交追踪\n如果不希望空目录被忽略，需要在里头建.gitkeep文件\n所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。\n星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符 （这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）。\n问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符， 表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。\n使用两个星号（ ** ）表示匹配任意中间目录，比如 a/**/z 可以匹配 a/z 、 a/b/z 或 a/b/c/z 等。\n前提约定 约定1\n“当前目录、子目录、子子目录…” 的表述包含的目录是：.gitignore文件所在的目录，以及该目录下的所有目录和它们的所有子目录及子子目录… 总之是这颗目录树的所有节点。\n例如： .gitignore文件在 /Users/stonewang/git-ignore-test/.gitignore，即.gitignore文件所在的目录为/Users/stonewang/git-ignore-test/。 该表述的含义是：以/Users/stonewang/git-ignore-test/作为起点的所有目录树节点\n1 2 3 4 5 6 7 8 9 10 11 12 # 该表述包含了dir1、dir2、dir1_sub、dir1_sub2、dir1_sub_sub、dir1_sub_sub2、dir1_sub2_sub /Users/stonewang/git-ignore-test/ |-------.gitignore | |-------dir1 |\t|----dir1_sub |\t|-----dir1_sub_sub |\t|-----dir1_sub_sub2 |\t|----dir1_sub2 |\t|-----dir1_sub2_sub | |-------dir2 ‍\n其他补充\n目录（即文件夹）的名字有各种表现形式，如显示的、隐藏的、带扩展名的和不带扩展名的。例如：dir、.dir、dir.ext、.dir.ext\n文件名的形式也各种各样，如显示的，隐藏的，带扩展名的，不带扩展名的。如file、.file、file.ext、.file.ext\n在.gitignore中，以 / 结尾的只会匹配目录，不带 / 结尾的匹配文件和目录，注意没有一种写法仅匹配文件的\n在Mac和Windows中都不允许文件之间重名，目录之间重名，目录和文件之间重名。不区分大小写\n在Mac和Windows中，目录名都是允许带点的，如dir.ext 可以作为目录名（看起来就像文件的扩展名）\n详细例子 为了表述准确，引入自创数学符号\n(.gitignore)N 表示.gitignore文件所在的目录+所有子目录包括直接或间接 (.gitignore)O 表示.gitignore文件所在的目录，不包括其任何子目录 写法 作用 dir/ 忽略 (.gitignore)N 中的dir目录（不包含子目录） /dir/ 忽略 (.gitignore)O 中的dir目录 file 忽略(.gitignore)N 中的file 文件\u0026amp;目录（名为file的目录也会被忽略） /file 忽略(.gitignore)O 中的file文件 *.log 忽略(.gitignore)N 中的*.log 文件\u0026amp;目录（符合名字的目录也将被忽略） /dir/file 忽略(.gitignore)O 中的dir目录下的file文件 /dir/Abc* 和 /dir/Abc .java 和/dir/ .java 忽略(.gitignore)O 中的dir目录下符合Abc （或Abc.java或*.java）规则的文件\u0026amp;目录 /dir/Abc*/ 忽略(.gitignore)O 中的dir目录下符合Abc*的目录（不忽略dir下的文件!） /dir/*/ 忽略(.gitignore)O 中的dir目录下的符合*的子目录（注意/sub/file的文件不会忽略） /dir// .txt 忽略(.gitignore)O 中的dir目录下的符合的子目录下的，符合.txt的文件\u0026amp;目录。注意是一个星，仅忽略一层，即/dir/sub/a.txt 和 /dir/sub/sub2/b.txt，仅仅忽略a.txt，不忽略b.txt，另外/dir/k.txt也不会被忽略 /dir/**/*.txt 忽略 (.gitignore)O 中的dir目录下的直接和间接子目录下的，符合*.txt的文件\u0026amp;目录。两个星号表示0-n层级的目录 /sub/** 和 /sub/ 是等价的 亲测。前者表示忽略/sub/下的所有直接或间接的目录和文件（**表示文件和目录，因为没有/结尾），后者表示忽略/sub/下的东西 /sub/**/ 和 /sub/ 是不等价的 亲测。前者明确表示忽略目录除掉了文件，所以对于/sub/file是不会被忽略的。 sub/ 和 /sub/ 含义不同 前者忽略(.gitignore)N下的sub目录，后者忽略(.gitignore)O下的sub sub/abc/ 和 /sub/abc/ 这两个的含义完全相同（有点奇怪，本以为前者是递归所有的目录） **/src/main/java/ 和 src/main/java/ 不等价。前者匹配(.gitignore)N下的src/main/java/ 目录，要满足这个目录的层级结构的。后者等价于/src/main/java/，仅仅忽略(.gitignore)O下的该目录 **/src/main/file.txt 和 src/main/file.txt 不等价。前者匹配(.gitignore)N下的src/main/file.txt，符合这个目录层级结构的将会被忽略，后者等价于/src/main/file.txt，仅仅忽略(.gitignore)O下所匹配的 **/dir/ 和 dir/ 是等价的。上面的例子等价这个不等价，就是因为目录的层级数的问题导致的 **/file.txt 和 file.txt 是等价的。 先后写!a.txt和*.txt 后面的配置覆盖前面的，导致所有*.txt文件都被忽略（有点奇怪，实际测试确实如此） 先后写*.txt 和 !a.txt 正确。能够忽略除了a.txt外的文件。 对于.gitignore文件不在git仓库根目录的情况：参考特殊情况 （参考特殊情况） ","date":"2024-02-22T10:43:52+08:00","permalink":"https://codetang-2417.github.io/p/gitignore/","title":"Gitignore"},{"content":"安装sendmail 1 sudo apt install sendemail 开机自动启动服务 在文件夹：/etc/systemd/system/​ 下创建文件：auto_sendip.service，并填写下列内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Unit] Description=Send ip with email when start machine After=network-online.target Wants=network-online.target [Service] Environment=\u0026#34;LIBVA_DRIVER_NAME=iHD\u0026#34; # 可以去掉，本脚本是从todesk的自启动脚本移植而来 ExecStart=/home/user/send_ip.sh # 绝对地址 Restart=on-failure RestartSec=5s User=user # 想要运行本服务的用户 [Install] WantedBy=multi-user.target 将自启动脚本软链接到系统，并开启开机自启。\n1 2 sudo ln -sf /home/user/auto_sendip.service /usr/lib/systemd/system/auto_sendip.service systemctl enable --now auto_sendip.service send_ip.sh脚本 使用139邮箱作为发送邮箱，开启IMAP/SMTP功能，允许sendemail命令行登陆邮箱并发送邮件。下列的参数-xp后跟的字符串即为客户端授权码。\nsend_mail为发送邮件的139邮箱，accept_mail_1和accept_mail_2为接受信息的邮箱。\n1 2 3 4 5 6 7 8 #! /bin/bash # send_host_ip_to_edu_mail.sh curl -s -o /dev/null \u0026#39;http://10.3.8.211/login\u0026#39; --data \u0026#39;user=202211xxxx\u0026amp;pass=xxxx\u0026#39; # 登陆校园网的用户和密码 sleep 2s echo begin send email ifconfig | grep inet | sendemail -f send_mail -t accept_mail_1 -u ip_of_P920_1 -s smtp.139.com -xu send_mail -xp 授权码 -o tls=no sleep 2s ifconfig | grep inet | sendemail -f send_mail -t accept_mail_2 -u ip_of_P920_1 -s smtp.139.com -xu send_mail -xp 授权码 -o tls=no ‍\n","date":"2024-01-19T15:03:55+08:00","permalink":"https://codetang-2417.github.io/p/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E5%8F%91%E9%80%81ip%E9%82%AE%E4%BB%B6/","title":"服务器开机自动发送ip邮件"},{"content":"　IOS的app store在国区有很多软件不能下载，包括科学上网和一些好用的软件，使用美区的账号登陆app store就可以解除限制（注意：只能在app store中登陆，不能在设置中登陆，否则有可能会激活id锁，导致机器无法使用）\n参考：美区Apple ID注册流程：不需要信用卡、也不需要美国地址、知乎：【2023年】五分钟注册美区AppleID，手把手教，稳定且耐用！\n一、准备工作 1.一个能接收短信的国内手机号2.一个全新邮箱（指从没注册过Apple ID的邮箱）3.美国地址生成器（文中有地址）4.无需任何代理工具\n注意以下四点可以避免很多问题：\n出生日期：一定要设置成大于 18 周岁的日期，否则会导致部分应用由于年龄限制无法使用。\n电子邮件：建议新注册一个全新的从未注册过 Apple ID 的邮箱，比如 163 邮箱，我使用的谷歌邮箱。\n手机号码：亲测，注册过中国区 Apple ID 的手机号码可以用来注册美区账号，不会产生冲突。\n密码：设置密码时，密码中不要包含有名字、生日、邮箱中的信息，否则会卡在验证码那一步。\n‍\n注意事项 1.设置密码时，密码中不要包含前面填写的名字、生日、邮箱中的任何信息，否则可能会卡在验证码那一步，总之就是密码尽量原创一个。\n2.不要在「设置」中登录美区Apple ID，以免造成不必要的麻烦。下载美区 App 只需在 App Store 中登录即可，下载完后再换回国区账号即可，对 iCloud 等不会有任何影响。\n3.如果你有在用Apple Music，切换成美区后会导致已下载的歌曲全被清空。\n4.建议不要把美区 Apple ID 当成主力账号，需要下美区应用时登录就行了，以免出现啥问题。\n二、注册教程 可以使用电脑也可以使用手机。\n首先进入美国 Apple ID 注册页面，复制下方网址至 Safari 浏览器中打开即可进入。\n1 https://appleid.apple.com/account ​ 需要注意以下几点：\n地区需要选择美国 出生年龄必须大于18周岁 电话可以填大陆 邮箱一定要是一个没有注册过的新邮箱 ​​\n接下来验证邮箱地址，输入验证码，继续。确认无误后，就会跳转到你的Appid主页，完成账号注册。\n三、填写付款方式和账单地址 购买app时，需要我们通过AppleID进行付费，否则无法使用。我们需要通过下面的方法生成一个美国地区的地址、电话、邮编等，然后添加到其中。\n生成美国地址建议选以下五个免税州：\n蒙大拿州（Montana） 俄勒冈州（Oregon） 阿拉斯加州（Alaska） 特拉华州（Delaware） 新罕布什尔州（New Hampshire） 打开网址：https://www.meiguodizhi.com/ 生成一个地址\n然后再进入AppleID官网，用新注册的账号登陆、点击付款与配送\n​\n这里有两个选项，第一个是添加付款方式，在开头提到的两个教程的链接中，第一个是点击添加付款方式，并且在弹出的选择框中选择了“无”，但目前实测已经没有这个选项了。第二个选择的是添加购物地址。目前不清楚第二种方法是否有效，这里给出我成功的方法。\n在官网用新账号登陆后，在管理账户里把语言换成英文。\n在手机或者平板的设置—通用/语言与地区，语言改成英文（US），地区改为 美国\n进入App store，用你新注册的苹果号登陆，然后随便下载一个软件，就会提示点选review（检查）。之后就会跳出付款信息的填写，此时会看见强制填写的信用卡号等信息变成了选填，完善完城市街道等基本信息，点选next，就会跳出完成注册的提示。\n四、常见问题汇总 ➊ 手机号码提示错误怎么解决？\n答：看看复制的号码是不是开头有数字\u0026quot;1\u0026quot;或者\u0026quot;+1\u0026quot;，有的话去掉即可。\n➋ 更新 App 的时候显示账号被锁定，但可以下载未下载过的 App 是什么原因？\n答：因为你更新的这个 App 之前是用其他 Apple ID 下载的，所以这个 App 是和你之前下载时的那个 Apple ID 绑定在一起的，所以出现被锁定的提示是原先账号出了问题，和当前账号没关系。解决方法很简单，把 App 卸载重新安装即可。\n➌ 邮编错误怎么办？\n答：估计是地址生成器网站数据库中的部分邮编有误，多生成几份地址试试即可。\n➍ Your request could not be completed at this time 怎么办？\n答：应该是地址生成器生成的号码有问题，电话是 xxx-xxx-xxx 的正常，而 +1xxx-xxx-xxx 就不行。解决方法就是去掉号码开头的\u0026quot;1\u0026quot;或者\u0026quot;+1\u0026quot;即可。\n➎ Cannot be created at this time 怎么办？\n答：切换成 4G、5G、或者换个浏览器、或者用电脑注册，或者次日再试试。\n➏ 注册成功后，如何二次修改美区 Apple ID 的地址、姓名等信息？\n答：进入美国苹果官网，拉到底部找到 manage your apple id，登录后即可修改，不懂英文的同学可借助翻译。\n如果以上回答仍然无法解决你的问题，那建议用百度、必应、知乎等搜索工具去寻找解决方法。\n","date":"2023-10-30T14:58:42+08:00","permalink":"https://codetang-2417.github.io/p/%E6%B3%A8%E5%86%8C%E7%BE%8E%E5%8C%BA%E8%B4%A6%E5%8F%B7/","title":"注册美区账号"},{"content":"linux ubuntu搭建不同用户的VNC 安装tigervnc 1 sudo apt install tigervnc-standalone-server 安装gnome桌面 1 sudo apt install gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal ubuntu-desktop 因为自带的桌面在后续登陆输入密码时有问题，没办法输入文字。因此使用此gnome桌面。安装后还需要配置启动脚本，使得启动后使用ubuntu的默认gnome桌面。\n配置xstartup 如果已经有默认的脚本，则将其备份，如果没有可以直接编辑\n1 2 cp ~/.vnc/xstartup ~/.vnc/xstartup.bak nano ~/.vnc/xstartup 在用户home目录下的.vnc目录下创建xstartup，并添加如下内容\n1 2 3 4 5 6 7 8 9 10 #!/bin/sh export XKL_XMODMAP_DISABLE=1 export XDG_CURRENT_DESKTOP=\u0026#34;GNOME-Flashback:GNOME\u0026#34; export XDG_MENU_PREFIX=\u0026#34;gnome-flashback-\u0026#34; # 服务器物理显示器会默认使用显示端口 5901，需要确保 VNC端口以及配置 不与现有的 GNOME 会话发生冲突。 unset SESSION_MANAGER unset DBUS_SESSION_BUS_ADDRESS gnome-session --session=gnome-flashback-metacity --disable-acceleration-check 然后赋予执行权限\n1 chmod 777 ~/.vnc/xstartup 测试 使用下列命令将vnc服务运行在5902端口，不建议使用5901作为默认显示端口，因为物理显示器会默认使用5901。\n1 vncserver -geometry 1920x1080 :2 -localhost no 使用 vncserver -list​ 获取端口号：\n​​\nvnc脚本 将启动脚本写成sh文件，便于执行\n1 2 #! /bin/bash vncserver -geometry 1920x1080 :2 -localhost no # :1 reserved for local connection offline. 添加权限\n1 chmod 777 vnc_run.sh :2表示使用的端口为5902，如果不指定，会自动分配，这样的话，就需要先shell登陆，查看端口号，然后再登陆vnc。\n打开其他图形应用没有反应 如果可以右键打开终端，但是打开文件夹之类的应用没有反应。就在终端中输入：xhost +​。（仅仅在图形界面下有效，shell中无效）\n登陆shell自动启动vnc 为了能够让每个用户都使用vnc，需要让每个用户登录时自启动vnc，在用户目录下的.profile​文件中添加运行vnc的脚本。当用户登录shell时，就会运行一次vnc启动脚本。（这样就需要固定显示端口，否则将建立多个vnc端口）\n例如，在 ～/.profile​中的末尾添加一行：/home/user/vnc_run.sh​\n​～/.bash_profile​ 或 ～/.profile​ ：每个用户都可使用该文件，输入专用于当前用户使用的shell信息。当用户登录时，该文件仅仅执行一次！默认情况下，设一些环境变量，执行用户的.bashrc文件。\n为新用户添加vnc 若为一个新用户添加vnc支持，则需要完成本文中的 配置xstartup、vnc脚本、登陆shell自动启动vnc 等三个部分。\n‍\n","date":"2023-10-25T20:36:04+08:00","permalink":"https://codetang-2417.github.io/p/linux-ubuntu%E6%90%AD%E5%BB%BA%E4%B8%8D%E5%90%8C%E7%94%A8%E6%88%B7%E7%9A%84vnc/","title":"linux ubuntu搭建不同用户的VNC"},{"content":"　参考链接：宿主机利用在虚拟机中建立的VPN加密隧道连接内网、在宿主机中使用虚拟机的VPN连接\n整体思想是：\n建立一张单独的host-only网卡，使得虚拟机和宿主机之间可以通信，利用windows的网络分享功能，将VPN的网卡的网络分享到这张host-only网卡。那么访问这张host-only网卡，就可以访问到VPN的网络。而host-only网卡可以被主机访问到。因此，就是实现了主机通过虚拟机的VPN进行访问的功能。但虚拟机仍然需要一张可以直接上网的网卡。因为虚拟机需要正常和外界通信，因此主机需要为虚拟机创建两张独立的网卡。\n注意：本文的应用场景是在非校园网环境，Linux系统通过虚拟机的VPN来访问校园网资源，在上述参考链接中，其中一个虚拟机使用的是桥接网卡上网，另一个使用的是网络地址转换NAT上网。\n根据我的测试，校园网环境可能会阻止桥接模式下虚拟机获取 ipv4 地址，我们学校最开始允许宿舍有线网络上网，这时还可以通过桥接模式获取到ipv4的地址。后面禁止了有线网络，现在我的虚拟机桥接模式在校园网环境中就获取不到ipv4地址了。于是我在校园网中只能使用NAT模式上网。\n但在公司时，虚拟机使用NAT上网并在开启VPN后，整个虚拟机将无法访问网络。这应该跟网络地址转换NAT有关，因为使用该方法，虚拟机获取的ip地址是10.0.2.16，可能跟VPN代理的10.0.0.0网段有冲突。导致最后虚拟机无法正常上网。\n解决方案就是：在学校校园网用虚拟机NAT上网，在校园网以外的地方，用桥接网卡的方式上网。\n为了方便，我创建了三张网卡：NAT、host-only、桥接。便于在NAT和host-only之间切换。\n虚拟机添加host-only网络 virtaulBox建立host-only网卡 选中工具-\u0026gt;网络，然后建立一个host-only网络\n​​\n点击DHCP服务器，启动服务器，也可以不使用DHCP。区别在与在后续Linux宿主机添加路由节点时，DHCP分配到的网址可能不唯一，每次都需要重新查看。而使用默认地址，则固定为192.168.137.1。\n这里需要注意，VirtualBox \u0026gt;= 6.1.28 ​的版本上，默认指定的网段是192.168.56.0/24，无法更改为其他网段。因此不能够像这篇文章 宿主机利用在虚拟机中建立的VPN加密隧道连接内网 中提到的，修改VirtualBox的网段。\n2024.10.21补充：目前virtualbox 7.1.2​已经支持修改网段。我将该host-only网址指定为 192.168.137.2，因为windows11在网络共享时默认指定的网络地址192.168.137.1，需要两者在同一网段内。可以在后续少修改一次网络地址。\n​​\n​​\n添加完后，可以在Linux宿主机中查看\n1 ip addr ​​\n为虚拟机添加host-only的网卡并设置共享VPN网络 在虚拟机对应的设置中，增加一个网卡，连接方式选择 仅主机（Host-Only）网络​。但需要先关闭虚拟机，否则无法进行更改，就像我这里一样，没有关闭虚拟机，按钮是灰色的。\n​​​​\n添加完成后，记住这里的MAC地址结尾E124，后续识别网卡的时候会用。打开虚拟机，进入设置-\u0026gt;网络和Internet-\u0026gt;高级网络设置-\u0026gt;更多网络适配器选项。\n​​\n这里的三个网卡，其中一个是深信服的Sanfor的网卡，也就是我这里的vpn软件使用的网卡。以太网是NAT网络的网卡，以太网2是host-only网卡。\n可以在win11中的终端中输入命令Get-NetAdapter​查看，前面添加网卡的时候提到，E124结尾的是Host-Only，所以这里就可以区分出哪一些是VPN的网卡，哪一些是virtualbox创建的网卡。\n​​\n然后开启VPN，转到网络适配器界面。右键VPN对应的网卡，选择 属性-\u0026gt;共享，然后选择Host-Only网卡。\n​​\n这里win10以前的系统可能弹出提示窗，说会前往设置以太网2的IP为192.168.137.1，我是安装的win11，没有弹窗，默认更改。因此，我们需要手动将Host-Only网卡的IP修改回原来的设定好的地址。\n2024.10.21补充：目前virtualbox 7.1.2​已经支持修改网段。我将该host-only网址指定为 192.168.137.2，因为windows11在网络共享时默认指定的网络地址是192.168.137.1，两者需要在同一网段内不能冲突。这里就不需要更改。\n右键Host-Only网卡，选择属性，Internet 协议版本 4，然后双击，就会弹出修改IP的弹窗。\n​​​​\n如果前面开启了DHCP，则可以点自动获取IP，否则需要手动改动IP为Host-Only网络段中与前面设置不同的IP地址。比如前面已经使用了 192.168.56.1 和 192.168.56.2，则就现在就需要设置为192.168.56.3。\n​​\n设置完成后，回到host。\n连通性测试 设置完成后，在host的终端中，应该可以ping通虚拟机中的host网卡的地址\n​​\n如果ping不通，显示无法到达，很可能是win11的防火墙没有开启报文回复功能。\n参考：知乎回答，在设置中按照 隐私安全性 -\u0026gt; Windows安全中心 -\u0026gt; 防火墙和网络保护，打开防火墙设置\n​​\n然后打开高级设置，将入站和出站的ICMPv4回显请求​功能打开。\n​​\n宿主机设置路由 添加路由规则 我使用的manjaro，默认安装的是ip工具，先查看当前路由表\n1 sudo ip route ​​\n可以看到192.168.56.0/24的网络段都会被路由到虚拟机win11的地址为192.168.56.1的网卡上去。但没有将VPN内网地址路由到虚拟机的表项。\n因此需要添加路由规则，将VPN访问的网段路由到192.168.56.3，也就是之前在虚拟机中的host-only网卡中修改的地址。vboxnet0就是之前添加网卡时，系统中显示的网卡。\n1 sudo ip route add 10.0.0.0/8 via 192.168.56.3 dev vboxnet0 metric 100 我要访问的VPN网段为10.0.0.0/8，如有需要可以更改为自己的内网网段。metric 100​设置路由优先级，避免在Linux宿主机开启其他网络代理时，优先代理该网络段。\n2024.10.21补充：目前virtualbox 7.1.2​已经支持修改网段。我将该host-only网址指定为 192.168.137.1，因为这是windows11在网络共享时默认指定的网络地址。则这里路由添加表项就应当修改为\n1 sudo ip route add 10.0.0.0/8 via 192.168.137.1 dev vboxnet0 metric 100 添加完成后再次查看\n​​\n此时 PING 自己的内网网段，就可以ping通。如果这里发现，ping不通，则需要在win11中重新将VPN的网卡分享到host-only网卡，然后修改host-only网卡（或者是VPN不会转发ICMP消息，可以直接打开对应VPN内网资源看看是否成功）。下一次开机时，需要先取消共享网络，再重新共享，否则也会出现没有回复的情况。（即每次开虚拟机并开启VPN后，都需要重新共享网络）\n​​\n设置完成后，如果重启虚拟机，需要重新分享网络，然后再更改ip。​​\n目前还没有添加永久路由的方法，每次Linux宿主机重启后，都需要重新添加路由。\n在主机中访问对应网段 当可以ping通时，就能够在主机中正常访问了。实测ssh到内网网段服务器也是可以的。\n​​\n且不会和主机中的vpn冲突。我的主机使用的是v2ray进行科学上网，实测对本文中的行为没有影响，如果使用其他方式，不能保证。\n2024.10.21补充： 在 v2ray 不能很好的解决DNS泄漏，以及代理节点转向clash verge后，换用clash verge作为代理软件。在Linux上，Clash需要开启TUN模式，会接管DNS系统。我们学校的一些内网域名需要向VPN软件设立的DNS服务器（198.18.0.1）查询ip地址，而TUN模式的DNS查询不会自动转发到我们自己设立的虚拟机的网路中，因此导致这类网址只能在虚拟机中访问。\n尝试过在clash中配置单独的域名解析地位，将这类域名DNS解析服务器指定为198.18.0.1​，并将clash的fake ip域名范围修改为198.19.0.1/16​（默认为198.18.0.1/16​，和VPN的网段冲突）。但目前的clash verge版本中，配置nameserver-policy:​不生效，因此，此方案还没有结果。\n目前没有其他解决方式，但这种情况不需要在Linux宿主机上解决，直接在虚拟机上访问即可。本文的初衷是在Linux中的终端访问服务器，或者vscode连接服务器工作，因此只需要能够正常通过ip连接内网服务器即可。\n2024.11.4补充： 本文只能代理 10.0.0.0/8​ 的网段，如果希望通过访问内网域名的形式访问内网资源，则还应当配置 DNS 服务器。 ‍\n","date":"2023-10-12T11:12:24+08:00","permalink":"https://codetang-2417.github.io/p/linuxmanjaro%E5%AE%BF%E4%B8%BB%E6%9C%BA%E9%80%9A%E8%BF%87virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BAwin11%E8%BF%9E%E6%8E%A5vpn%E8%AE%BF%E9%97%AE%E5%86%85%E7%BD%91/","title":"Linux（Manjaro）宿主机通过virtualBox虚拟机win11连接vpn访问内网"},{"content":"现象：浏览网页，编写文字等正常工作时，会突然卡死，屏幕显示内容不动，鼠标无法移动，键盘没有反应（按下大小写键，大写提示灯不会改变）。且完全随机 ，跟打开软件没有关系。经过一年多的使用，的确是AMD CPU的问题。因此尝试下面这个方案：Ryzen随机卡死问题、解决方案原git仓库\n原博主内容截图：\n​​\n根据其中的描述\n先安装守护进程服务软件\n1 2 yay -S disable-c6-systemd sudo modprobe msr 编辑/etc/modules-load.d/modules.conf，添加msr这一行，以便在启动时加载msr模块：\n1 msr 最后，启动如下service，完成上述操作完成后，推荐重启电脑后才能启动。\n1 2 sudo systemctl enable disable-c6.service sudo systemctl start disable-c6.service 如果报错，就在重启后重新安装一下，再开service。\n​​\n另，根据在Manjaro中的讨论，有人在Archlinux的wiki中也找到了同样的问题描述，称之为 Soft lock freezing 。根据其解决方案的描述，提供了四种方案：\n关闭rcu。考虑到需要编译内核，比较麻烦，大多数情况下不会尝试。\n当Kernel \u0026gt;= 4.10.0​，编译内核时，追加参数CONFIG_RCU_NOCB_CPU​进行编译。将echo rcu_nocbs=0-$(($(nproc)-1))​的结果，添加到grub的GRUB_CMDLINE_LINUX​中。\n关闭c6 state\nkernel参数追加processor.max_cstate=5​：在grub的GRUB_CMDLINE_LINUX​中添加processor.max_cstate=5processor.max_cstate=5​\n1 sudo nano /etc/default/grub ​​\n保存后，还要运行sudo update-grub​以更新grub。\n但这个方法有可能不能正确关闭c6状态，此时就需要本文提到的方法，使用disable-c6-systemd​进行关闭。该方法在我的电脑上不可行的，因此我通过disable-c6-systemd​进行关闭。\n某一些笔记本中（例如HP Envy x360 15-bq100na），可能存在CPU软件锁定的问题，通过在kernel中追加参数idle=nomwait​，可以避免。\nkernel参数追加pci=nomsi​，这个办法我尝试过，但不起作用，仍然会冻结。尝试：acpi_osi=Linux​加入的到kernel参数或许有用(我增加这个参数后，仍然会死机，但相较于之前概率小很多)。\n补充：这个问题所有的AMD的Ryzen处理器都会遇到！根据 Bug 196683 - Random Soft Lockup on new Ryzen build 这个帖子中的讨论，从2017年就开始存在，一直到现在都没有修复，我使用的是 R7 5800H，甚至在windows下，都有一定概率发生。因此，AMD真的不能yes，下一台笔记本还是intel算了。AMD虽然整体性能已经追上来了，但仍然有一些小问题，虽然不致命，但很让人心烦。\n2023/10/13 更新\n最近的卡死概率降低了很多，但是在半夜仍然会卡死，看来通过软件在开机启动的时候关闭C6不能完全解决这个问题。\n又通过一些搜索，找到了下面的文章：ADM Ryzon处理器随机”冻结”问题、AMD Ryzen CPU 随机“冻结”、AMD Ryzen 2700X + CentOS7 隨機鎖死問題\n根据其中的各种描述，解决方法如下：\n如果你的BIOS支持关闭CPU电源管理，则需要在BIOS中关闭。 在内核参数中增加​idle=nomwait​ 在内核参数中增加​processor.max_cstate=1 intel_idle.max_cstate=0​ 内核参数更新后，需要手动执行sudo update-grub​以更新配置 通过下列命令查看max_cstate​，没有更改之前其值为9。\n1 cat /sys/module/intel_idle/parameters/max_cstate 通过cat /proc/cmdline​可以查看内核启动参数。\n最后，我有一个不算办法的办法：启动 linux 后启动 virtualbox 虚拟机，运行 windows。这样的话，virtualbox 一直运行，能够保证不处于低功耗状态，且因为 Linux 现在并不支持微信，日常使用还是需要安装 windows 的虚拟机，因此这也算是一个卡死问题的解决方案。\n2024/9/16 更新\nLinux现在是6.1内核，更新几次内核以后现在已经不存在卡死的问题了，即便是低功耗运行。\n但是，windows 11更新以后却开始了。。。也是低功耗运行时卡死，或者重启。为了玩黑神话我重装了系统，坏消息是重装系统没用；好消息是，高负载下不会卡死，不会重启。\n","date":"2023-10-08T22:49:25+08:00","permalink":"https://codetang-2417.github.io/p/ryzen%E9%9A%8F%E6%9C%BA%E5%8D%A1%E6%AD%BB%E9%97%AE%E9%A2%98/","title":"Ryzen随机卡死问题"},{"content":"当系统死机，没有响应（freezes），需要重启时，大多数人使用的方法是长按电源按钮进行硬关机，这样会导致系统数据丢失，严重情况下甚至会损坏系统。但在linux内核中，有一个特殊的按键：SysRq（Sys tem R e q uest key）。如果激活SysRq键，就可以输入一些特殊的系统操作命令，用于在系统崩溃时进行一些操作（同步数据、杀进程、卸载文件系统，甚至系统重启）。可以安全的重启系统。\n参考：linux 中的 SysRq 魔术键\nSysRq 键 在 QWERT 的全尺寸键盘上与 PrtSc​ 同键，并且会在按键上标注有SysRq。使用Alt​+PrtSc​激活SysRq​。\n在一些笔记本上虽然没有标注，但可以通过Fn​+Alt​+PrtSc​组合键的方式激活SysRq按键。\n如果上面的组合都不起作用，则可以尝试下面几种：\n​Alt​+PrtSc​ ​Alt Gr​+PrtSc​ ​Ctrl​+Alt​+PrtSc​ 注意，激活SysRq​后，需要保持Alt​按键按下，并松开SysRq​或​PrtSc​\n请阅读完后续内容再尝试，并在尝试之前保存所有工作内容！\nREISUB 参考：[HowTo] reboot / turn off your frozen computer: REISUB/REISUO\nREISUB是 R eboot E ven I f S ystem U tterly B roken 的SysRq命令的助记符。表示 即使系统完全崩溃也能重启。\n激活SysRq按键后，在键盘上按下如下按键，就可以优雅的重启系统：\nSwitch the keyboard from R aw mode, used by programs such as X11 ​112 and SVGALib ​25, to XLATE (translate) mode Send an E nd signal (SIGTERM) to all processes, except the boot process, allowing all processes to end gracefully Send an I nstant kill (SIGKILL) to all processes, except the boot process, forcing​ all processes to end ​43 . S ync all mounted filesystems, allowing them to write all data to disk. U nmount and remount all mounted filesystems in read-only ​8 mode. Re B oot the system 下面是上述英文的中文解释\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 R - 把键盘设置为 ASCII 模式 (用于接收后面键盘输入) SysRq: Keyboard mode set to XLATE E - 向除 init 以外所有进程发送 SIGTERM 信号 (让进程自己正常退出) SysRq: Terminate All Tasks I - 向除 init 以外所有进程发送 SIGKILL 信号 (强制结束进程) SysRq: Kill All Tasks S - 磁盘缓冲区同步 SysRq : Emergency Sync U - 重新挂载为只读模式 SysRq : Emergency Remount R/O B - 立即重启系统 SysRq: Resetting 由于系统环境与后台进程个数的不确定性，每一步按键操作执行完成所费时间无法确定。为保险起见，一般采用 R – 1 秒 – E – 30 秒 – I – 10 秒 – S – 5 秒 – U – 5 秒 – B，而不是一气呵成地按下这六个键。\n用法 如果按照上述方法，并没有左右，则可能是SysRq​功能没有启用。\n启用 SysRq 功能 首先检查 SysRq​ 是否开启\n1 cat /proc/sys/kernel/sysrq 若输出为 0，则还未开启。\n在manjaro中，通过向grub写入配置命令启用Linux的SysRq功能。\n向文件/etc/default/grub​中的GRUB_CMDLINE_LINUX_DEFAULT​参数添加： sysrq_always_enabled=1​\n1 sudo nano /etc/default/grub 更改完后记得ctrl​+O​保存文件。\n​​\n然后执行\n1 sudo update-grub 更新grub。最后重启系统。\n实际使用过程 先激活SysRq​按键，全键盘：Alt​+SysRq​，笔记本：Fn​+Alt​+PrtSc​。激活后保持Alt​按键按下，松开PrtSc​或者SysRq​。\n根据电脑的性能不同，激活时间不一样。新硬件可能在1秒，旧的硬件可能在6秒。\n激活后，在键盘上按照R E I S U B的顺序，就可以安全的重启系统，需要注意根据上述介绍，一般采用 R – 1 秒 – E – 30 秒 – I – 10 秒 – S – 5 秒 – U – 5 秒 – B，而不是一气呵成地按下这六个键。\n‍\n","date":"2023-10-07T11:12:13+08:00","permalink":"https://codetang-2417.github.io/p/linux%E4%B8%AD%E7%9A%84sysrq%E9%AD%94%E6%9C%AF%E9%94%AE/","title":"Linux中的SysRq魔术键"},{"content":"参考链接：降级软件包\n使用pacman的临时文件 如果一个新包刚刚被安装并且没有删除pacman cache,你可以在/var/cache/pacman/pkg/​中找到较早版本. 安装替换现有的版本.pacman会处理依赖包但不会处理依赖库的版本冲突。如果一个其依赖库因该包降级需要降级，你需要手动降级这些包。\n1 $ pacman -U /var/cache/pacman/pkg/package-old_version.pkg.tar.type 对老的软件包，type​ 应该是 xz​，遵循 2020 变更的新软件包，type​ 应该是 zst​。\n当成功降级该包以后，请暂时将其加入​**pacman.conf**​​​的IgnorePkg section，直到您的问题被解决。\n使用nano编辑文件/etc/pacman.conf，找到其中的IgnorePKG字段，按照下图将降级包加入到配置中。\n​​\n如果本地没有旧版本的cache，或者是被清理了，则需要去Arch Linux Archive下载旧版本的包，然后重复上述操作。\nArch Linux Archive Arch Linux Archive是official repositories的日更快照。\nALA能被用来降级包或者还原整个系统到过去版本。\n网站链接：归档\n自动化 downgrade — 基于Bash使用本地缓存和Arch Rollback Machine。详见downgrade(8)。\nhttps://github.com/pbrisbin/downgrade || downgrade​^AUR^\n‍\n","date":"2023-10-06T19:10:01+08:00","permalink":"https://codetang-2417.github.io/p/archlinux-%E9%99%8D%E7%BA%A7%E5%AE%89%E8%A3%85/","title":"Archlinux  降级安装"}]